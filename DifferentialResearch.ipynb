{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Исследование с учетом разницы между чистым и адверсариальным примерами",
   "id": "8a77807f92f26ee"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Определение функций",
   "id": "8c941b31fbad5a84"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Импорты и вспомогательные функции для отрисовки\n",
    "\n",
    "### Что делаем:\n",
    "\n",
    "Готовим инструменты для (1) локализации патча по разнице изображений и (2) сопоставления детекций.\n",
    "\n",
    "### Зачем:\n",
    "\n",
    "Для «гетерогенности успеха» критично локализовать вмешательство (патч) и сопоставлять объекты между clean и patched.\n",
    "\n",
    "IoU/matching нужен, чтобы понять: «тот же объект» пропал или просто сдвинулся.\n",
    "\n",
    "### Откуда идея в литературе:\n",
    "\n",
    "Thys 2019 (зависимость эффективности от положения патча), Saha 2020 (влияние патча даже при малом перекрытии), бенчмарки/анализы патчей (пространственные эффекты)."
   ],
   "id": "d84fdcdf4532443d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T11:47:12.433216Z",
     "start_time": "2026-01-19T11:47:10.517591Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import Any, Dict, List, Optional, Tuple\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Image conversions\n",
    "# -------------------------\n",
    "\n",
    "def pil_to_np_bgr(pil: Image.Image) -> np.ndarray:\n",
    "    \"\"\"PIL RGB -> np.uint8 BGR (H,W,3) for ultralytics predictor preprocess.\"\"\"\n",
    "    if pil.mode != \"RGB\":\n",
    "        pil = pil.convert(\"RGB\")\n",
    "    rgb = np.asarray(pil)  # uint8 RGB\n",
    "    bgr = rgb[..., ::-1].copy()\n",
    "    return bgr\n",
    "\n",
    "\n",
    "def pil_to_torch_rgb01(pil: Image.Image) -> torch.Tensor:\n",
    "    \"\"\"PIL -> torch float32 RGB in [0,1], shape [3,H,W] (CPU).\"\"\"\n",
    "    if pil.mode != \"RGB\":\n",
    "        pil = pil.convert(\"RGB\")\n",
    "    arr = np.asarray(pil).astype(np.float32) / 255.0\n",
    "    t = torch.from_numpy(arr).permute(2, 0, 1).contiguous()\n",
    "    return t\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Box utilities\n",
    "# -------------------------\n",
    "\n",
    "def box_iou_xyxy(a: torch.Tensor, b: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"IoU between sets of boxes in xyxy format. a[N,4], b[M,4] -> [N,M].\"\"\"\n",
    "    if a.numel() == 0 or b.numel() == 0:\n",
    "        return torch.zeros((a.shape[0], b.shape[0]), device=a.device, dtype=a.dtype)\n",
    "\n",
    "    tl = torch.maximum(a[:, None, :2], b[None, :, :2])\n",
    "    br = torch.minimum(a[:, None, 2:], b[None, :, 2:])\n",
    "    wh = (br - tl).clamp(min=0)\n",
    "    inter = wh[..., 0] * wh[..., 1]\n",
    "\n",
    "    area_a = (a[:, 2] - a[:, 0]).clamp(min=0) * (a[:, 3] - a[:, 1]).clamp(min=0)\n",
    "    area_b = (b[:, 2] - b[:, 0]).clamp(min=0) * (b[:, 3] - b[:, 1]).clamp(min=0)\n",
    "\n",
    "    union = area_a[:, None] + area_b[None, :] - inter\n",
    "    return inter / union.clamp(min=1e-9)\n",
    "\n",
    "\n",
    "def greedy_match_by_iou(boxes_a: torch.Tensor, boxes_b: torch.Tensor, iou_thr: float = 0.5) -> List[Tuple[int, int, float]]:\n",
    "    \"\"\"Greedy IoU matching: returns list of (i_in_a, j_in_b, iou).\"\"\"\n",
    "    iou = box_iou_xyxy(boxes_a, boxes_b)\n",
    "    pairs: List[Tuple[int, int, float]] = []\n",
    "    if iou.numel() == 0:\n",
    "        return pairs\n",
    "\n",
    "    used_a, used_b = set(), set()\n",
    "    flat = []\n",
    "    for i in range(iou.shape[0]):\n",
    "        for j in range(iou.shape[1]):\n",
    "            flat.append((i, j, float(iou[i, j].item())))\n",
    "    flat.sort(key=lambda x: x[2], reverse=True)\n",
    "\n",
    "    for i, j, v in flat:\n",
    "        if v < iou_thr:\n",
    "            break\n",
    "        if i in used_a or j in used_b:\n",
    "            continue\n",
    "        used_a.add(i)\n",
    "        used_b.add(j)\n",
    "        pairs.append((i, j, v))\n",
    "    return pairs\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Patch localization by diff\n",
    "# -------------------------\n",
    "\n",
    "def estimate_patch_region_from_diff(\n",
    "    clean_rgb01: torch.Tensor,\n",
    "    patched_rgb01: torch.Tensor,\n",
    "    diff_thr: float = 0.08,\n",
    "    min_pixels: int = 50,\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Estimate patch region via abs-diff thresholding.\n",
    "    Returns:\n",
    "      diff_map: [H,W] float\n",
    "      mask: [H,W] bool\n",
    "      bbox_xyxy: torch.Tensor[4] or None\n",
    "      area_px: int\n",
    "    \"\"\"\n",
    "    assert clean_rgb01.shape == patched_rgb01.shape\n",
    "    diff = (patched_rgb01 - clean_rgb01).abs().mean(dim=0)  # [H,W]\n",
    "    mask = diff > diff_thr\n",
    "    area = int(mask.sum().item())\n",
    "    bbox = None\n",
    "    if area >= min_pixels:\n",
    "        ys, xs = mask.nonzero(as_tuple=True)\n",
    "        x1 = float(xs.min().item())\n",
    "        x2 = float(xs.max().item() + 1)\n",
    "        y1 = float(ys.min().item())\n",
    "        y2 = float(ys.max().item() + 1)\n",
    "        bbox = torch.tensor([x1, y1, x2, y2], dtype=torch.float32)\n",
    "    return {\"diff_map\": diff, \"mask\": mask, \"bbox_xyxy\": bbox, \"area_px\": area}\n",
    "\n",
    "\n",
    "def show_patch_diff(clean_rgb01: torch.Tensor, patched_rgb01: torch.Tensor, patch_info: Dict[str, Any]) -> None:\n",
    "    diff = patch_info[\"diff_map\"].detach().cpu().numpy()\n",
    "    mask = patch_info[\"mask\"].detach().cpu().numpy()\n",
    "    bbox = patch_info[\"bbox_xyxy\"]\n",
    "\n",
    "    def imshow_rgb(t: torch.Tensor, ax, title: str):\n",
    "        ax.imshow(t.detach().cpu().permute(1, 2, 0).numpy().clip(0, 1))\n",
    "        ax.set_title(title)\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "    fig, axs = plt.subplots(1, 4, figsize=(16, 4))\n",
    "    imshow_rgb(clean_rgb01, axs[0], \"Clean\")\n",
    "    imshow_rgb(patched_rgb01, axs[1], \"Patched\")\n",
    "    axs[2].imshow(diff); axs[2].set_title(\"Abs diff (mean C)\"); axs[2].axis(\"off\")\n",
    "    axs[3].imshow(mask); axs[3].set_title(\"Diff mask\"); axs[3].axis(\"off\")\n",
    "\n",
    "    if bbox is not None:\n",
    "        x1, y1, x2, y2 = bbox.tolist()\n",
    "        for ax in axs:\n",
    "            ax.add_patch(plt.Rectangle((x1, y1), x2 - x1, y2 - y1, fill=False, linewidth=2))\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ],
   "id": "fbc121e30a2defb3",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Логика, связанная с предсказаниями\n",
    "\n",
    "### Что делаем:\n",
    "\n",
    "Инициализируем predictor (Ultralytics).\n",
    "\n",
    "Получаем:\n",
    "\n",
    "im — тензор после preprocess (letterbox+нормировка),\n",
    "\n",
    "raw — сырые предсказания модели (до NMS),\n",
    "\n",
    "post — финальные боксы после Ultralytics NMS,\n",
    "\n",
    "candidates — «почти pre-NMS» боксы через вызов Ultralytics NMS с iou_thres=1.0.\n",
    "\n",
    "### Зачем:\n",
    "\n",
    "Различать “score suppression” (candidate есть, но ниже conf) от “NMS suppression” (candidate есть и выше conf, но выкинут перекрывающимся конкурентом).\n",
    "\n",
    "Именно это разделение очень часто упоминается как источник «нестабильности по изображениям».\n",
    "\n",
    "### Откуда идея в литературе:\n",
    "\n",
    "DPatch 2019: патч как приманка → много сильных ложных кандидатов.\n",
    "\n",
    "Daedalus 2022: атаки на пост-обработку и поведение NMS.\n",
    "\n",
    "Аналитические бенчмарки 2022–2023: необходимость смотреть pre-NMS/порог/NMS раздельно."
   ],
   "id": "1b2eacbbf6a938ca"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T14:16:42.710586Z",
     "start_time": "2026-01-19T14:16:42.664410Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "def load_ultralytics_yolo(weights: str):\n",
    "    \"\"\"Convenience loader. Example: 'yolo11n.pt' or your custom .pt.\"\"\"\n",
    "    from ultralytics import YOLO\n",
    "    return YOLO(weights)\n",
    "\n",
    "\n",
    "def ensure_predictor(yolo, imgsz: int = 640, conf: float = 0.25, iou: float = 0.45, device: Optional[str] = None):\n",
    "    \"\"\"\n",
    "    Ultralytics lazily creates a predictor; we force initialization via a dummy predict.\n",
    "\n",
    "    Why:\n",
    "    - We need access to predictor.preprocess() and predictor.postprocess() for a consistent pipeline.\n",
    "    \"\"\"\n",
    "    if getattr(yolo, \"predictor\", None) is None:\n",
    "        dummy = np.zeros((imgsz, imgsz, 3), dtype=np.uint8)\n",
    "        _ = yolo.predict(source=dummy, imgsz=imgsz, conf=conf, iou=iou, device=device, verbose=False)\n",
    "\n",
    "    yolo.predictor.args.imgsz = imgsz\n",
    "    yolo.predictor.args.conf = conf\n",
    "    yolo.predictor.args.iou = iou\n",
    "\n",
    "    if device is not None:\n",
    "        yolo.predictor.device = torch.device(device)\n",
    "        yolo.predictor.model.to(device)\n",
    "\n",
    "    return yolo.predictor\n",
    "\n",
    "\n",
    "def get_ultralytics_raw_preds_and_im(\n",
    "    yolo,\n",
    "    pil: Image.Image,\n",
    "    imgsz: int = 640,\n",
    "    conf: float = 0.25,\n",
    "    iou: float = 0.45,\n",
    "    device: Optional[str] = None,\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      orig_bgr: np.ndarray(H,W,3)\n",
    "      im: torch.Tensor(1,3,h,w) after Ultralytics preprocess\n",
    "      raw: raw model outputs (before NMS)\n",
    "      predictor: Ultralytics predictor\n",
    "\n",
    "    Why:\n",
    "    - raw is required for pre-NMS analysis and alternative postprocessing.\n",
    "    - im is required for consistent scaling back to original image coordinates.\n",
    "    \"\"\"\n",
    "    predictor = ensure_predictor(yolo, imgsz=imgsz, conf=conf, iou=iou, device=device)\n",
    "\n",
    "    orig_bgr = pil_to_np_bgr(pil)\n",
    "    im = predictor.preprocess([orig_bgr])\n",
    "    with torch.no_grad():\n",
    "        raw = predictor.inference(im)\n",
    "    return {\"orig_bgr\": orig_bgr, \"im\": im, \"raw\": raw, \"predictor\": predictor}\n",
    "\n",
    "\n",
    "def ultralytics_post_nms_from_raw(\n",
    "    predictor,\n",
    "    raw_preds: torch.Tensor,\n",
    "    im: torch.Tensor,\n",
    "    orig_bgr: np.ndarray,\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Uses Ultralytics official postprocess (includes NMS + scaling) to get final detections.\n",
    "\n",
    "    Why:\n",
    "    - This is the “ground truth” of what the user typically sees.\n",
    "    - We compare it against our pre-NMS candidates and traced NMS.\n",
    "    \"\"\"\n",
    "    results = predictor.postprocess(raw_preds, im, [orig_bgr])\n",
    "    r0 = results[0]\n",
    "    boxes = r0.boxes.xyxy\n",
    "    scores = r0.boxes.conf\n",
    "    labels = r0.boxes.cls.long()\n",
    "    return {\"boxes\": boxes, \"scores\": scores, \"labels\": labels, \"results_obj\": r0}\n",
    "\n",
    "\n",
    "def ultralytics_candidates_no_suppression(\n",
    "    raw_preds: torch.Tensor,\n",
    "    conf_thres: float = 0.001,\n",
    "    max_det: int = 30000,\n",
    "    nc: int = 0,\n",
    "    rotated: bool = False,\n",
    "    end2end: bool = False,\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Produces a large set of candidates by running Ultralytics NMS with iou_thres=1.0\n",
    "    (effectively no suppression). This approximates “pre-NMS candidates”.\n",
    "\n",
    "    Why:\n",
    "    - We want to know whether the target existed among candidates at all.\n",
    "    - We want to later trace how NMS removes candidates.\n",
    "    \"\"\"\n",
    "    from ultralytics.utils import nms as ul_nms\n",
    "    out = ul_nms.non_max_suppression(\n",
    "        raw_preds,\n",
    "        conf_thres=conf_thres,\n",
    "        iou_thres=1.0,\n",
    "        classes=None,\n",
    "        agnostic=False,\n",
    "        multi_label=False,\n",
    "        labels=(),\n",
    "        max_det=max_det,\n",
    "        nc=nc,\n",
    "        rotated=rotated,\n",
    "        end2end=end2end,\n",
    "        return_idxs=False,\n",
    "    )\n",
    "    return out[0] if len(out) else torch.zeros((0, 6), device=raw_preds.device)\n",
    "\n",
    "\n",
    "def scale_boxes_to_original(\n",
    "    boxes_xyxy: torch.Tensor,\n",
    "    im_shape_hw: Tuple[int, int],\n",
    "    orig_shape_hw: Tuple[int, int],\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Scales xyxy from model input coords to original image coords using Ultralytics ops.\n",
    "\n",
    "    Why:\n",
    "    - Matching and patch-overlap must be done in original image space.\n",
    "    \"\"\"\n",
    "    from ultralytics.utils import ops\n",
    "    scaled = boxes_xyxy.clone()\n",
    "    scaled[:, :4] = ops.scale_boxes(im_shape_hw, scaled[:, :4], orig_shape_hw)\n",
    "    return scaled\n",
    "\n",
    "\n",
    "def split_cand(c: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"Candidate tensor (N,6) -> boxes(N,4), scores(N), labels(N).\"\"\"\n",
    "    if c.numel() == 0:\n",
    "        dev = c.device\n",
    "        return (\n",
    "            torch.zeros((0, 4), device=dev),\n",
    "            torch.zeros((0,), device=dev),\n",
    "            torch.zeros((0,), dtype=torch.long, device=dev),\n",
    "        )\n",
    "    return c[:, :4], c[:, 4], c[:, 5].long()"
   ],
   "id": "e1fa95d68774f328",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## NMS с трассировкой подавлений (кто кого подавил)\n",
    "\n",
    "### Что делаем:\n",
    "\n",
    "Реализуем NMS, которая возвращает не только kept boxes, но и список событий вида:\n",
    "\n",
    "какой кандидат подавлен,\n",
    "\n",
    "кем подавлен,\n",
    "\n",
    "IoU и сравнение score.\n",
    "\n",
    "### Зачем:\n",
    "\n",
    "Это прямой инструмент, чтобы различить “провал из-за NMS” от “провал из-за feature/score suppression”.\n",
    "\n",
    "Также позволяет понять паттерн “патч как приманка”: если подавляющие боксы часто расположены внутри bbox патча.\n",
    "\n",
    "### Откуда идея в литературе:\n",
    "\n",
    "Daedalus 2022: эффекты атаки на NMS/фильтрацию.\n",
    "\n",
    "DPatch 2019: ложные детекции конкурируют с целевыми.\n",
    "\n",
    "Бенчмарки/аналитика 2022: необходимость объяснять исчезновение объекта через post-processing."
   ],
   "id": "de0b07906188ae3a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T14:17:47.582852Z",
     "start_time": "2026-01-19T14:17:47.572436Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@dataclass\n",
    "class NMSSuppressionEvent:\n",
    "    suppressed_idx: int\n",
    "    kept_idx: int\n",
    "    iou: float\n",
    "    suppressed_score: float\n",
    "    kept_score: float\n",
    "    suppressed_cls: int\n",
    "    kept_cls: int\n",
    "\n",
    "\n",
    "def nms_with_trace(\n",
    "    boxes_xyxy: torch.Tensor,\n",
    "    scores: torch.Tensor,\n",
    "    clses: torch.Tensor,\n",
    "    iou_thr: float,\n",
    "    class_aware: bool = True,\n",
    "    max_det: int = 300,\n",
    ") -> Tuple[torch.Tensor, List[NMSSuppressionEvent]]:\n",
    "    \"\"\"\n",
    "    Deterministic NMS with suppression trace.\n",
    "\n",
    "    Returns:\n",
    "      kept_indices: indices into original candidate arrays\n",
    "      events: list of suppression events\n",
    "\n",
    "    Notes:\n",
    "    - This is a simplified NMS; later we can align it exactly with Ultralytics by using return_idxs=True\n",
    "      in ultralytics.utils.nms.non_max_suppression.\n",
    "    \"\"\"\n",
    "    if boxes_xyxy.numel() == 0:\n",
    "        return torch.empty((0,), dtype=torch.long, device=boxes_xyxy.device), []\n",
    "\n",
    "    order = scores.argsort(descending=True)\n",
    "    boxes = boxes_xyxy[order]\n",
    "    scr = scores[order]\n",
    "    cls = clses[order]\n",
    "\n",
    "    keep_local: List[int] = []\n",
    "    events: List[NMSSuppressionEvent] = []\n",
    "\n",
    "    suppressed = torch.zeros((boxes.shape[0],), dtype=torch.bool, device=boxes.device)\n",
    "\n",
    "    for i in range(boxes.shape[0]):\n",
    "        if suppressed[i]:\n",
    "            continue\n",
    "        keep_local.append(i)\n",
    "        if len(keep_local) >= max_det:\n",
    "            break\n",
    "\n",
    "        rest = torch.arange(i + 1, boxes.shape[0], device=boxes.device)\n",
    "        if rest.numel() == 0:\n",
    "            continue\n",
    "\n",
    "        ious = box_iou_xyxy(boxes[i:i+1], boxes[rest]).squeeze(0)\n",
    "        if class_aware:\n",
    "            same_cls = cls[rest] == cls[i]\n",
    "        else:\n",
    "            same_cls = torch.ones_like(ious, dtype=torch.bool)\n",
    "\n",
    "        to_suppress = (ious > iou_thr) & same_cls\n",
    "        sup_idxs = rest[to_suppress]\n",
    "\n",
    "        for j_local in sup_idxs.tolist():\n",
    "            events.append(\n",
    "                NMSSuppressionEvent(\n",
    "                    suppressed_idx=int(order[j_local].item()),\n",
    "                    kept_idx=int(order[i].item()),\n",
    "                    iou=float(box_iou_xyxy(boxes[i:i+1], boxes[j_local:j_local+1]).item()),\n",
    "                    suppressed_score=float(scr[j_local].item()),\n",
    "                    kept_score=float(scr[i].item()),\n",
    "                    suppressed_cls=int(cls[j_local].item()),\n",
    "                    kept_cls=int(cls[i].item()),\n",
    "                )\n",
    "            )\n",
    "        suppressed[sup_idxs] = True\n",
    "\n",
    "    kept_global = order[torch.tensor(keep_local, device=boxes.device)]\n",
    "    return kept_global, events"
   ],
   "id": "20695acc4dd1109c",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Feature-level: hooks на Detect head (multi-scale feature maps)\n",
    "\n",
    "### Что делаем:\n",
    "\n",
    "Находим модуль Detect внутри модели Ultralytics.\n",
    "\n",
    "Ставим hook и сохраняем его входы — список feature maps разных масштабов.\n",
    "\n",
    "Для ROI (область объекта или область патча) считаем cosine similarity между clean и patched фичами на каждом масштабе.\n",
    "\n",
    "### Зачем:\n",
    "\n",
    "Если объект пропал «ещё до NMS» (нет кандидата рядом), полезно иметь сигнал: патч реально изменил признаки детектора в области объекта.\n",
    "\n",
    "Это поддерживает гипотезу feature suppression / ранний сбой, а не постпроцессинг.\n",
    "\n",
    "### Откуда идея в литературе:\n",
    "\n",
    "Работы с анализом feature attribution/активаций (2020–2023) и бенчмарки патч-атак: смотреть карты confidence/objectness и связь с признаками.\n",
    "\n",
    "В контексте anchor-free/YOLO-подобных моделей анализируют где и на каком масштабе происходит деградация."
   ],
   "id": "7dcc831093119a34"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T14:19:34.908739Z",
     "start_time": "2026-01-19T14:19:34.891609Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def find_detect_module(torch_model: torch.nn.Module) -> Optional[torch.nn.Module]:\n",
    "    \"\"\"Find Ultralytics Detect head module by class name.\"\"\"\n",
    "    for m in torch_model.modules():\n",
    "        if m.__class__.__name__ == \"Detect\":\n",
    "            return m\n",
    "    return None\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DetectInputsSnapshot:\n",
    "    feat_maps: Optional[List[torch.Tensor]]\n",
    "\n",
    "\n",
    "def _safe_model_forward(torch_model: torch.nn.Module, im: torch.Tensor, kwargs: Dict[str, Any]) -> Any:\n",
    "    \"\"\"Try several forward signatures used by Ultralytics models.\"\"\"\n",
    "    try:\n",
    "        return torch_model(im, **kwargs)\n",
    "    except TypeError:\n",
    "        pass\n",
    "    for trial in [\n",
    "        dict(augment=False, visualize=False),\n",
    "        dict(augment=False, visualize=False, embed=None),\n",
    "    ]:\n",
    "        try:\n",
    "            return torch_model(im, **trial)\n",
    "        except TypeError:\n",
    "            continue\n",
    "    return torch_model(im)\n",
    "\n",
    "\n",
    "def capture_detect_inputs_during_forward(\n",
    "    torch_model: torch.nn.Module,\n",
    "    im: torch.Tensor,\n",
    "    forward_kwargs: Optional[Dict[str, Any]] = None,\n",
    ") -> Tuple[Any, DetectInputsSnapshot]:\n",
    "    \"\"\"\n",
    "    Runs forward and captures Detect head inputs (multi-scale feature maps).\n",
    "\n",
    "    Why:\n",
    "    - These feature maps are the immediate precursor to detection predictions.\n",
    "    - Large changes in ROI features correlate with “feature suppression”.\n",
    "    \"\"\"\n",
    "    det = find_detect_module(torch_model)\n",
    "    snap = DetectInputsSnapshot(feat_maps=None)\n",
    "\n",
    "    if det is None:\n",
    "        with torch.no_grad():\n",
    "            raw = _safe_model_forward(torch_model, im, forward_kwargs or {})\n",
    "        return raw, snap\n",
    "\n",
    "    def hook(_module, inputs, output):\n",
    "        x = inputs[0]\n",
    "        if isinstance(x, (list, tuple)) and len(x) > 0 and torch.is_tensor(x[0]):\n",
    "            snap.feat_maps = [t.detach() for t in x]\n",
    "\n",
    "    h = det.register_forward_hook(hook)\n",
    "    try:\n",
    "        with torch.no_grad():\n",
    "            raw = _safe_model_forward(torch_model, im, forward_kwargs or {})\n",
    "    finally:\n",
    "        try:\n",
    "            h.remove()\n",
    "        except Exception:\n",
    "            pass\n",
    "    return raw, snap\n",
    "\n",
    "\n",
    "def _box_to_feature_coords(box_xyxy: torch.Tensor, feat_h: int, feat_w: int, img_h: int, img_w: int) -> Tuple[int,int,int,int]:\n",
    "    x1, y1, x2, y2 = box_xyxy.tolist()\n",
    "    fx1 = int(round(x1 / img_w * feat_w))\n",
    "    fx2 = int(round(x2 / img_w * feat_w))\n",
    "    fy1 = int(round(y1 / img_h * feat_h))\n",
    "    fy2 = int(round(y2 / img_h * feat_h))\n",
    "    fx1 = max(0, min(feat_w - 1, fx1))\n",
    "    fx2 = max(0, min(feat_w, fx2))\n",
    "    fy1 = max(0, min(feat_h - 1, fy1))\n",
    "    fy2 = max(0, min(feat_h, fy2))\n",
    "    if fx2 <= fx1: fx2 = min(feat_w, fx1 + 1)\n",
    "    if fy2 <= fy1: fy2 = min(feat_h, fy1 + 1)\n",
    "    return fx1, fy1, fx2, fy2\n",
    "\n",
    "\n",
    "def region_cosine_similarity_on_featmap(\n",
    "    feat_clean: torch.Tensor,\n",
    "    feat_patch: torch.Tensor,\n",
    "    box_xyxy_img: torch.Tensor,\n",
    "    img_hw: Tuple[int, int],\n",
    ") -> float:\n",
    "    if feat_clean.dim() == 4:\n",
    "        feat_clean = feat_clean[0]\n",
    "    if feat_patch.dim() == 4:\n",
    "        feat_patch = feat_patch[0]\n",
    "    C, Hf, Wf = feat_clean.shape\n",
    "    Hi, Wi = img_hw\n",
    "    fx1, fy1, fx2, fy2 = _box_to_feature_coords(box_xyxy_img, Hf, Wf, Hi, Wi)\n",
    "\n",
    "    a = feat_clean[:, fy1:fy2, fx1:fx2].flatten()\n",
    "    b = feat_patch[:, fy1:fy2, fx1:fx2].flatten()\n",
    "    if a.numel() == 0 or b.numel() == 0:\n",
    "        return float(\"nan\")\n",
    "\n",
    "    a = a - a.mean()\n",
    "    b = b - b.mean()\n",
    "    sim = torch.nn.functional.cosine_similarity(a[None, :], b[None, :], dim=1).item()\n",
    "    return float(sim)"
   ],
   "id": "3db285c7be5590f",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Главный анализатор пары (clean, patched) + вывод\n",
    "\n",
    "### Что делаем:\n",
    "\n",
    "Для пары изображений вычисляем:\n",
    "\n",
    "bbox патча,\n",
    "\n",
    "Ultralytics post-NMS выходы (как в обычной инференс-процедуре),\n",
    "\n",
    "pre-NMS candidates (приближённо),\n",
    "\n",
    "NMS-trace на patched candidates,\n",
    "\n",
    "сопоставление объектов clean vs patched,\n",
    "\n",
    "пер-объектный диагноз (почему объект пропал/остался).\n",
    "\n",
    "### Зачем:\n",
    "\n",
    "Это центральная логика, которую вы будете «гонять» по множеству изображений.\n",
    "\n",
    "Встроенная диагностика гарантирует полезный результат даже при «провале атаки»: вы всё равно увидите, что изменилось в кандидатах/скор/фичах.\n",
    "\n",
    "### Откуда идея в литературе:\n",
    "\n",
    "Разделение механизмов по стадиям (порог/NMS/фичи) — мотивировано работами, где патч либо снижает objectness, либо создаёт конкурентов."
   ],
   "id": "ab99d4d5dd0e08c8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T14:24:13.626288Z",
     "start_time": "2026-01-19T14:24:13.593019Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@dataclass\n",
    "class TargetDiagnosis:\n",
    "    clean_idx: int\n",
    "    clean_label: int\n",
    "    clean_score: float\n",
    "    status: str\n",
    "    diagnosis: str\n",
    "    evidence: Dict[str, Any]\n",
    "\n",
    "\n",
    "def analyze_yolo_patch_pair(\n",
    "    clean_pil: Image.Image,\n",
    "    patched_pil: Image.Image,\n",
    "    yolo,\n",
    "    *,\n",
    "    imgsz: int = 640,\n",
    "    conf: float = 0.25,\n",
    "    iou_nms: float = 0.45,\n",
    "    match_iou: float = 0.5,\n",
    "    pre_conf: float = 0.001,\n",
    "    pre_max_det: int = 30000,\n",
    "    max_det: int = 300,\n",
    "    class_aware_nms: bool = True,\n",
    "    device: Optional[str] = None,\n",
    "    diff_thr: float = 0.08,\n",
    "    diff_min_pixels: int = 50,\n",
    "    enable_detect_feature_compare: bool = True,\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"Main entrypoint: returns a structured report with mechanisms.\"\"\"\n",
    "\n",
    "    # Patch bbox from diff\n",
    "    clean_t = pil_to_torch_rgb01(clean_pil)\n",
    "    patched_t = pil_to_torch_rgb01(patched_pil)\n",
    "    H, W = clean_t.shape[1], clean_t.shape[2]\n",
    "\n",
    "    patch_info = estimate_patch_region_from_diff(clean_t, patched_t, diff_thr=diff_thr, min_pixels=diff_min_pixels)\n",
    "    patch_bbox = patch_info[\"bbox_xyxy\"]\n",
    "    patch_area_ratio = float(patch_info[\"area_px\"]) / float(H * W)\n",
    "\n",
    "    # Ultralytics preprocess + raw + post\n",
    "    clean_pack = get_ultralytics_raw_preds_and_im(yolo, clean_pil, imgsz=imgsz, conf=conf, iou=iou_nms, device=device)\n",
    "    patched_pack = get_ultralytics_raw_preds_and_im(yolo, patched_pil, imgsz=imgsz, conf=conf, iou=iou_nms, device=device)\n",
    "    predictor = clean_pack[\"predictor\"]\n",
    "\n",
    "    clean_post = ultralytics_post_nms_from_raw(predictor, clean_pack[\"raw\"], clean_pack[\"im\"], clean_pack[\"orig_bgr\"])\n",
    "    patched_post = ultralytics_post_nms_from_raw(predictor, patched_pack[\"raw\"], patched_pack[\"im\"], patched_pack[\"orig_bgr\"])\n",
    "\n",
    "    # Candidates ≈ pre-NMS\n",
    "    nc = len(getattr(predictor.model, \"names\", getattr(yolo, \"names\", {}))) if hasattr(predictor, \"model\") else 0\n",
    "    end2end = bool(getattr(predictor.model, \"end2end\", False)) if hasattr(predictor, \"model\") else False\n",
    "\n",
    "    clean_cand_in = ultralytics_candidates_no_suppression(clean_pack[\"raw\"], conf_thres=pre_conf, max_det=pre_max_det, nc=nc, end2end=end2end)\n",
    "    patched_cand_in = ultralytics_candidates_no_suppression(patched_pack[\"raw\"], conf_thres=pre_conf, max_det=pre_max_det, nc=nc, end2end=end2end)\n",
    "\n",
    "    im_hw_clean = (int(clean_pack[\"im\"].shape[2]), int(clean_pack[\"im\"].shape[3]))\n",
    "    orig_hw_clean = (int(clean_pack[\"orig_bgr\"].shape[0]), int(clean_pack[\"orig_bgr\"].shape[1]))\n",
    "    im_hw_patched = (int(patched_pack[\"im\"].shape[2]), int(patched_pack[\"im\"].shape[3]))\n",
    "    orig_hw_patched = (int(patched_pack[\"orig_bgr\"].shape[0]), int(patched_pack[\"orig_bgr\"].shape[1]))\n",
    "\n",
    "    clean_cand = scale_boxes_to_original(clean_cand_in.clone(), im_hw_clean, orig_hw_clean) if clean_cand_in.numel() else clean_cand_in\n",
    "    patched_cand = scale_boxes_to_original(patched_cand_in.clone(), im_hw_patched, orig_hw_patched) if patched_cand_in.numel() else patched_cand_in\n",
    "\n",
    "    c_boxes, c_scores, c_cls = split_cand(clean_cand)\n",
    "    p_boxes, p_scores, p_cls = split_cand(patched_cand)\n",
    "\n",
    "    # NMS trace on patched candidates\n",
    "    kept_idx, nms_events = nms_with_trace(\n",
    "        p_boxes, p_scores, p_cls,\n",
    "        iou_thr=iou_nms,\n",
    "        class_aware=class_aware_nms,\n",
    "        max_det=max_det\n",
    "    )\n",
    "\n",
    "    # Match post-NMS clean vs patched\n",
    "    clean_post_boxes = clean_post[\"boxes\"]\n",
    "    patched_post_boxes = patched_post[\"boxes\"]\n",
    "    clean_post_labels = clean_post[\"labels\"]\n",
    "    patched_post_labels = patched_post[\"labels\"]\n",
    "\n",
    "    pairs = []\n",
    "    for lab in torch.unique(clean_post_labels).tolist():\n",
    "        idx_c = (clean_post_labels == lab).nonzero(as_tuple=True)[0]\n",
    "        idx_p = (patched_post_labels == lab).nonzero(as_tuple=True)[0]\n",
    "        if idx_c.numel() == 0 or idx_p.numel() == 0:\n",
    "            continue\n",
    "        sub = greedy_match_by_iou(clean_post_boxes[idx_c], patched_post_boxes[idx_p], iou_thr=match_iou)\n",
    "        for i, j, v in sub:\n",
    "            pairs.append((int(idx_c[i].item()), int(idx_p[j].item()), float(v)))\n",
    "    matched_clean = {i for i, _, _ in pairs}\n",
    "\n",
    "    # Build suppression map for quick lookup\n",
    "    suppressed_by = {ev.suppressed_idx: ev for ev in nms_events}\n",
    "\n",
    "    def best_candidate_for_target(target_box: torch.Tensor, target_cls: int) -> Dict[str, Any]:\n",
    "        if p_boxes.numel() == 0:\n",
    "            return {\"idx\": None, \"iou\": 0.0, \"score\": 0.0}\n",
    "        mask_cls = (p_cls == target_cls)\n",
    "        if mask_cls.sum() == 0:\n",
    "            return {\"idx\": None, \"iou\": 0.0, \"score\": 0.0}\n",
    "        ious = box_iou_xyxy(target_box[None, :], p_boxes[mask_cls]).squeeze(0)\n",
    "        best_local = int(torch.argmax(ious).item())\n",
    "        best_iou = float(ious[best_local].item())\n",
    "        global_idx = int(mask_cls.nonzero(as_tuple=True)[0][best_local].item())\n",
    "        return {\"idx\": global_idx, \"iou\": best_iou, \"score\": float(p_scores[global_idx].item())}\n",
    "\n",
    "    diagnoses: List[TargetDiagnosis] = []\n",
    "\n",
    "    for i in range(clean_post_boxes.shape[0]):\n",
    "        box = clean_post_boxes[i]\n",
    "        lab = int(clean_post_labels[i].item())\n",
    "        sc = float(clean_post[\"scores\"][i].item())\n",
    "\n",
    "        if i in matched_clean:\n",
    "            diagnoses.append(TargetDiagnosis(\n",
    "                clean_idx=i,\n",
    "                clean_label=lab,\n",
    "                clean_score=sc,\n",
    "                status=\"matched\",\n",
    "                diagnosis=\"kept_after_patch\",\n",
    "                evidence={\"match_pairs\": [p for p in pairs if p[0] == i]}\n",
    "            ))\n",
    "            continue\n",
    "\n",
    "        # Missing in patched post-NMS\n",
    "        cand = best_candidate_for_target(box, lab)\n",
    "\n",
    "        patch_iou = None\n",
    "        if patch_bbox is not None:\n",
    "            patch_iou = float(box_iou_xyxy(patch_bbox[None, :], box[None, :]).item())\n",
    "\n",
    "        if cand[\"idx\"] is None or cand[\"iou\"] < 0.05:\n",
    "            diagnoses.append(TargetDiagnosis(\n",
    "                clean_idx=i,\n",
    "                clean_label=lab,\n",
    "                clean_score=sc,\n",
    "                status=\"missing\",\n",
    "                diagnosis=\"no_preNMS_candidate_near_target\",\n",
    "                evidence={\n",
    "                    \"best_candidate\": cand,\n",
    "                    \"patch_iou_with_target\": patch_iou,\n",
    "                    \"hint\": \"Likely feature/objectness suppression OR localization collapse.\"\n",
    "                }\n",
    "            ))\n",
    "            continue\n",
    "\n",
    "        if cand[\"score\"] < conf:\n",
    "            diagnoses.append(TargetDiagnosis(\n",
    "                clean_idx=i,\n",
    "                clean_label=lab,\n",
    "                clean_score=sc,\n",
    "                status=\"missing\",\n",
    "                diagnosis=\"score_below_threshold\",\n",
    "                evidence={\n",
    "                    \"best_candidate\": cand,\n",
    "                    \"conf_threshold\": conf,\n",
    "                    \"patch_iou_with_target\": patch_iou,\n",
    "                    \"hint\": \"Candidate exists but score suppressed below threshold.\"\n",
    "                }\n",
    "            ))\n",
    "            continue\n",
    "\n",
    "        if cand[\"idx\"] in suppressed_by:\n",
    "            ev = suppressed_by[cand[\"idx\"]]\n",
    "            kept_box = p_boxes[ev.kept_idx]\n",
    "            kept_center = ((kept_box[:2] + kept_box[2:]) / 2.0)\n",
    "            kept_in_patch = False\n",
    "            if patch_bbox is not None:\n",
    "                kept_in_patch = bool(\n",
    "                    (kept_center[0] >= patch_bbox[0]) and (kept_center[0] <= patch_bbox[2]) and\n",
    "                    (kept_center[1] >= patch_bbox[1]) and (kept_center[1] <= patch_bbox[3])\n",
    "                )\n",
    "            diagnoses.append(TargetDiagnosis(\n",
    "                clean_idx=i,\n",
    "                clean_label=lab,\n",
    "                clean_score=sc,\n",
    "                status=\"missing\",\n",
    "                diagnosis=\"nms_suppressed_by_competitor\",\n",
    "                evidence={\n",
    "                    \"best_candidate\": cand,\n",
    "                    \"suppressed_event\": {\n",
    "                        \"kept_idx\": ev.kept_idx,\n",
    "                        \"kept_score\": ev.kept_score,\n",
    "                        \"kept_cls\": ev.kept_cls,\n",
    "                        \"iou\": ev.iou,\n",
    "                        \"kept_in_patch_bbox\": kept_in_patch,\n",
    "                    },\n",
    "                    \"patch_iou_with_target\": patch_iou,\n",
    "                    \"hint\": \"NMS failure: overlapping higher-score box suppressed target.\"\n",
    "                }\n",
    "            ))\n",
    "            continue\n",
    "\n",
    "        diagnoses.append(TargetDiagnosis(\n",
    "            clean_idx=i,\n",
    "            clean_label=lab,\n",
    "            clean_score=sc,\n",
    "            status=\"missing\",\n",
    "            diagnosis=\"candidate_exists_but_not_in_final_output\",\n",
    "            evidence={\n",
    "                \"best_candidate\": cand,\n",
    "                \"patch_iou_with_target\": patch_iou,\n",
    "                \"hint\": \"Check bbox drift / class drift / Ultralytics-NMS vs traced-NMS differences.\"\n",
    "            }\n",
    "        ))\n",
    "\n",
    "    # Feature similarity\n",
    "    feat_sim: Dict[str, Any] = {}\n",
    "    if enable_detect_feature_compare:\n",
    "        torch_model = getattr(yolo, \"model\", None)\n",
    "        if isinstance(torch_model, torch.nn.Module):\n",
    "            _, snap_clean = capture_detect_inputs_during_forward(torch_model, clean_pack[\"im\"])\n",
    "            _, snap_patch = capture_detect_inputs_during_forward(torch_model, patched_pack[\"im\"])\n",
    "\n",
    "            if clean_post[\"scores\"].numel() > 0 and snap_clean.feat_maps and snap_patch.feat_maps:\n",
    "                tgt_idx = int(torch.argmax(clean_post[\"scores\"]).item())\n",
    "                tgt_box = clean_post[\"boxes\"][tgt_idx].detach().cpu().to(torch.float32)\n",
    "                img_hw = (H, W)\n",
    "\n",
    "                sims_obj = []\n",
    "                for k in range(min(len(snap_clean.feat_maps), len(snap_patch.feat_maps))):\n",
    "                    sims_obj.append(region_cosine_similarity_on_featmap(\n",
    "                        snap_clean.feat_maps[k], snap_patch.feat_maps[k], tgt_box, img_hw\n",
    "                    ))\n",
    "                feat_sim[\"object_roi\"] = {\"target_clean_post_idx\": tgt_idx, \"cosine_per_scale\": sims_obj}\n",
    "\n",
    "                if patch_bbox is not None:\n",
    "                    pb = patch_bbox.detach().cpu().to(torch.float32)\n",
    "                    sims_patch = []\n",
    "                    for k in range(min(len(snap_clean.feat_maps), len(snap_patch.feat_maps))):\n",
    "                        sims_patch.append(region_cosine_similarity_on_featmap(\n",
    "                            snap_clean.feat_maps[k], snap_patch.feat_maps[k], pb, img_hw\n",
    "                        ))\n",
    "                    feat_sim[\"patch_roi\"] = {\"cosine_per_scale\": sims_patch}\n",
    "            else:\n",
    "                feat_sim[\"note\"] = \"Detect inputs not captured or no clean detections.\"\n",
    "        else:\n",
    "            feat_sim[\"note\"] = \"Non-torch backend; feature hooks unavailable.\"\n",
    "\n",
    "    # Lure stats: how much top-K is inside patch\n",
    "    lure_stats = {}\n",
    "    if patch_bbox is not None and p_boxes.numel() > 0:\n",
    "        centers = (p_boxes[:, :2] + p_boxes[:, 2:]) / 2.0\n",
    "        in_patch = (\n",
    "            (centers[:, 0] >= patch_bbox[0]) & (centers[:, 0] <= patch_bbox[2]) &\n",
    "            (centers[:, 1] >= patch_bbox[1]) & (centers[:, 1] <= patch_bbox[3])\n",
    "        )\n",
    "        K = min(500, int(p_scores.numel()))\n",
    "        topk = torch.topk(p_scores, k=K).indices\n",
    "        lure_stats = {\n",
    "            \"patch_bbox\": patch_bbox.tolist(),\n",
    "            \"topK\": K,\n",
    "            \"frac_topK_centers_in_patch\": float(in_patch[topk].float().mean().item()) if K > 0 else 0.0,\n",
    "            \"max_score_in_patch\": float(p_scores[in_patch].max().item()) if in_patch.any() else 0.0,\n",
    "            \"num_candidates_total\": int(p_scores.numel()),\n",
    "            \"num_candidates_in_patch\": int(in_patch.sum().item()),\n",
    "        }\n",
    "\n",
    "    return {\n",
    "        \"patch_info\": {**patch_info, \"patch_area_ratio\": patch_area_ratio, \"patch_bbox_xyxy\": patch_bbox.tolist() if patch_bbox is not None else None},\n",
    "        \"clean_post\": {\"boxes\": clean_post[\"boxes\"], \"scores\": clean_post[\"scores\"], \"labels\": clean_post[\"labels\"]},\n",
    "        \"patched_post\": {\"boxes\": patched_post[\"boxes\"], \"scores\": patched_post[\"scores\"], \"labels\": patched_post[\"labels\"]},\n",
    "        \"clean_candidates\": {\"boxes\": c_boxes, \"scores\": c_scores, \"labels\": c_cls},\n",
    "        \"patched_candidates\": {\"boxes\": p_boxes, \"scores\": p_scores, \"labels\": p_cls},\n",
    "        \"patched_nms_trace\": {\"kept_indices\": kept_idx, \"events\": nms_events},\n",
    "        \"match_pairs_post\": pairs,\n",
    "        \"diagnoses\": diagnoses,\n",
    "        \"feature_similarity\": feat_sim,\n",
    "        \"lure_stats\": lure_stats,\n",
    "    }\n",
    "\n",
    "\n",
    "def pretty_print_diagnosis(report: Dict[str, Any], max_items: int = 30) -> None:\n",
    "    print(\"=== Patch region ===\")\n",
    "    pi = report[\"patch_info\"]\n",
    "    print(f\"bbox={pi['patch_bbox_xyxy']}  area_ratio={pi['patch_area_ratio']:.6f}  area_px={pi['area_px']}\")\n",
    "    print()\n",
    "\n",
    "    cp = report[\"clean_post\"]\n",
    "    pp = report[\"patched_post\"]\n",
    "    print(\"=== Post-NMS counts ===\")\n",
    "    print(f\"clean: {int(cp['boxes'].shape[0])}  patched: {int(pp['boxes'].shape[0])}\")\n",
    "    print()\n",
    "\n",
    "    print(\"=== Lure stats (patched candidates) ===\")\n",
    "    print(report.get(\"lure_stats\", {}))\n",
    "    print()\n",
    "\n",
    "    print(\"=== Feature similarity (Detect inputs) ===\")\n",
    "    print(report.get(\"feature_similarity\", {}))\n",
    "    print()\n",
    "\n",
    "    print(\"=== Per-target diagnosis (clean post-NMS objects) ===\")\n",
    "    for d in report[\"diagnoses\"][:max_items]:\n",
    "        print(f\"- clean#{d.clean_idx} cls={d.clean_label} score={d.clean_score:.3f} status={d.status} diagnosis={d.diagnosis}\")\n",
    "        ev = d.evidence\n",
    "        if \"best_candidate\" in ev:\n",
    "            bc = ev[\"best_candidate\"]\n",
    "            print(f\"    best_candidate: idx={bc.get('idx')} iou={bc.get('iou'):.3f} score={bc.get('score'):.3f}\")\n",
    "        if \"suppressed_event\" in ev:\n",
    "            se = ev[\"suppressed_event\"]\n",
    "            print(f\"    suppressed_by: kept_idx={se['kept_idx']} kept_score={se['kept_score']:.3f} iou={se['iou']:.3f} kept_in_patch={se['kept_in_patch_bbox']}\")\n",
    "        if \"patch_iou_with_target\" in ev and ev[\"patch_iou_with_target\"] is not None:\n",
    "            print(f\"    IoU(patch,target)={ev['patch_iou_with_target']:.3f}\")\n",
    "        if \"hint\" in ev:\n",
    "            print(f\"    hint: {ev['hint']}\")\n",
    "\n",
    "    if len(report[\"diagnoses\"]) > max_items:\n",
    "        print(f\"... ({len(report['diagnoses']) - max_items} more)\")"
   ],
   "id": "758602478e0153c3",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Эксперименты",
   "id": "c26d3ab42ebb594"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "yolo = load_ultralytics_yolo(\"yolo11s.pt\")\n",
    "clean_pil = Image.open(\"data/person_012_patched_lu.png\")\n",
    "patched_pil = Image.open(\"patched.jpg\")\n",
    "\n",
    "report = analyze_yolo_patch_pair(\n",
    "    clean_pil, patched_pil, yolo,\n",
    "    imgsz=640,\n",
    "    conf=0.25,\n",
    "    iou_nms=0.45,\n",
    "    match_iou=0.5,\n",
    "    pre_conf=0.001,\n",
    "    pre_max_det=30000,\n",
    "    max_det=300,\n",
    "    class_aware_nms=True,\n",
    "    device=None,\n",
    "    enable_detect_feature_compare=True,\n",
    ")\n",
    "\n",
    "pretty_print_diagnosis(report)\n",
    "\n",
    "patch_vis = estimate_patch_region_from_diff(pil_to_torch_rgb01(clean_pil), pil_to_torch_rgb01(patched_pil))\n",
    "show_patch_diff(pil_to_torch_rgb01(clean_pil), pil_to_torch_rgb01(patched_pil), patch_vis)"
   ],
   "id": "50f9ac71a6146de9"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
