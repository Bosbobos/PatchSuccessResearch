{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Написанные человеком и проверенные эксперименты",
   "id": "9a9b2c4b62bd9ce8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Вспомогательные функции",
   "id": "b64a1ce25957b5e6"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import Any, Dict, List, Optional, Tuple\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Image conversions\n",
    "# -------------------------\n",
    "\n",
    "def pil_to_np_bgr(pil: Image.Image) -> np.ndarray:\n",
    "    \"\"\"PIL RGB -> np.uint8 BGR (H,W,3) for ultralytics predictor preprocess.\"\"\"\n",
    "    if pil.mode != \"RGB\":\n",
    "        pil = pil.convert(\"RGB\")\n",
    "    rgb = np.asarray(pil)  # uint8 RGB\n",
    "    bgr = rgb[..., ::-1].copy()\n",
    "    return bgr\n",
    "\n",
    "\n",
    "def pil_to_torch_rgb01(pil: Image.Image) -> torch.Tensor:\n",
    "    \"\"\"PIL -> torch float32 RGB in [0,1], shape [3,H,W] (CPU).\"\"\"\n",
    "    if pil.mode != \"RGB\":\n",
    "        pil = pil.convert(\"RGB\")\n",
    "    arr = np.asarray(pil).astype(np.float32) / 255.0\n",
    "    t = torch.from_numpy(arr).permute(2, 0, 1).contiguous()\n",
    "    return t\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Patch application\n",
    "# -------------------------\n",
    "\n",
    "def apply_patch_to_image(\n",
    "    base_pil: Image.Image,\n",
    "    patch_pil: Image.Image,\n",
    "    position_xy: Tuple[int, int] = (0, 0),\n",
    ") -> Tuple[Image.Image, Optional[torch.Tensor], int]:\n",
    "    \"\"\"Paste patch onto base image at (x,y). Returns patched PIL, bbox_xyxy, area_px.\"\"\"\n",
    "    if base_pil.mode != \"RGB\":\n",
    "        base_pil = base_pil.convert(\"RGB\")\n",
    "    if patch_pil.mode != \"RGB\":\n",
    "        patch_pil = patch_pil.convert(\"RGB\")\n",
    "    base_w, base_h = base_pil.size\n",
    "    patch_w, patch_h = patch_pil.size\n",
    "    x, y = position_xy\n",
    "    x1 = max(0, int(x))\n",
    "    y1 = max(0, int(y))\n",
    "    x2 = min(base_w, int(x) + patch_w)\n",
    "    y2 = min(base_h, int(y) + patch_h)\n",
    "    if x2 <= x1 or y2 <= y1:\n",
    "        return base_pil.copy(), None, 0\n",
    "    # Crop patch if it spills outside the base image.\n",
    "    px1 = x1 - int(x)\n",
    "    py1 = y1 - int(y)\n",
    "    px2 = px1 + (x2 - x1)\n",
    "    py2 = py1 + (y2 - y1)\n",
    "    patch_crop = patch_pil.crop((px1, py1, px2, py2))\n",
    "    out = base_pil.copy()\n",
    "    out.paste(patch_crop, (x1, y1))\n",
    "    bbox = torch.tensor([float(x1), float(y1), float(x2), float(y2)], dtype=torch.float32)\n",
    "    area = int((x2 - x1) * (y2 - y1))\n",
    "    return out, bbox, area\n",
    "\n",
    "\n",
    "def letterbox_pil(pil: Image.Image, imgsz: int, color: Tuple[int, int, int] = (114, 114, 114)) -> Image.Image:\n",
    "    \"\"\"Resize+pad image to square imgsz, matching Ultralytics letterbox behavior.\"\"\"\n",
    "    if pil.mode != \"RGB\":\n",
    "        pil = pil.convert(\"RGB\")\n",
    "    w, h = pil.size\n",
    "    r = min(imgsz / h, imgsz / w)\n",
    "    new_w = int(round(w * r))\n",
    "    new_h = int(round(h * r))\n",
    "    resized = pil.resize((new_w, new_h), Image.BILINEAR)\n",
    "    out = Image.new(\"RGB\", (imgsz, imgsz), color)\n",
    "    pad_w = int((imgsz - new_w) / 2)\n",
    "    pad_h = int((imgsz - new_h) / 2)\n",
    "    out.paste(resized, (pad_w, pad_h))\n",
    "    return out\n",
    "\n",
    "from pathlib import Path\n",
    "import random\n",
    "from typing import List\n",
    "\n",
    "\n",
    "def collect_images(\n",
    "    folder: Path,\n",
    "    n: int,\n",
    "    extensions: tuple[str, ...] = (\".png\", \".jpg\", \".jpeg\"),\n",
    "    shuffle: bool = False,\n",
    "    seed: int | None = 42,\n",
    ") -> List[str]:\n",
    "    \"\"\"\n",
    "    Берёт n изображений из папки.\n",
    "    Если shuffle=True — случайная выборка (с фиксируемым seed).\n",
    "    \"\"\"\n",
    "    files = [\n",
    "        p for p in folder.iterdir()\n",
    "        if p.is_file() and p.suffix.lower() in extensions\n",
    "    ]\n",
    "\n",
    "    if not files:\n",
    "        raise RuntimeError(f\"В папке {folder} нет изображений\")\n",
    "\n",
    "    if shuffle:\n",
    "        if seed is not None:\n",
    "            random.seed(seed)\n",
    "        random.shuffle(files)\n",
    "\n",
    "    return [str(p) for p in files[:n]]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def _load_ultralytics_yolo(model_path: str):\n",
    "    try:\n",
    "        from ultralytics import YOLO\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(\n",
    "            \"Не удалось импортировать ultralytics. Установите пакет ultralytics или убедитесь, что среда активна.\"\n",
    "        ) from e\n",
    "    return YOLO(model_path)\n",
    "\n",
    "\n",
    "def _get_class_id_from_names(names: Dict[int, str], class_name: str) -> Optional[int]:\n",
    "    class_name = class_name.lower().strip()\n",
    "    for k, v in names.items():\n",
    "        if str(v).lower().strip() == class_name:\n",
    "            return int(k)\n",
    "    return None\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def yolo_predict_conf_scalar(\n",
    "    yolo_model,\n",
    "    pil_img: Image.Image,\n",
    "    imgsz: int,\n",
    "    target_class_id: Optional[int],\n",
    "    conf: float = 0.001,\n",
    ") -> Tuple[float, Any]:\n",
    "    \"\"\"Ultralytics predict -> scalar confidence (NMS-based) + raw Results.\"\"\"\n",
    "    bgr = pil_to_np_bgr(pil_img)\n",
    "    res = yolo_model.predict(source=bgr, imgsz=imgsz, conf=conf, verbose=False)[0]\n",
    "\n",
    "    if res.boxes is None or len(res.boxes) == 0:\n",
    "        return 0.0, res\n",
    "\n",
    "    confs = res.boxes.conf.detach().cpu().numpy()\n",
    "    clss = res.boxes.cls.detach().cpu().numpy().astype(int)\n",
    "\n",
    "    if target_class_id is None:\n",
    "        return float(confs.max(initial=0.0)), res\n",
    "\n",
    "    mask = (clss == int(target_class_id))\n",
    "    if not np.any(mask):\n",
    "        return 0.0, res\n",
    "\n",
    "    return float(confs[mask].max(initial=0.0)), res"
   ],
   "id": "76c39b776d013a90",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def build_clean_and_patched_letterboxed(\n",
    "    base_pil: Image.Image,\n",
    "    patch_pil: Image.Image,\n",
    "    cfg: ExpConfig,\n",
    ") -> Tuple[Image.Image, Image.Image, Optional[torch.Tensor]]:\n",
    "    clean_lb = letterbox_pil(base_pil, imgsz=cfg.imgsz)\n",
    "\n",
    "    if cfg.apply_patch_after_letterbox:\n",
    "        patched_lb, bbox, _ = apply_patch_to_image(clean_lb, patch_pil, cfg.patch_xy)\n",
    "        return clean_lb, patched_lb, bbox\n",
    "\n",
    "    patched_orig, _bbox_orig, _ = apply_patch_to_image(base_pil, patch_pil, cfg.patch_xy)\n",
    "    patched_lb = letterbox_pil(patched_orig, imgsz=cfg.imgsz)\n",
    "    return clean_lb, patched_lb, None\n",
    "\n",
    "def pick_center_person_bbox_from_results(\n",
    "    res,\n",
    "    target_class_id: int,\n",
    "    imgsz: int,\n",
    "    strategy: str = \"score\",\n",
    "    min_conf: float = 0.10,\n",
    "    min_area_frac: float = 0.01,\n",
    "    ar_range: Tuple[float, float] = (0.15, 1.20),\n",
    "    w_conf: float = 1.0,\n",
    "    w_area: float = 0.6,\n",
    "    w_dist: float = 0.4,\n",
    "    w_ar: float = 0.2,\n",
    "):\n",
    "    \"\"\"Pick the most plausible 'person' bbox from YOLO post-NMS detections.\n",
    "\n",
    "    Why this exists:\n",
    "      Center-closest can pick tiny false positives near center.\n",
    "\n",
    "    Strategies:\n",
    "      - 'center' : legacy center-closest (kept for debugging)\n",
    "      - 'conf'   : highest confidence (tie-breaker by area)\n",
    "      - 'area'   : largest area (tie-breaker by confidence)\n",
    "      - 'score'  : weighted score combining confidence, area, center-distance and aspect-ratio prior\n",
    "\n",
    "    Returns dict: {picked_bbox: [x1,y1,x2,y2], picked_conf: float, picked_idx: int}\n",
    "    or {} if no person found.\n",
    "    \"\"\"\n",
    "    if res is None or getattr(res, \"boxes\", None) is None or len(res.boxes) == 0:\n",
    "        return {}\n",
    "\n",
    "    xyxy = res.boxes.xyxy.detach().cpu().numpy()          # (N,4)\n",
    "    conf = res.boxes.conf.detach().cpu().numpy()          # (N,)\n",
    "    cls  = res.boxes.cls.detach().cpu().numpy().astype(int)  # (N,)\n",
    "\n",
    "    m = (cls == int(target_class_id))\n",
    "    if not np.any(m):\n",
    "        return {}\n",
    "\n",
    "    idxs = np.flatnonzero(m)\n",
    "    xyxy_p = xyxy[m]\n",
    "    conf_p = conf[m]\n",
    "\n",
    "        # geometry\n",
    "    w = (xyxy_p[:, 2] - xyxy_p[:, 0]).clip(min=0.0)\n",
    "    h = (xyxy_p[:, 3] - xyxy_p[:, 1]).clip(min=0.0)\n",
    "    area = w * h\n",
    "\n",
    "    # basic filtering to avoid tiny garbage boxes\n",
    "    min_area = float(min_area_frac) * float(imgsz) * float(imgsz)\n",
    "    keep = (conf_p >= float(min_conf)) & (area >= min_area)\n",
    "\n",
    "    # aspect-ratio prior for a person box in full-body-ish imagery (very loose)\n",
    "    ar = w / (h + 1e-9)  # width/height\n",
    "    keep = keep & (ar >= float(ar_range[0])) & (ar <= float(ar_range[1]))\n",
    "\n",
    "    if not np.any(keep):\n",
    "        # Fallback: just keep the best-conf person (even if small)\n",
    "        j = int(np.argmax(conf_p))\n",
    "        picked_idx = int(idxs[j])\n",
    "        return {\n",
    "            \"picked_bbox\": [float(v) for v in xyxy_p[j].tolist()],\n",
    "            \"picked_conf\": float(conf_p[j]),\n",
    "            \"picked_idx\": picked_idx,\n",
    "        }\n",
    "\n",
    "    xyxy_p = xyxy_p[keep]\n",
    "    conf_p = conf_p[keep]\n",
    "    area = area[keep]\n",
    "    ar = ar[keep]\n",
    "    idxs = idxs[keep]\n",
    "\n",
    "    # center distance (normalized)\n",
    "\n",
    "    cx = 0.5 * (xyxy_p[:, 0] + xyxy_p[:, 2])\n",
    "    cy = 0.5 * (xyxy_p[:, 1] + xyxy_p[:, 3])\n",
    "    dx = (cx - (float(imgsz) * 0.5)) / float(imgsz)\n",
    "    dy = (cy - (float(imgsz) * 0.5)) / float(imgsz)\n",
    "    dist = np.sqrt(dx * dx + dy * dy)  # 0..~0.7\n",
    "\n",
    "    strategy = str(strategy).lower().strip()\n",
    "\n",
    "    if strategy == \"center\":\n",
    "        j = int(np.argmin(dist))\n",
    "    elif strategy == \"conf\":\n",
    "        # tie-breaker: larger area\n",
    "        j = int(np.lexsort((-area, -conf_p))[-1])\n",
    "\n",
    "    elif strategy == \"area\":\n",
    "        # tie-breaker: higher conf\n",
    "        j = int(np.lexsort((-conf_p, -area))[-1])\n",
    "\n",
    "    elif strategy == \"score\":\n",
    "        # normalize area to [0,1] by image area; then compress with sqrt to reduce dominance\n",
    "        area_n = np.sqrt(area / (float(imgsz) * float(imgsz) + 1e-9))\n",
    "\n",
    "        # aspect ratio prior: prefer tall-ish boxes (smaller ar). Use a soft penalty around ar~0.5\n",
    "        # penalty in [0,1], 0 best.\n",
    "        ar_target = 0.55\n",
    "        ar_pen = np.clip(np.abs(ar - ar_target) / 0.65, 0.0, 1.0)\n",
    "\n",
    "        # score: higher is better\n",
    "        score = (\n",
    "            float(w_conf) * conf_p\n",
    "            + float(w_area) * area_n\n",
    "            - float(w_dist) * dist\n",
    "            - float(w_ar) * ar_pen\n",
    "        )\n",
    "        j = int(np.argmax(score))\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown strategy='{strategy}'\")\n",
    "\n",
    "    picked_idx = int(idxs[j])\n",
    "\n",
    "    return {\n",
    "        \"picked_bbox\": [float(v) for v in xyxy_p[j].tolist()],\n",
    "        \"picked_conf\": float(conf_p[j]),\n",
    "        \"picked_idx\": picked_idx,\n",
    "    }"
   ],
   "id": "d6b91a8034ca626d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Параметры экспериментов",
   "id": "37095b20c3646804"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# We do NOT trust folder labels fully; we will oversample from folders and then\n",
    "# select a balanced set by the *computed* success flag (drop > CFG.success_thresh).\n",
    "N_FROM_EACH_DIR = 150   # how many files to pull from each folder initially\n",
    "N_SUCCESS = 100         # how many SUCCESS examples to keep after labeling\n",
    "N_FAIL = 100            # how many FAIL examples to keep after labeling\n",
    "SEED = 17\n",
    "\n",
    "# successful_dir = Path(\"../stats/attack_split/success\")\n",
    "# unsuccessful_dir = Path(\"../stats/attack_split/fail\")\n",
    "\n",
    "successful_dir = Path(\"successful_examples\")\n",
    "unsuccessful_dir = Path(\"unsuccessful_examples\")\n",
    "\n",
    "image_paths = (\n",
    "    collect_images(successful_dir, N_FROM_EACH_DIR, shuffle=True, seed=SEED)\n",
    "    + collect_images(unsuccessful_dir, N_FROM_EACH_DIR, shuffle=True, seed=SEED)\n",
    ")\n",
    "patch_path = \"data/patch.png\""
   ],
   "id": "f131fa9340722cf4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "@dataclass\n",
    "class ExpConfig:\n",
    "    # путь к весам (можно заменить на локальный)\n",
    "    model_path: str = \"yolo11s.pt\"\n",
    "\n",
    "    # размер входа\n",
    "    imgsz: int = 640\n",
    "\n",
    "    # устройство\n",
    "    device: str = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.mps.is_available() else \"cpu\"\n",
    "\n",
    "    # True: накладываем патч уже на letterbox-изображение (самый честный режим)\n",
    "    # False: накладываем на оригинал, потом делаем letterbox\n",
    "    apply_patch_after_letterbox: bool = True\n",
    "\n",
    "    # позиция патча (x,y) в координатах того изображения, куда накладываем\n",
    "    patch_xy: Tuple[int, int] = (0, 0)\n",
    "\n",
    "    # целевой класс (None => берём max по всем классам)\n",
    "    target_class_name: Optional[str] = \"person\"\n",
    "\n",
    "    # успех атаки: падение скаляра уверенности >= threshold\n",
    "    success_thresh: float = 0.30\n",
    "\n",
    "    # число каналов, используемое в top-k метриках и в абляциях\n",
    "    topk_channels: int = 32\n",
    "\n",
    "    # ROI scalar reduction for attribution: \"max\" | \"logsumexp\" | \"topk_mean\"\n",
    "    roi_reduce: str = \"logsumexp\"\n",
    "\n",
    "    # temperature for logsumexp (larger -> closer to max)\n",
    "    roi_lse_temp: float = 20.0\n",
    "\n",
    "    # k for topk_mean\n",
    "    roi_topk: int = 10\n",
    "\n",
    "    # --- ROI attribution layer selection ---\n",
    "    # How many layers to keep for ROI-attribution (set 1 to mimic the previous \"single good layer\" behavior)\n",
    "    roi_keep_topk_layers: int = 1\n",
    "\n",
    "    # How many near-head conv layers to consider as candidates\n",
    "    roi_candidate_last_n_layers: int = 8\n",
    "\n",
    "    # How many examples from each group (success/fail) to use for scanning grad signal\n",
    "    roi_scan_n_per_group: int = 2\n",
    "\n",
    "    # Minimum median ma_abs.max required to accept a layer (0.0 keeps the best even if tiny)\n",
    "    roi_min_grad_strength: float = 0.0\n",
    "\n",
    "CFG = ExpConfig()"
   ],
   "id": "84112a950b4cf034",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Подсчет разности фич между атакованным и чистым примерами\n",
    "\n",
    "Берем хуками выходы предпоследних слоев модели и считаем:\n",
    "- `F_l(clean)` и `F_l(patched)` для набора слоёв `l`\n",
    "- `Δ_l = F_l(patched) - F_l(clean)`"
   ],
   "id": "727eb50011a80231"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "def pick_default_conv_layers(model_torch: nn.Module, n_layers: int = 12) -> List[str]:\n",
    "    convs: List[str] = []\n",
    "    for n, m in model_torch.named_modules():\n",
    "        if isinstance(m, nn.Conv2d):\n",
    "            convs.append(n)\n",
    "    if not convs:\n",
    "        raise RuntimeError(\"Не удалось найти Conv2d модули в модели.\")\n",
    "\n",
    "    idxs = np.linspace(0, len(convs) - 1, num=min(n_layers, len(convs))).round().astype(int)\n",
    "    picked = []\n",
    "    seen = set()\n",
    "    for i in idxs:\n",
    "        name = convs[int(i)]\n",
    "        if name not in seen:\n",
    "            picked.append(name)\n",
    "            seen.add(name)\n",
    "    return picked\n",
    "\n",
    "\n",
    "def get_module_by_name(model_torch: nn.Module, name: str) -> nn.Module:\n",
    "    d = dict(model_torch.named_modules())\n",
    "    if name not in d:\n",
    "        raise KeyError(f\"Layer '{name}' not found.\")\n",
    "    return d[name]\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def torch_preprocess_letterboxed(pil_img_lb: Image.Image, device: str, dtype: torch.dtype) -> torch.Tensor:\n",
    "    \"\"\"Preprocess PIL -> BCHW tensor on the requested device/dtype.\"\"\"\n",
    "    t = pil_to_torch_rgb01(pil_img_lb)  # CPU float32 [3,H,W]\n",
    "    t = t.unsqueeze(0)  # [1,3,H,W]\n",
    "    return t.to(device=device, dtype=dtype, non_blocking=False)\n",
    "\n",
    "\n",
    "def capture_activations_for_layers(\n",
    "    model_torch: nn.Module,\n",
    "    x_bchw: torch.Tensor,\n",
    "    layer_names: List[str],\n",
    ") -> Dict[str, torch.Tensor]:\n",
    "    acts: Dict[str, torch.Tensor] = {}\n",
    "    hooks = []\n",
    "\n",
    "    def _mk_hook(name: str):\n",
    "        def _hook(_m, _inp, out):\n",
    "            # Some Ultralytics blocks can emit tuples/lists; take the first tensor.\n",
    "            if isinstance(out, (list, tuple)):\n",
    "                for o in out:\n",
    "                    if isinstance(o, torch.Tensor):\n",
    "                        out = o\n",
    "                        break\n",
    "\n",
    "            # We focus on spatial feature maps (B,C,H,W). Skip others.\n",
    "            if isinstance(out, torch.Tensor) and out.ndim == 4:\n",
    "                acts[name] = out.detach().cpu()\n",
    "        return _hook\n",
    "\n",
    "    for ln in layer_names:\n",
    "        m = get_module_by_name(model_torch, ln)\n",
    "        hooks.append(m.register_forward_hook(_mk_hook(ln)))\n",
    "    # MPS requires input and weights to share device AND dtype.\n",
    "    x_bchw = x_bchw.to(\n",
    "        device=next(model_torch.parameters()).device,\n",
    "        dtype=next(model_torch.parameters()).dtype,\n",
    "    )\n",
    "\n",
    "\n",
    "    _ = model_torch(x_bchw)\n",
    "\n",
    "    for h in hooks:\n",
    "        h.remove()\n",
    "\n",
    "    return acts\n",
    "\n",
    "def _top_level_model_index(name: str) -> Optional[int]:\n",
    "    \"\"\"Parse 'model.<idx>....' -> idx. Returns None if not matching.\"\"\"\n",
    "    if not name.startswith(\"model.\"):\n",
    "        return None\n",
    "    parts = name.split(\".\")\n",
    "    if len(parts) < 2:\n",
    "        return None\n",
    "    try:\n",
    "        return int(parts[1])\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "\n",
    "def find_head_start_index(model_torch: nn.Module) -> int:\n",
    "    \"\"\"Heuristically find the first top-level model.<idx> belonging to the head.\"\"\"\n",
    "    head_class_names = {\n",
    "        \"Detect\", \"Segment\", \"Pose\", \"OBB\", \"Classify\", \"RTDETRDecoder\", \"WorldDetect\",\n",
    "    }\n",
    "\n",
    "    best_idx: Optional[int] = None\n",
    "\n",
    "    # 1) Prefer class-name detection\n",
    "    for n, m in model_torch.named_modules():\n",
    "        if m.__class__.__name__ in head_class_names:\n",
    "            idx = _top_level_model_index(n)\n",
    "            if idx is not None:\n",
    "                best_idx = idx if best_idx is None else min(best_idx, idx)\n",
    "\n",
    "    # 2) Fallback: name heuristics\n",
    "    if best_idx is None:\n",
    "        for n, _m in model_torch.named_modules():\n",
    "            nnm = n.lower()\n",
    "            if (\"dfl\" in nnm) or (\"detect\" in nnm) or (\"decoder\" in nnm):\n",
    "                idx = _top_level_model_index(n)\n",
    "                if idx is not None:\n",
    "                    best_idx = idx if best_idx is None else min(best_idx, idx)\n",
    "\n",
    "    # 3) If still unknown: treat everything as pre-head\n",
    "    if best_idx is None:\n",
    "        top_idxs = []\n",
    "        for n, _m in model_torch.named_modules():\n",
    "            idx = _top_level_model_index(n)\n",
    "            if idx is not None:\n",
    "                top_idxs.append(idx)\n",
    "        return max(top_idxs) if top_idxs else 10**9\n",
    "\n",
    "    return int(best_idx)"
   ],
   "id": "b9f48b075869e3ad",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Запуск и подсчет нужных метрик по слоям",
   "id": "f538450f242f7d4d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# load model\n",
    "\n",
    "yolo = _load_ultralytics_yolo(CFG.model_path)\n",
    "\n",
    "# Put Ultralytics wrapper AND underlying torch module on the same device.\n",
    "# On Apple Silicon, this ensures weights are moved to MPS as well.\n",
    "try:\n",
    "    yolo.to(CFG.device)\n",
    "except Exception:\n",
    "    # Some ultralytics versions may not expose .to(); we still move the torch model below.\n",
    "    pass\n",
    "\n",
    "model_torch: nn.Module = yolo.model\n",
    "model_torch = model_torch.to(CFG.device)\n",
    "model_torch.eval()\n",
    "\n",
    "# Keep a reference dtype for safe casting of inputs (MPS is strict about dtype/device).\n",
    "_MODEL_DTYPE = next(model_torch.parameters()).dtype\n",
    "\n",
    "\n",
    "names = getattr(yolo, \"names\", None)\n",
    "if names is None:\n",
    "    names = getattr(model_torch, \"names\", {})\n",
    "\n",
    "if CFG.target_class_name is not None:\n",
    "    target_class_id = _get_class_id_from_names(names, CFG.target_class_name)\n",
    "    if target_class_id is None:\n",
    "        print(f\"[warn] target_class_name='{CFG.target_class_name}' не найден в model.names; использую max по всем классам\")\n",
    "else:\n",
    "    target_class_id = None\n",
    "\n",
    "# ---- Use all pre-head top-level blocks as layers ----\n",
    "def pick_prehead_top_level_blocks(model_torch: nn.Module) -> List[str]:\n",
    "    \"\"\"Return names ['model.0', ..., f'model.{head_start-1}'] for pre-head top-level blocks.\"\"\"\n",
    "    head_start = find_head_start_index(model_torch)\n",
    "    # Confirm model has that many top-level blocks\n",
    "    seq = getattr(model_torch, \"model\", None)\n",
    "    if isinstance(seq, (nn.Sequential, list, tuple)):\n",
    "        n_blocks = len(seq)\n",
    "        head_start = min(head_start, n_blocks)\n",
    "    return [f\"model.{i}\" for i in range(int(head_start))]\n",
    "\n",
    "head_start_idx = find_head_start_index(model_torch)\n",
    "# Choose which blocks to analyze.\n",
    "# - Full pre-head profile: pick_prehead_top_level_blocks(model_torch)\n",
    "# - Single block (requested): [\"model.22\"]\n",
    "layer_names = [\"model.22\"]\n",
    "\n",
    "print(f\"Head starts at top-level model index: {head_start_idx}\")\n",
    "print(f\"Selected blocks: {len(layer_names)} -> {layer_names}\")\n",
    "\n",
    "patch_pil = Image.open(patch_path).convert(\"RGB\")\n",
    "\n",
    "run_data: List[Dict[str, Any]] = []\n",
    "\n",
    "for p in image_paths:\n",
    "    base_pil = Image.open(p).convert(\"RGB\")\n",
    "    clean_lb, patched_lb, patch_bbox_lb = build_clean_and_patched_letterboxed(base_pil, patch_pil, CFG)\n",
    "\n",
    "    conf_clean, res_clean = yolo_predict_conf_scalar(yolo, clean_lb, CFG.imgsz, target_class_id)\n",
    "    conf_patch, res_patch = yolo_predict_conf_scalar(yolo, patched_lb, CFG.imgsz, target_class_id)\n",
    "\n",
    "    gradcam_info = {}\n",
    "    if target_class_id is not None:\n",
    "        gradcam_info = pick_center_person_bbox_from_results(\n",
    "            res_clean,\n",
    "            target_class_id=int(target_class_id),\n",
    "            imgsz=int(CFG.imgsz),\n",
    "            strategy=\"score\",      # попробуй также: 'conf' или 'area'\n",
    "            min_conf=0.10,\n",
    "            min_area_frac=0.01,\n",
    "        )\n",
    "\n",
    "    x_clean = torch_preprocess_letterboxed(clean_lb, device=CFG.device, dtype=_MODEL_DTYPE)\n",
    "    x_patch = torch_preprocess_letterboxed(patched_lb, device=CFG.device, dtype=_MODEL_DTYPE)\n",
    "\n",
    "    acts_clean = capture_activations_for_layers(model_torch, x_clean, layer_names)\n",
    "    acts_patch = capture_activations_for_layers(model_torch, x_patch, layer_names)\n",
    "\n",
    "    deltas: Dict[str, torch.Tensor] = {}\n",
    "    for ln in layer_names:\n",
    "        if ln in acts_clean and ln in acts_patch:\n",
    "            deltas[ln] = (acts_patch[ln] - acts_clean[ln])\n",
    "\n",
    "    drop = float(conf_clean - conf_patch)\n",
    "    #success = bool(conf_clean >= CFG.success_thresh > conf_patch)\n",
    "    success = bool(drop > CFG.success_thresh)\n",
    "\n",
    "    run_data.append(\n",
    "        {\n",
    "            \"path\": p,\n",
    "            \"clean_lb\": clean_lb,\n",
    "            \"patched_lb\": patched_lb,\n",
    "            \"patch_bbox_lb\": patch_bbox_lb,\n",
    "            \"conf_clean\": float(conf_clean),\n",
    "            \"conf_patch\": float(conf_patch),\n",
    "            \"drop\": drop,\n",
    "            \"success\": success,\n",
    "            \"acts_clean\": acts_clean,\n",
    "            \"acts_patch\": acts_patch,\n",
    "            \"deltas\": deltas,\n",
    "            \"res_clean\": res_clean,\n",
    "            \"res_patch\": res_patch,\n",
    "            \"gradcam_info\": gradcam_info,\n",
    "        }\n",
    "    )\n",
    "\n",
    "print(\"\\nPer-image summary:\")\n",
    "for d in run_data:\n",
    "    print(f\"- {d['path']}: clean={d['conf_clean']:.3f} patched={d['conf_patch']:.3f} drop={d['drop']:.3f} success={d['success']}\")\n",
    "\n",
    "\n",
    "# --- Re-balance by computed success label (folder names may be wrong) ---\n",
    "rng = np.random.default_rng(SEED)\n",
    "\n",
    "succ_rd = [d for d in run_data if bool(d.get(\"success\", False))]\n",
    "fail_rd = [d for d in run_data if not bool(d.get(\"success\", False))]\n",
    "\n",
    "# shuffle to avoid ordering bias\n",
    "rng.shuffle(succ_rd)\n",
    "rng.shuffle(fail_rd)\n",
    "\n",
    "n_s = min(int(N_SUCCESS), len(succ_rd))\n",
    "n_f = min(int(N_FAIL), len(fail_rd))\n",
    "\n",
    "run_data_balanced = succ_rd[:n_s] + fail_rd[:n_f]\n",
    "rng.shuffle(run_data_balanced)\n",
    "\n",
    "print(f\"\\n[rebalance] Computed labels in pool: success={len(succ_rd)} fail={len(fail_rd)}\")\n",
    "print(f\"[rebalance] Keeping: success={n_s} fail={n_f} (total={len(run_data_balanced)})\")\n",
    "\n",
    "# Overwrite run_data so all downstream cells use the balanced subset.\n",
    "run_data = run_data_balanced"
   ],
   "id": "3369ba92a89f9b6a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Визуализация карт разности фич (Δ = F(patched) − F(clean))\n",
    "\n",
    "Для каждого изображения строим 2D-карту разности на выбранном слое, схлопывая 512 каналов в один скаляр на пиксель.\n",
    "Покажем две версии:\n",
    "- **signed**: сохраняем знак (положительные/отрицательные изменения)\n",
    "- **abs**: модуль разности\n",
    "\n",
    "Далее можно варьировать способ схлопывания каналов (mean / l2 / max / topk_mean / pca1), чтобы уменьшить потерю информации.\n"
   ],
   "id": "9d7a55b41e871e80"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from pathlib import Path\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.patches as patches\n",
    "from typing import List\n",
    "\n",
    "\n",
    "def _reduce_channels(delta_chw: torch.Tensor, mode: str = \"l2\", topk: int = 32) -> torch.Tensor:\n",
    "    \"\"\"Reduce CxHxW -> HxW.\n",
    "\n",
    "    mode:\n",
    "      - 'mean'      : mean over channels (signed)\n",
    "      - 'l2'        : sqrt(mean(delta^2)) (non-negative)\n",
    "      - 'max'       : max over channels (signed, preserves sign of max value)\n",
    "      - 'abs_mean'  : mean(|delta|)\n",
    "      - 'topk_mean' : mean of top-k |delta|, keeps sign by multiplying by sign(mean(delta over topk idx))\n",
    "      - 'pca1'      : first principal component projection (signed). Uses a light SVD on (HW x C).\n",
    "\n",
    "    Returns: HxW on CPU.\n",
    "    \"\"\"\n",
    "    if delta_chw.ndim != 3:\n",
    "        raise ValueError(f\"Expected CHW tensor, got {tuple(delta_chw.shape)}\")\n",
    "\n",
    "    C, H, W = delta_chw.shape\n",
    "    x = delta_chw.reshape(C, H * W).T  # (HW, C)\n",
    "\n",
    "    mode = mode.lower().strip()\n",
    "\n",
    "    if mode == \"mean\":\n",
    "        return delta_chw.mean(dim=0)\n",
    "\n",
    "    if mode == \"abs_mean\":\n",
    "        return delta_chw.abs().mean(dim=0)\n",
    "\n",
    "    if mode == \"l2\":\n",
    "        # sqrt(mean(delta^2))\n",
    "        return (delta_chw.float().pow(2).mean(dim=0)).sqrt()\n",
    "\n",
    "    if mode == \"max\":\n",
    "        return delta_chw.max(dim=0).values\n",
    "\n",
    "    if mode == \"topk_mean\":\n",
    "        k = int(min(max(topk, 1), C))\n",
    "        # indices of top-k by magnitude per spatial position\n",
    "        # We do it in Cx(HW) space to stay vectorized.\n",
    "        mag = delta_chw.abs().reshape(C, H * W)\n",
    "        _, idx = torch.topk(mag, k=k, dim=0, largest=True, sorted=False)\n",
    "        vals = delta_chw.reshape(C, H * W).gather(0, idx)  # (k, HW)\n",
    "        # signed aggregation: mean of selected values\n",
    "        out = vals.mean(dim=0).reshape(H, W)\n",
    "        return out\n",
    "\n",
    "    if mode == \"pca1\":\n",
    "        # Center across spatial positions, compute first right-singular vector.\n",
    "        # x: (HW, C)\n",
    "        x = x.float()\n",
    "        x = x - x.mean(dim=0, keepdim=True)\n",
    "        # For typical YOLO feature maps, HW is not huge; SVD is acceptable for visualization.\n",
    "        # We only need V[:,0].\n",
    "        try:\n",
    "            # torch.linalg.svd returns U, S, Vh; Vh shape (C, C)\n",
    "            _U, _S, Vh = torch.linalg.svd(x, full_matrices=False)\n",
    "            v0 = Vh[0]  # (C,)\n",
    "        except Exception:\n",
    "            # Fallback: use power iteration on covariance (C x C) if SVD fails.\n",
    "            cov = (x.T @ x) / max(x.shape[0] - 1, 1)\n",
    "            v0 = torch.randn((C,), device=cov.device, dtype=cov.dtype)\n",
    "            v0 = v0 / (v0.norm() + 1e-12)\n",
    "            for _ in range(15):\n",
    "                v0 = cov @ v0\n",
    "                v0 = v0 / (v0.norm() + 1e-12)\n",
    "\n",
    "        proj = (x @ v0)  # (HW,)\n",
    "        return proj.reshape(H, W)\n",
    "\n",
    "    raise ValueError(f\"Unknown mode='{mode}'\")\n",
    "\n",
    "\n",
    "def _robust_norm_signed(hw: np.ndarray, q: float = 99.0) -> Tuple[np.ndarray, float]:\n",
    "    \"\"\"Normalize signed map to [-1,1] using symmetric percentile scaling.\"\"\"\n",
    "    s = float(np.percentile(np.abs(hw), q))\n",
    "    s = max(s, 1e-8)\n",
    "    out = np.clip(hw / s, -1.0, 1.0)\n",
    "    return out, s\n",
    "\n",
    "\n",
    "def _robust_norm_positive(hw: np.ndarray, q: float = 99.0) -> Tuple[np.ndarray, float]:\n",
    "    \"\"\"Normalize non-negative map to [0,1] using percentile scaling.\"\"\"\n",
    "    s = float(np.percentile(hw, q))\n",
    "    s = max(s, 1e-8)\n",
    "    out = np.clip(hw / s, 0.0, 1.0)\n",
    "    return out, s\n"
   ],
   "id": "98f56b099f9f6460",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from random import sample\n",
    "\n",
    "def visualize_delta_maps(\n",
    "    run_data: List[Dict[str, Any]],\n",
    "    layer: str = \"model.22\",\n",
    "    reduce_mode: str = \"topk_mean\",\n",
    "    topk: int = 32,\n",
    "    max_rows: int | None = None,\n",
    "    save_dir: str | Path | None = None,\n",
    "):\n",
    "    \"\"\"Show per-image delta maps overlaid on the patched image.\n",
    "\n",
    "    Layout per row: patched | patched+signedΔ | patched+absΔ\n",
    "\n",
    "    Notes:\n",
    "    - signed overlay uses a diverging cmap (seismic) with symmetric robust scaling.\n",
    "    - abs overlay uses a positive cmap (viridis) with robust scaling.\n",
    "    - alpha controls overlay transparency.\n",
    "    \"\"\"\n",
    "    if save_dir is not None:\n",
    "        save_dir = Path(save_dir)\n",
    "        save_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    items = run_data if max_rows is None else run_data[: int(max_rows)]\n",
    "\n",
    "    n = len(items)\n",
    "    if n == 0:\n",
    "        raise RuntimeError(\"run_data is empty\")\n",
    "\n",
    "    alpha = 1  # overlay transparency\n",
    "\n",
    "    def _draw_clean_bbox(ax, bbox_xyxy, success: bool):\n",
    "        \"\"\"Draw the predicted person bbox from clean image onto an axis.\"\"\"\n",
    "        if bbox_xyxy is None:\n",
    "            return\n",
    "        x1, y1, x2, y2 = [float(v) for v in bbox_xyxy]\n",
    "        w = max(0.0, x2 - x1)\n",
    "        h = max(0.0, y2 - y1)\n",
    "        if w <= 0 or h <= 0:\n",
    "            return\n",
    "        # Green for success, red for fail\n",
    "        ec = \"lime\" if success else \"black\"\n",
    "        rect = patches.Rectangle((x1, y1), w, h, linewidth=4.0, edgecolor=ec, facecolor=\"none\")\n",
    "        ax.add_patch(rect)\n",
    "\n",
    "\n",
    "    fig, axes = plt.subplots(nrows=n, ncols=3, figsize=(15, 4.6 * n))\n",
    "    if n == 1:\n",
    "        axes = np.expand_dims(axes, axis=0)\n",
    "\n",
    "    for i, d in enumerate(items):\n",
    "        p = d.get(\"path\", f\"idx_{i}\")\n",
    "        success = d.get(\"success\", False)\n",
    "        drop = d.get(\"drop\", 0.0)\n",
    "        conf_c = d.get(\"conf_clean\", 0.0)\n",
    "        conf_p = d.get(\"conf_patch\", 0.0)\n",
    "\n",
    "        status = \"SUCCESS\" if success else \"FAIL\"\n",
    "        # Predicted bbox of the person BEFORE attack (from clean prediction)\n",
    "        bbox_xyxy = None\n",
    "        gi = d.get(\"gradcam_info\", {})\n",
    "        if isinstance(gi, dict):\n",
    "            bbox_xyxy = gi.get(\"picked_bbox\", None)\n",
    "\n",
    "        # Base (patched) image\n",
    "        patched_img = d[\"patched_lb\"]\n",
    "\n",
    "        # --- Δ feature map ---\n",
    "        delta = d[\"deltas\"].get(layer, None)\n",
    "        if delta is None:\n",
    "            for j, title in enumerate([\"patched\", \"patched + signed Δ\", \"patched + abs Δ\"]):\n",
    "                axes[i, j].imshow(patched_img)\n",
    "                _draw_clean_bbox(axes[i, j], bbox_xyxy, success)\n",
    "                axes[i, j].set_title(title + \" (missing Δ)\")\n",
    "                axes[i, j].axis(\"off\")\n",
    "            axes[i, 0].set_ylabel(\n",
    "                f\"{Path(p).name}\\n{status} | clean={conf_c:.3f} patched={conf_p:.3f} drop={drop:.3f}\",\n",
    "                rotation=0,\n",
    "                labelpad=60,\n",
    "                va=\"center\",\n",
    "            )\n",
    "            continue\n",
    "\n",
    "        # delta: (B,C,H,W) -> (C,H,W)\n",
    "        if delta.ndim == 4:\n",
    "            delta_chw = delta[0]\n",
    "        else:\n",
    "            raise ValueError(f\"Unexpected delta ndim={delta.ndim} for layer={layer}\")\n",
    "\n",
    "        # Reduce channels -> HxW feature-space map (typically ~20x20) and upsample to image resolution (e.g., 640x640)\n",
    "        signed_hw_t = _reduce_channels(delta_chw, mode=reduce_mode, topk=topk).detach().cpu()  # torch [h,w]\n",
    "\n",
    "        # Target size is the rendered patched image size\n",
    "        if isinstance(patched_img, Image.Image):\n",
    "            tgt_w, tgt_h = patched_img.size\n",
    "        else:\n",
    "            # assume numpy HWC\n",
    "            tgt_h, tgt_w = np.asarray(patched_img).shape[:2]\n",
    "\n",
    "        if tuple(signed_hw_t.shape) != (tgt_h, tgt_w):\n",
    "            signed_hw_t = F.interpolate(\n",
    "                signed_hw_t[None, None, ...].float(),\n",
    "                size=(int(tgt_h), int(tgt_w)),\n",
    "                mode=\"nearest\",\n",
    "            )[0, 0]\n",
    "\n",
    "        signed_hw = signed_hw_t.numpy()\n",
    "\n",
    "        # abs map: if reduce_mode already non-negative, keep it; otherwise take abs\n",
    "        if reduce_mode in {\"l2\", \"abs_mean\"}:\n",
    "            abs_hw = signed_hw\n",
    "        else:\n",
    "            abs_hw = np.abs(signed_hw)\n",
    "\n",
    "        signed_n, s_signed = _robust_norm_signed(signed_hw, q=99.0)\n",
    "        abs_n, s_abs = _robust_norm_positive(abs_hw, q=99.0)\n",
    "\n",
    "        # --- Col 1: patched only ---\n",
    "        axes[i, 0].imshow(patched_img)\n",
    "        _draw_clean_bbox(axes[i, 0], bbox_xyxy, success)\n",
    "        axes[i, 0].set_title(f\"patched | {status}\\nclean={conf_c:.3f} → patched={conf_p:.3f} (drop={drop:.3f})\")\n",
    "        axes[i, 0].axis(\"off\")\n",
    "\n",
    "                # Row badge\n",
    "        axes[i, 0].text(\n",
    "            8,\n",
    "            18,\n",
    "            status,\n",
    "            fontsize=14,\n",
    "            fontweight=\"bold\",\n",
    "            color=(\"lime\" if success else \"red\"),\n",
    "            bbox=dict(facecolor=\"black\", alpha=0.35, pad=3, edgecolor=\"none\"),\n",
    "        )\n",
    "\n",
    "\n",
    "        # --- Col 2: patched + signed Δ ---\n",
    "        axes[i, 1].imshow(patched_img)\n",
    "        _draw_clean_bbox(axes[i, 1], bbox_xyxy, success)\n",
    "        im_signed = axes[i, 1].imshow(signed_n, vmin=-1, vmax=1, cmap=\"seismic\", alpha=alpha)\n",
    "        axes[i, 1].set_title(f\"patched + signed Δ | {reduce_mode}\\n{status} | clean={conf_c:.3f} → patched={conf_p:.3f}\")\n",
    "        axes[i, 1].axis(\"off\")\n",
    "        plt.colorbar(im_signed, ax=axes[i, 1], fraction=0.046, pad=0.04)\n",
    "\n",
    "        # --- Col 3: patched + abs Δ ---\n",
    "        axes[i, 2].imshow(patched_img)\n",
    "        _draw_clean_bbox(axes[i, 2], bbox_xyxy, success)\n",
    "        im_abs = axes[i, 2].imshow(abs_n, vmin=0, vmax=1, cmap=\"viridis\", alpha=alpha)\n",
    "        axes[i, 2].set_title(f\"patched + abs Δ | {reduce_mode}\\n{status} | clean={conf_c:.3f} → patched={conf_p:.3f}\")\n",
    "        axes[i, 2].axis(\"off\")\n",
    "        plt.colorbar(im_abs, ax=axes[i, 2], fraction=0.046, pad=0.04)\n",
    "\n",
    "        axes[i, 0].set_ylabel(\n",
    "            f\"{Path(p).name}\\n{status} | clean={conf_c:.3f} patched={conf_p:.3f} drop={drop:.3f}\",\n",
    "            rotation=0,\n",
    "            labelpad=60,\n",
    "            va=\"center\",\n",
    "        )\n",
    "\n",
    "        if save_dir is not None:\n",
    "            stem = Path(p).stem\n",
    "            # Save overlays as images\n",
    "            out_signed = (save_dir / f\"{stem}__overlay_signed_{reduce_mode}.png\")\n",
    "            out_abs = (save_dir / f\"{stem}__overlay_abs_{reduce_mode}.png\")\n",
    "\n",
    "            # Render and save (matplotlib imsave doesn't support alpha-compositing easily),\n",
    "            # so we create composited RGB arrays.\n",
    "            base = np.asarray(patched_img).astype(np.float32) / 255.0  # HWC RGB\n",
    "\n",
    "            # signed overlay: map [-1,1] -> RGBA via cmap\n",
    "            cmap_s = plt.get_cmap(\"seismic\")\n",
    "            rgba_s = cmap_s((signed_n + 1.0) * 0.5)  # HxWx4\n",
    "            comp_s = (1 - alpha) * base + alpha * rgba_s[..., :3]\n",
    "            comp_s = np.clip(comp_s, 0.0, 1.0)\n",
    "\n",
    "            cmap_a = plt.get_cmap(\"viridis\")\n",
    "            rgba_a = cmap_a(abs_n)  # HxWx4\n",
    "            comp_a = (1 - alpha) * base + alpha * rgba_a[..., :3]\n",
    "            comp_a = np.clip(comp_a, 0.0, 1.0)\n",
    "\n",
    "            plt.imsave(out_signed, comp_s)\n",
    "            plt.imsave(out_abs, comp_a)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Быстрый запуск\n",
    "visualize_delta_maps(\n",
    "    run_data[:10],\n",
    "    layer=\"model.22\",\n",
    "    reduce_mode=\"mean\",  # попробуй: 'mean', 'max', 'l2', 'abs_mean', 'topk_mean', 'pca1'\n",
    "    topk=CFG.topk_channels,\n",
    "    max_rows=None,\n",
    "    save_dir=None,  # например: \"viz_delta_overlays/model22\"\n",
    ")\n"
   ],
   "id": "c2089bbde58cebec",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Выводы из эксперимента\n",
    "\n",
    "Синий = фича упала, предположительно, нам нужно именно это в ROI"
   ],
   "id": "fb4a812ce23c194a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# --- gini для неотрицательных величин ---\n",
    "def gini(x: np.ndarray, eps: float = 1e-12) -> float:\n",
    "    x = np.asarray(x, dtype=np.float64).reshape(-1)\n",
    "    x = x[np.isfinite(x)]\n",
    "    if x.size == 0:\n",
    "        return float(\"nan\")\n",
    "    x = np.clip(x, 0.0, None)\n",
    "    s = x.sum()\n",
    "    if s <= eps:\n",
    "        return 0.0\n",
    "    x = np.sort(x)\n",
    "    n = x.size\n",
    "    i = np.arange(1, n + 1, dtype=np.float64)\n",
    "    return float(1.0 + 1.0 / n - 2.0 * np.sum((n + 1 - i) * x) / (n * s))\n",
    "\n",
    "# bbox 640x640 -> (H,W) координаты фич\n",
    "def xyxy_to_hw_roi(xyxy, H: int, W: int, imgsz: int = 640):\n",
    "    if xyxy is None:\n",
    "        return None\n",
    "    x1, y1, x2, y2 = [float(v) for v in xyxy]\n",
    "    x1 = max(0.0, min(float(imgsz), x1)); x2 = max(0.0, min(float(imgsz), x2))\n",
    "    y1 = max(0.0, min(float(imgsz), y1)); y2 = max(0.0, min(float(imgsz), y2))\n",
    "    if x2 <= x1 or y2 <= y1:\n",
    "        return None\n",
    "    sx = W / float(imgsz); sy = H / float(imgsz)\n",
    "    fx1 = int(np.floor(x1 * sx)); fx2 = int(np.ceil(x2 * sx))\n",
    "    fy1 = int(np.floor(y1 * sy)); fy2 = int(np.ceil(y2 * sy))\n",
    "    fx1 = max(0, min(W - 1, fx1)); fx2 = max(1, min(W, fx2))\n",
    "    fy1 = max(0, min(H - 1, fy1)); fy2 = max(1, min(H, fy2))\n",
    "    if fx2 <= fx1 or fy2 <= fy1:\n",
    "        return None\n",
    "    return (slice(fy1, fy2), slice(fx1, fx2))\n",
    "\n",
    "def compute_metrics(delta_bchw: torch.Tensor, reduce_mode_hw: str = \"mean\", topk: int = 32, imgsz: int = 640, bbox_xyxy=None):\n",
    "    \"\"\"\n",
    "    delta_bchw: torch [B,C,H,W] (CPU у тебя)\n",
    "    reduce_mode_hw: как схлопывать каналы в карту HxW через _reduce_channels (mean/topk_mean/l2/abs_mean/max/pca1)\n",
    "    \"\"\"\n",
    "    if delta_bchw is None:\n",
    "        return {}\n",
    "\n",
    "    d = delta_bchw[0].float()          # [C,H,W]\n",
    "    C, H, W = d.shape\n",
    "\n",
    "    # A) full Δ (512,20,20)\n",
    "    mean_signed = float(d.mean().item())\n",
    "    l2_rms = float((d.pow(2).mean()).sqrt().item())\n",
    "    abs_mean = float(d.abs().mean().item())\n",
    "    abs_max = float(d.abs().max().item())\n",
    "\n",
    "    # channel energies E_c = mean_{h,w}|Δ_c|\n",
    "    E = d.abs().mean(dim=(1,2)).cpu().numpy().astype(np.float64)  # (C,)\n",
    "    k = int(min(max(topk, 1), C))\n",
    "    topk_E = np.partition(E, -k)[-k:]\n",
    "    chan_energy_topk_mean = float(np.mean(topk_E))\n",
    "    chan_energy_gini = gini(E)\n",
    "\n",
    "    # B) reduced HxW map using your existing reducer\n",
    "    hw_signed = _reduce_channels(d, mode=reduce_mode_hw, topk=topk).detach().cpu().numpy().astype(np.float64)\n",
    "    hw_abs = hw_signed if reduce_mode_hw in {\"l2\", \"abs_mean\"} else np.abs(hw_signed)\n",
    "\n",
    "    hw_abs_mean = float(hw_abs.mean())\n",
    "    hw_abs_max  = float(hw_abs.max())\n",
    "    hw_gini     = gini(hw_abs)\n",
    "\n",
    "    p90 = float(np.percentile(hw_abs.reshape(-1), 90.0))\n",
    "    hw_sparsity_p90 = float(np.mean(hw_abs >= p90)) if p90 > 0 else 0.0\n",
    "\n",
    "    # C) ROI (bbox человека из clean)\n",
    "    roi_abs_mean = float(\"nan\")\n",
    "    roi_abs_out_mean = float(\"nan\")\n",
    "    roi_abs_ratio = float(\"nan\")\n",
    "    roi = xyxy_to_hw_roi(bbox_xyxy, H=H, W=W, imgsz=imgsz)\n",
    "    if roi is not None:\n",
    "        roi_map = hw_abs[roi]\n",
    "        out_mask = np.ones((H,W), dtype=bool)\n",
    "        out_mask[roi] = False\n",
    "        out_map = hw_abs[out_mask]\n",
    "        roi_abs_mean = float(np.mean(roi_map)) if roi_map.size else float(\"nan\")\n",
    "        roi_abs_out_mean = float(np.mean(out_map)) if out_map.size else float(\"nan\")\n",
    "        if np.isfinite(roi_abs_out_mean) and roi_abs_out_mean > 0:\n",
    "            roi_abs_ratio = float(roi_abs_mean / roi_abs_out_mean)\n",
    "\n",
    "    return {\n",
    "        \"mean_signed\": mean_signed,\n",
    "        \"l2_rms\": l2_rms,\n",
    "        \"abs_mean\": abs_mean,\n",
    "        \"abs_max\": abs_max,\n",
    "        \"chan_energy_topk_mean\": chan_energy_topk_mean,\n",
    "        \"chan_energy_gini\": chan_energy_gini,\n",
    "        \"hw_abs_mean\": hw_abs_mean,\n",
    "        \"hw_abs_max\": hw_abs_max,\n",
    "        \"hw_gini\": hw_gini,\n",
    "        \"hw_sparsity_p90\": hw_sparsity_p90,\n",
    "        \"roi_abs_mean\": roi_abs_mean,\n",
    "        \"roi_abs_ratio\": roi_abs_ratio,\n",
    "        \"H\": H, \"W\": W, \"C\": C,\n",
    "    }\n",
    "\n",
    "LAYER = \"model.22\"\n",
    "\n",
    "rows = []\n",
    "for d in run_data:\n",
    "    gi = d.get(\"gradcam_info\", {})\n",
    "    bbox = gi.get(\"picked_bbox\", None) if isinstance(gi, dict) else None\n",
    "\n",
    "    m = compute_metrics(\n",
    "        d.get(\"deltas\", {}).get(LAYER, None),\n",
    "        reduce_mode_hw=\"mean\",           # попробуй также \"topk_mean\" / \"l2\" / \"abs_mean\"\n",
    "        topk=int(CFG.topk_channels),\n",
    "        imgsz=int(CFG.imgsz),\n",
    "        bbox_xyxy=bbox,\n",
    "    )\n",
    "\n",
    "    rows.append({\n",
    "        \"path\": d.get(\"path\"),\n",
    "        \"name\": Path(d.get(\"path\",\"\")).name,\n",
    "        \"success\": bool(d.get(\"success\", False)),\n",
    "        \"conf_clean\": float(d.get(\"conf_clean\", 0.0)),\n",
    "        \"conf_patch\": float(d.get(\"conf_patch\", 0.0)),\n",
    "        \"drop\": float(d.get(\"drop\", 0.0)),\n",
    "        **m\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "df.head()"
   ],
   "id": "b4d557ad9d97f8ec",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import roc_auc_score, balanced_accuracy_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def roc_auc_for_metric(df: pd.DataFrame, metric: str, label_col: str = \"success\") -> tuple[float, int]:\n",
    "    \"\"\"\n",
    "    Return (AUC>=0.5, direction).\n",
    "\n",
    "    direction = +1: larger metric -> more likely SUCCESS\n",
    "    direction = -1: smaller metric -> more likely SUCCESS (we flip to keep AUC>=0.5)\n",
    "    \"\"\"\n",
    "    y = df[label_col].astype(int).to_numpy()\n",
    "    x = df[metric].to_numpy().astype(float)\n",
    "\n",
    "    m = np.isfinite(x) & np.isfinite(y)\n",
    "    x = x[m]\n",
    "    y = y[m]\n",
    "\n",
    "    if np.unique(y).size < 2:\n",
    "        return float(\"nan\"), 0\n",
    "\n",
    "    auc_raw = float(roc_auc_score(y, x))\n",
    "    direction = +1\n",
    "    auc = auc_raw\n",
    "    if auc_raw < 0.5:\n",
    "        auc = 1.0 - auc_raw\n",
    "        direction = -1\n",
    "\n",
    "    return float(auc), int(direction)\n",
    "\n",
    "def best_balanced_accuracy_for_metric(\n",
    "    df: pd.DataFrame,\n",
    "    metric: str,\n",
    "    label_col: str = \"success\",\n",
    "    *,\n",
    "    direction: int | None = None,\n",
    ") -> tuple[float, float, int]:\n",
    "    \"\"\"Best balanced accuracy achievable by thresholding a single scalar metric.\n",
    "\n",
    "    Returns:\n",
    "      (best_bal_acc, best_threshold, used_direction)\n",
    "\n",
    "    used_direction:\n",
    "      +1 => predict SUCCESS when x >= thr\n",
    "      -1 => predict SUCCESS when x <= thr\n",
    "    \"\"\"\n",
    "    y = df[label_col].astype(int).to_numpy()\n",
    "    x = df[metric].to_numpy().astype(float)\n",
    "\n",
    "    m = np.isfinite(x) & np.isfinite(y)\n",
    "    x = x[m]\n",
    "    y = y[m]\n",
    "\n",
    "    if x.size == 0 or np.unique(y).size < 2:\n",
    "        return float(\"nan\"), float(\"nan\"), 0\n",
    "\n",
    "    if direction is None:\n",
    "        _auc, direction = roc_auc_for_metric(df.loc[m], metric, label_col=label_col)\n",
    "\n",
    "    direction = +1 if int(direction) >= 0 else -1\n",
    "\n",
    "    xs = np.unique(x)\n",
    "    if xs.size == 1:\n",
    "        thr = float(xs[0])\n",
    "        yhat = (x >= thr) if direction == +1 else (x <= thr)\n",
    "        ba = float(balanced_accuracy_score(y, yhat.astype(int)))\n",
    "        return ba, thr, int(direction)\n",
    "\n",
    "    mids = (xs[:-1] + xs[1:]) * 0.5\n",
    "    thr_candidates = np.concatenate(([xs[0] - 1e-12], mids, [xs[-1] + 1e-12]))\n",
    "\n",
    "    best_ba = -1.0\n",
    "    best_thr = float(\"nan\")\n",
    "\n",
    "    for thr in thr_candidates:\n",
    "        yhat = (x >= thr) if direction == +1 else (x <= thr)\n",
    "        ba = float(balanced_accuracy_score(y, yhat.astype(int)))\n",
    "        if ba > best_ba:\n",
    "            best_ba = ba\n",
    "            best_thr = float(thr)\n",
    "\n",
    "    return float(best_ba), float(best_thr), int(direction)\n",
    "\n",
    "metric_cols_delta_only = [\n",
    "    \"mean_signed\", \"l2_rms\", \"abs_mean\", \"abs_max\",\n",
    "    \"chan_energy_topk_mean\", \"chan_energy_gini\",\n",
    "    \"hw_abs_mean\", \"hw_abs_max\", \"hw_gini\", \"hw_sparsity_p90\",\n",
    "    \"roi_abs_mean\", \"roi_abs_ratio\",\n",
    "]\n",
    "\n",
    "succ = df[df.success == True]\n",
    "fail = df[df.success == False]\n",
    "\n",
    "summary = []\n",
    "for c in metric_cols_delta_only:\n",
    "    xs = succ[c].to_numpy()\n",
    "    xf = fail[c].to_numpy()\n",
    "\n",
    "    auc, direction = roc_auc_for_metric(df, c, label_col=\"success\")\n",
    "    bacc, bthr, _ = best_balanced_accuracy_for_metric(df, c, label_col=\"success\", direction=direction)\n",
    "\n",
    "    summary.append({\n",
    "        \"metric\": c,\n",
    "        \"mean_s\": float(np.nanmean(xs)),\n",
    "        \"mean_f\": float(np.nanmean(xf)),\n",
    "        \"std_s\": float(np.nanstd(xs)),\n",
    "        \"std_f\": float(np.nanstd(xf)),\n",
    "        \"best_bal_acc\": bacc,\n",
    "        \"best_bal_thr\": bthr,\n",
    "        \"roc_auc\": auc,\n",
    "        \"auc_direction\": direction,\n",
    "    })\n",
    "\n",
    "summary_df_delta_only = pd.DataFrame(summary).sort_values(\"best_bal_acc\", ascending=False)\n",
    "summary_df_delta_only"
   ],
   "id": "735b4aeb23150d2b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def _violin_metric(ax, data_s, data_f, title: str):\n",
    "    \"\"\"FAIL vs SUCCESS distribution: violin + median + jitter points.\n",
    "\n",
    "    Лучше boxplot при tiny-std и при дискретных значениях (квантизация).\n",
    "    \"\"\"\n",
    "    data_s = np.asarray(data_s, dtype=float)\n",
    "    data_f = np.asarray(data_f, dtype=float)\n",
    "\n",
    "    data_s = data_s[np.isfinite(data_s)]\n",
    "    data_f = data_f[np.isfinite(data_f)]\n",
    "\n",
    "    if (data_s.size == 0) and (data_f.size == 0):\n",
    "        ax.text(0.5, 0.5, \"no finite data\", ha=\"center\", va=\"center\")\n",
    "        ax.set_axis_off()\n",
    "        return\n",
    "\n",
    "    series = []\n",
    "    labels = []\n",
    "    positions = []\n",
    "\n",
    "    if data_f.size:\n",
    "        series.append(data_f)\n",
    "        labels.append(f\"FAIL (n={data_f.size})\")\n",
    "        positions.append(1)\n",
    "\n",
    "    if data_s.size:\n",
    "        series.append(data_s)\n",
    "        labels.append(f\"SUCCESS (n={data_s.size})\")\n",
    "        positions.append(2 if data_f.size else 1)\n",
    "\n",
    "    ax.violinplot(\n",
    "        series,\n",
    "        positions=positions,\n",
    "        widths=0.8,\n",
    "        showmeans=False,\n",
    "        showmedians=True,\n",
    "        showextrema=False,\n",
    "    )\n",
    "\n",
    "    # jitter + median line (чтобы видно было схлопывание)\n",
    "    rng = np.random.default_rng(0)\n",
    "    if data_f.size:\n",
    "        jf = (rng.random(data_f.size) - 0.5) * 0.16\n",
    "        ax.scatter(np.full(data_f.size, 1.0) + jf, data_f, s=10, alpha=0.35)\n",
    "        ax.hlines(np.median(data_f), 0.78, 1.22, linewidth=3)\n",
    "\n",
    "    if data_s.size:\n",
    "        xs = 2.0 if data_f.size else 1.0\n",
    "        js = (rng.random(data_s.size) - 0.5) * 0.16\n",
    "        ax.scatter(np.full(data_s.size, xs) + js, data_s, s=10, alpha=0.35)\n",
    "        ax.hlines(np.median(data_s), xs - 0.22, xs + 0.22, linewidth=3)\n",
    "\n",
    "    ax.set_xticks(positions)\n",
    "    ax.set_xticklabels(labels)\n",
    "    ax.set_title(title)\n",
    "    ax.grid(True, alpha=0.25)\n",
    "\n",
    "\n",
    "# --- Violins for top metrics by ROC-AUC ---\n",
    "topM = 20\n",
    "best = summary_df_delta_only.head(topM)[\"metric\"].tolist()\n",
    "\n",
    "fig = plt.figure(figsize=(14, 3.2 * ((topM + 1) // 2)))\n",
    "for i, m in enumerate(best, 1):\n",
    "    ax = plt.subplot((topM + 1) // 2, 2, i)\n",
    "    _violin_metric(\n",
    "        ax,\n",
    "        succ[m].to_numpy(),\n",
    "        fail[m].to_numpy(),\n",
    "        f\"{m} | AUC={summary_df_delta_only.set_index('metric').loc[m, 'roc_auc']:.3g} | bAcc={summary_df_delta_only.set_index('metric').loc[m, 'best_bal_acc']:.3g}\",\n",
    "    )\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# --- Bar chart of ROC-AUC for all metrics ---\n",
    "fig = plt.figure(figsize=(9.5, 0.42 * len(summary_df_delta_only) + 1.5))\n",
    "order = summary_df_delta_only.sort_values(\"best_bal_acc\", ascending=True)\n",
    "plt.barh(order[\"metric\"], order[\"best_bal_acc\"])\n",
    "plt.xlabel(\"best_bal_acc (>=0.5; higher is better)\")\n",
    "plt.title(\"Best balanced accuracy for feature-delta metrics (no attribution)\")\n",
    "plt.grid(True, axis=\"x\", alpha=0.25)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "ed3d37bf0f49b4ea",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Δ-only метрики (по тензору разности фич) — что означает каждая\n",
    "\n",
    "Ниже `Δ = F(patched) − F(clean)` для выбранного слоя, где `Δ` имеет форму `(C, H, W)` (в нашем случае обычно `C=512`, `H=W≈20`).\n",
    "Важно: эти метрики описывают **только величину/структуру изменения фич**, без сравнения с картой важности.\n",
    "\n",
    "---\n",
    "\n",
    "### `mean_signed`\n",
    "**Среднее значение Δ по всем элементам** (с сохранением знака):\n",
    "$\n",
    "\\text{mean\\_signed}=\\frac{1}{CHW}\\sum_{c,h,w}\\Delta_{c,h,w}\n",
    "$\n",
    "- Показывает: общий **сдвиг** фич в плюс/минус.\n",
    "- Не показывает: локализацию и “энергию” (может быть близко к 0 при больших разнонаправленных изменениях).\n",
    "\n",
    "---\n",
    "\n",
    "### `l2_rms`\n",
    "**RMS-энергия изменения** (аналог L2-нормы на элемент, без знака):\n",
    "$\n",
    "\\text{l2\\_rms}=\\sqrt{\\frac{1}{CHW}\\sum_{c,h,w}\\Delta_{c,h,w}^2}\n",
    "$\n",
    "- Показывает: **общую силу** изменения фич.\n",
    "- Не показывает: где именно изменение произошло и в каком направлении (знак теряется).\n",
    "\n",
    "---\n",
    "\n",
    "### `abs_mean`\n",
    "**Средний модуль изменения**:\n",
    "$\n",
    "\\text{abs\\_mean}=\\frac{1}{CHW}\\sum_{c,h,w}\\left|\\Delta_{c,h,w}\\right|\n",
    "$\n",
    "- Показывает: “насколько в среднем шевельнули фичи”.\n",
    "- Менее чувствителен к редким большим выбросам, чем `abs_max`.\n",
    "\n",
    "---\n",
    "\n",
    "### `abs_max`\n",
    "**Максимальный модуль изменения**:\n",
    "$\n",
    "\\text{abs\\_max}=\\max_{c,h,w}\\left|\\Delta_{c,h,w}\\right|\n",
    "$\n",
    "- Показывает: наличие **очень сильного локального выброса** (хотя бы в одном канале/пикселе).\n",
    "- Может быть нестабильным: одна “аномальная” ячейка доминирует метрику.\n",
    "\n",
    "---\n",
    "\n",
    "### `chan_energy_topk_mean`\n",
    "Сначала считаем **энергию по каналам**:\n",
    "$\n",
    "E_c=\\frac{1}{HW}\\sum_{h,w}\\left|\\Delta_{c,h,w}\\right|\n",
    "$\n",
    "Далее берём **top-k** каналов по \\(E_c\\) и усредняем:\n",
    "$\n",
    "\\text{chan\\_energy\\_topk\\_mean}=\\frac{1}{k}\\sum_{c \\in \\text{TopK}(E)} E_c\n",
    "$\n",
    "- Показывает: насколько сильно изменены **наиболее затронутые каналы**.\n",
    "- Это “канальная концентрация” атаки: бьёт ли она в несколько каналов сильно.\n",
    "\n",
    "---\n",
    "\n",
    "### `chan_energy_gini`\n",
    "**Коэффициент Джини** для распределения энергий по каналам \\(E_c\\) (неотрицательных).\n",
    "- Показывает: **насколько неравномерно** распределено изменение по каналам.\n",
    "  - ближе к 0 → изменение “размазано” по многим каналам;\n",
    "  - ближе к 1 → изменение сосредоточено в малом числе каналов.\n",
    "- Не показывает: абсолютную величину изменения (может быть высокий Джини при маленькой общей энергии).\n",
    "\n",
    "---\n",
    "\n",
    "### `hw_abs_mean`\n",
    "Строим 2D-карту по пространству `H×W` (через `_reduce_channels`, у тебя здесь `reduce_mode_hw=\"mean\"`):\n",
    "$\n",
    "\\Delta_{hw} = \\text{reduce}_c(\\Delta_{c,h,w})\n",
    "$\n",
    "и берём среднее по пространству от модуля:\n",
    "$\n",
    "\\text{hw\\_abs\\_mean}=\\frac{1}{HW}\\sum_{h,w}|\\Delta_{hw}(h,w)|\n",
    "$\n",
    "- Показывает: “среднее изменение по клеткам” после сведения каналов к карте.\n",
    "- Зависит от выбранного `reduce_mode_hw` (mean/l2/topk_mean/...).\n",
    "\n",
    "---\n",
    "\n",
    "### `hw_abs_max`\n",
    "$\n",
    "\\text{hw\\_abs\\_max}=\\max_{h,w}|\\Delta_{hw}(h,w)|\n",
    "$\n",
    "- Показывает: самый сильный “пространственный” выброс после сведения каналов.\n",
    "- Аналогично `abs_max`, но уже после collapse каналов.\n",
    "\n",
    "---\n",
    "\n",
    "### `hw_gini`\n",
    "Коэффициент Джини по **пространственной карте** \\( |\\Delta_{hw}(h,w)| \\).\n",
    "- Показывает: **насколько локализовано** изменение по H×W:\n",
    "  - низкий → равномерно по всей карте;\n",
    "  - высокий → сосредоточено в малом числе клеток.\n",
    "\n",
    "---\n",
    "\n",
    "### `hw_sparsity_p90`\n",
    "Доля клеток, чьё значение ≥ 90-перцентиля карты:\n",
    "$\n",
    "p90=\\text{percentile}(|\\Delta_{hw}|,90),\\quad\n",
    "\\text{hw\\_sparsity\\_p90}=\\frac{1}{HW}\\sum_{h,w}\\mathbf{1}\\{|\\Delta_{hw}(h,w)|\\ge p90\\}\n",
    "$\n",
    "- Показывает: “разреженность” по хвосту распределения.\n",
    "- Для непрерывных значений часто будет около 0.10 по определению; информативность появляется, когда карта **квантизована/имеет плато/много нулей**.\n",
    "\n",
    "---\n",
    "\n",
    "### `roi_abs_mean`\n",
    "Берём ROI на сетке фич (проекция bbox человека из clean в (H,W)) и считаем среднее по ROI:\n",
    "$\n",
    "\\text{roi\\_abs\\_mean}=\\frac{1}{|ROI|}\\sum_{(h,w)\\in ROI}|\\Delta_{hw}(h,w)|\n",
    "$\n",
    "- Показывает: **насколько сильно изменились фичи внутри ROI объекта**.\n",
    "- Не показывает: что происходит вне ROI (поэтому полезно сравнивать с `roi_abs_ratio`).\n",
    "\n",
    "---\n",
    "\n",
    "### `roi_abs_ratio`\n",
    "$\n",
    "\\text{roi\\_abs\\_ratio}=\\frac{\\text{mean}(|\\Delta_{hw}| \\text{ inside ROI})}{\\text{mean}(|\\Delta_{hw}| \\text{ outside ROI})}\n",
    "$\n",
    "- Показывает: “насколько атака сфокусирована на ROI”:\n",
    "  - > 1 → изменение концентрируется в ROI сильнее, чем вне ROI;\n",
    "  - < 1 → больше “шумит” вне ROI.\n",
    "- Важно: это **отношение**, поэтому оно может быть большим и при малых абсолютных значениях (если вне ROI почти ноль)."
   ],
   "id": "978eaebea0bb3637"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Смотрим на важность",
   "id": "6499dbd1f870af7c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# --- Minimal cell: visualize SSGrad-CAM (top-3 ROI logits) vs |grad*act| on model.22 ---\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from typing import Dict, Any, Optional, Tuple\n",
    "\n",
    "# -------------------\n",
    "# Params (edit if needed)\n",
    "# -------------------\n",
    "TARGET_LAYER = \"model.22\"\n",
    "NUM_EXAMPLES = 10          # total images shown (tries to split equally success/fail)\n",
    "TOPK = 3                   # top-k ROI cells (rank by sigmoid, aggregate logits)\n",
    "IMG_SIZE = int(CFG.imgsz)\n",
    "\n",
    "# -------------------\n",
    "# Helpers (minimal)\n",
    "# -------------------\n",
    "def _normalize_11hw(m_11hw: torch.Tensor, eps: float = 1e-12) -> torch.Tensor:\n",
    "    # m: (1,1,h,w) -> [0,1]\n",
    "    m = torch.nan_to_num(m_11hw, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    m = m - m.amin(dim=(2, 3), keepdim=True)\n",
    "    m = m / m.amax(dim=(2, 3), keepdim=True).clamp(min=eps)\n",
    "    return m\n",
    "\n",
    "def _roi_mask_on_grid(h: int, w: int, imgsz: int, bbox_xyxy: Tuple[float, float, float, float], device, dtype):\n",
    "    # mark a cell as inside ROI if its center lies within bbox; return (1,h,w) binary\n",
    "    x1, y1, x2, y2 = [float(v) for v in bbox_xyxy]\n",
    "    stride_h = float(imgsz) / float(h)\n",
    "    stride_w = float(imgsz) / float(w)\n",
    "    stride = 0.5 * (stride_h + stride_w)\n",
    "\n",
    "    ys = (torch.arange(h, device=device, dtype=dtype) + 0.5) * stride\n",
    "    xs = (torch.arange(w, device=device, dtype=dtype) + 0.5) * stride\n",
    "    yy, xx = torch.meshgrid(ys, xs, indexing=\"ij\")\n",
    "    m = (xx >= x1) & (xx <= x2) & (yy >= y1) & (yy <= y2)\n",
    "    mask = m.to(dtype=dtype).unsqueeze(0)  # (1,h,w)\n",
    "\n",
    "    # tiny bbox fallback: pick closest cell to bbox center\n",
    "    if float(mask.sum().item()) < 1.0:\n",
    "        cx, cy = 0.5 * (x1 + x2), 0.5 * (y1 + y2)\n",
    "        d2 = (xx - cx) ** 2 + (yy - cy) ** 2\n",
    "        ij = torch.argmin(d2)\n",
    "        mask = torch.zeros_like(mask)\n",
    "        mask.view(-1)[ij] = 1.0\n",
    "    return mask  # (1,h,w)\n",
    "\n",
    "def _detect_forward_train_levels(model_torch: nn.Module, x_bchw: torch.Tensor):\n",
    "    # Force Detect head into train() so we avoid inference tensors in some Ultralytics builds.\n",
    "    detect = get_module_by_name(model_torch, \"model.23\")\n",
    "    was_detect_training = bool(detect.training)\n",
    "    detect.train()\n",
    "    try:\n",
    "        out = model_torch(x_bchw)\n",
    "    finally:\n",
    "        if not was_detect_training:\n",
    "            detect.eval()\n",
    "\n",
    "    pred_levels = out\n",
    "    if isinstance(out, (tuple, list)) and len(out) == 2 and isinstance(out[0], torch.Tensor):\n",
    "        pred_levels = out[1]  # some builds return (pred, x)\n",
    "\n",
    "    if not isinstance(pred_levels, (list, tuple)) or len(pred_levels) == 0:\n",
    "        raise RuntimeError(f\"Unexpected Detect output type: {type(pred_levels)}\")\n",
    "\n",
    "    reg_max = int(getattr(detect, \"reg_max\", 16))\n",
    "    nc = int(getattr(detect, \"nc\", 80))\n",
    "    return pred_levels, reg_max, nc\n",
    "\n",
    "def _person_logit_map_from_level(t: torch.Tensor, reg_max: int, nc: int, target_class_id: int) -> torch.Tensor:\n",
    "    # t: (B,C,h,w) -> (B,h,w) person logits\n",
    "    cls_logits = t[:, reg_max * 4: reg_max * 4 + nc, :, :]\n",
    "    return cls_logits[:, int(target_class_id), :, :]\n",
    "\n",
    "def target_topk_roi_logits_scalar(\n",
    "    model_torch: nn.Module,\n",
    "    x_bchw: torch.Tensor,\n",
    "    target_class_id: int,\n",
    "    imgsz: int,\n",
    "    bbox_xyxy: Tuple[float, float, float, float],\n",
    "    topk: int = 3,\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    y = mean(logits of top-k ROI cells), where ranking is by sigmoid(prob) but aggregation is logits.\n",
    "    \"\"\"\n",
    "    pred_levels, reg_max, nc = _detect_forward_train_levels(model_torch, x_bchw)\n",
    "\n",
    "    all_logits = []\n",
    "    all_probs = []\n",
    "\n",
    "    for t in pred_levels:\n",
    "        if not (isinstance(t, torch.Tensor) and t.ndim == 4):\n",
    "            continue\n",
    "        pl = _person_logit_map_from_level(t, reg_max, nc, target_class_id)  # (B,h,w)\n",
    "        roi_bin = _roi_mask_on_grid(pl.shape[1], pl.shape[2], imgsz, bbox_xyxy, device=pl.device, dtype=pl.dtype)  # (1,h,w)\n",
    "        mask = roi_bin[0].reshape(-1) > 0\n",
    "\n",
    "        if mask.sum().item() < 1:\n",
    "            continue\n",
    "\n",
    "        lr = pl.reshape(pl.shape[0], -1)[:, mask]   # (B, n_roi)\n",
    "        pr = lr.sigmoid()                           # (B, n_roi)\n",
    "        all_logits.append(lr)\n",
    "        all_probs.append(pr)\n",
    "\n",
    "    if len(all_logits) == 0:\n",
    "        raise RuntimeError(\"No ROI cells found across pred levels.\")\n",
    "\n",
    "    L = torch.cat(all_logits, dim=1)  # (B, total_roi)\n",
    "    P = torch.cat(all_probs, dim=1)   # (B, total_roi)\n",
    "\n",
    "    k = int(min(int(topk), P.shape[1]))\n",
    "    idx = torch.topk(P, k=k, dim=1, largest=True, sorted=False).indices  # (B,k)\n",
    "    chosen_logits = torch.gather(L, dim=1, index=idx)                    # (B,k)\n",
    "    y = chosen_logits.mean(dim=1).mean()                                 # scalar\n",
    "    return y\n",
    "\n",
    "def layer_act_and_grad_for_y(\n",
    "    model_torch: nn.Module,\n",
    "    x_bchw: torch.Tensor,\n",
    "    target_layer_name: str,\n",
    "    y_fn,                       # callable(model_torch, x)->scalar tensor\n",
    ") -> Tuple[torch.Tensor, torch.Tensor, float]:\n",
    "    device = next(model_torch.parameters()).device\n",
    "    dtype = next(model_torch.parameters()).dtype\n",
    "\n",
    "    x = x_bchw.to(device=device, dtype=dtype)\n",
    "    x.requires_grad_(True)\n",
    "\n",
    "    layer = get_module_by_name(model_torch, target_layer_name)\n",
    "    buf: Dict[str, torch.Tensor] = {}\n",
    "\n",
    "    def _hook(_m, _inp, out):\n",
    "        if isinstance(out, (list, tuple)):\n",
    "            for o in out:\n",
    "                if isinstance(o, torch.Tensor):\n",
    "                    out = o\n",
    "                    break\n",
    "        if isinstance(out, torch.Tensor) and out.ndim == 4:\n",
    "            buf[\"A\"] = out\n",
    "            try:\n",
    "                out.retain_grad()\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "            def _save_grad(g):\n",
    "                if isinstance(g, torch.Tensor) and g.ndim == 4:\n",
    "                    buf[\"G\"] = g\n",
    "                return g\n",
    "\n",
    "            try:\n",
    "                out.register_hook(_save_grad)\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "    h = layer.register_forward_hook(_hook)\n",
    "    was_training = bool(model_torch.training)\n",
    "\n",
    "    try:\n",
    "        model_torch.zero_grad(set_to_none=True)\n",
    "        model_torch.train()  # keep autograd-friendly path\n",
    "\n",
    "        y = y_fn(model_torch, x)\n",
    "        y.backward()\n",
    "\n",
    "        if \"A\" not in buf:\n",
    "            raise RuntimeError(\"Failed to capture activation A.\")\n",
    "        if \"G\" not in buf:\n",
    "            Ag = getattr(buf[\"A\"], \"grad\", None)\n",
    "            if isinstance(Ag, torch.Tensor) and Ag.ndim == 4:\n",
    "                buf[\"G\"] = Ag\n",
    "            else:\n",
    "                raise RuntimeError(\"Failed to capture gradient G.\")\n",
    "\n",
    "        A = buf[\"A\"].detach().cpu().to(torch.float32)\n",
    "        G = buf[\"G\"].detach().cpu().to(torch.float32)\n",
    "        return A, G, float(y.detach().cpu().item())\n",
    "\n",
    "    finally:\n",
    "        h.remove()\n",
    "        if not was_training:\n",
    "            model_torch.eval()\n",
    "        x.requires_grad_(False)\n",
    "\n",
    "def ssgradcam_raw(A_bchw: torch.Tensor, G_bchw: torch.Tensor, eps: float = 1e-12) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    SSGrad-CAM (raw grid):\n",
    "      w_k = GAP(G_k)\n",
    "      S_k = |G_k| / max(|G_k|)\n",
    "      cam = ReLU( sum_k (w_k * A_k) ∘ S_k )\n",
    "    Returns: (1,1,h,w) normalized to [0,1]\n",
    "    \"\"\"\n",
    "    w = G_bchw.mean(dim=(2, 3), keepdim=True)                 # (1,C,1,1)\n",
    "    S = G_bchw.abs()\n",
    "    S = S / S.amax(dim=(2, 3), keepdim=True).clamp(min=eps)   # (1,C,h,w)\n",
    "    cam = ((w * A_bchw) * S).sum(dim=1, keepdim=True)         # (1,1,h,w)\n",
    "    cam = F.relu(cam)\n",
    "    return _normalize_11hw(cam, eps=eps)\n",
    "\n",
    "def gradxact_raw(A_bchw: torch.Tensor, G_bchw: torch.Tensor, eps: float = 1e-12) -> torch.Tensor:\n",
    "    # |grad * act| energy map on the same grid: (1,1,h,w) in [0,1]\n",
    "    m = (G_bchw * A_bchw).abs().sum(dim=1, keepdim=True)\n",
    "    return _normalize_11hw(m, eps=eps)\n",
    "\n",
    "def _overlay_pair(pil_img, m1_11hw, m2_11hw, title1, title2, suptitle=\"\", imgsz=640):\n",
    "    img = np.asarray(pil_img.convert(\"RGB\"))\n",
    "\n",
    "    def up(h):\n",
    "        return F.interpolate(h.detach().cpu(), size=(imgsz, imgsz), mode=\"nearest\")[0, 0].numpy()\n",
    "\n",
    "    h1 = up(m1_11hw)\n",
    "    h2 = up(m2_11hw)\n",
    "\n",
    "    plt.figure(figsize=(14, 5))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(img)\n",
    "    plt.imshow(h1, alpha=0.45, vmin=0.0, vmax=1.0)\n",
    "    plt.title(title1)\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(img)\n",
    "    plt.imshow(h2, alpha=0.45, vmin=0.0, vmax=1.0)\n",
    "    plt.title(title2)\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    if suptitle:\n",
    "        plt.suptitle(suptitle)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# -------------------\n",
    "# Pick balanced examples (equal successes & fails)\n",
    "# -------------------\n",
    "succ = [d for d in run_data if bool(d.get(\"success\", False))]\n",
    "fail = [d for d in run_data if not bool(d.get(\"success\", False))]\n",
    "\n",
    "n_each = max(1, NUM_EXAMPLES // 2)\n",
    "n_each = min(n_each, len(succ), len(fail))\n",
    "examples = succ[:n_each] + fail[:n_each]\n",
    "\n",
    "print(f\"[info] Using {len(examples)} examples: success={n_each}, fail={n_each}\")\n",
    "\n",
    "# -------------------\n",
    "# Run + plot\n",
    "# -------------------\n",
    "for d in examples:\n",
    "    gcinfo = d.get(\"gradcam_info\", {})\n",
    "    bbox = gcinfo.get(\"picked_bbox\", None)\n",
    "    if bbox is None:\n",
    "        print(\"[skip] no picked_bbox for\", d.get(\"path\", \"<?>\"))\n",
    "        continue\n",
    "\n",
    "    x_clean = torch_preprocess_letterboxed(d[\"clean_lb\"], device=CFG.device, dtype=_MODEL_DTYPE)\n",
    "\n",
    "    def _y_fn(model, x):\n",
    "        return target_topk_roi_logits_scalar(\n",
    "            model, x,\n",
    "            target_class_id=int(target_class_id),\n",
    "            imgsz=int(IMG_SIZE),\n",
    "            bbox_xyxy=tuple(float(v) for v in bbox),\n",
    "            topk=int(TOPK),\n",
    "        )\n",
    "\n",
    "    A, G, y = layer_act_and_grad_for_y(model_torch, x_clean, TARGET_LAYER, _y_fn)\n",
    "\n",
    "    ssg = ssgradcam_raw(A, G)\n",
    "    gxa = gradxact_raw(A, G)\n",
    "\n",
    "    title = (\n",
    "        f\"{Path(d['path']).name} | success={bool(d['success'])} | drop={float(d['drop']):.3f} | \"\n",
    "        f\"clean={float(d['conf_clean']):.3f} patched={float(d['conf_patch']):.3f} | y(top-{TOPK} ROI logits)={y:.3f}\"\n",
    "    )\n",
    "    print(title)\n",
    "\n",
    "    _overlay_pair(\n",
    "        d[\"clean_lb\"],\n",
    "        ssg, gxa,\n",
    "        title1=f\"SSGrad-CAM (top-{TOPK} ROI logits)\",\n",
    "        title2=\"|grad*act| (same y)\",\n",
    "        suptitle=title,\n",
    "        imgsz=int(IMG_SIZE),\n",
    "    )"
   ],
   "id": "abceb3dbcf04c792",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## SSGrad-CAM vs Grad-CAM: математика и интуиция (в терминах нашего кода)\n",
    "\n",
    "### Обозначения\n",
    "- Выбираем слой (например, `model.22`) и фиксируем вход (clean).\n",
    "- Активации слоя:  \n",
    "  $\n",
    "  A \\in \\mathbb{R}^{1\\times C\\times H\\times W}\n",
    "  $\n",
    "- Градиент целевой скалярной функции по активациям:  \n",
    "  $\n",
    "  G = \\frac{\\partial y}{\\partial A} \\in \\mathbb{R}^{1\\times C\\times H\\times W}\n",
    "  $\n",
    "- Целевая функция `y` у нас **не “класс-скор всей картинки”**, а скаляр, построенный из логитов детекции человека **в ROI**:  \n",
    "  мы берём по всем уровням головы logits карты для класса `person`, ограничиваемся ROI, выбираем top-K ячеек по `sigmoid(prob)`, и агрегируем **их logits** (обычно mean).  \n",
    "  Формально можно писать:\n",
    "  $\n",
    "  y = \\frac{1}{K}\\sum_{i\\in \\text{TopK}(\\sigma(L_{ROI}))} L_i\n",
    "  $\n",
    "  где \\(L\\) — логит-карта (по всем ROI-ячеек в head features), \\(\\sigma\\) — sigmoid, TopK выбирается по вероятностям, но агрегируются logits.\n",
    "\n",
    "---\n",
    "\n",
    "## Grad-CAM (классика)\n",
    "1) Считаем **канальные веса** через spatial average pooling градиента:\n",
    "$\n",
    "w_k = \\mathrm{GAP}(G_k) = \\frac{1}{HW}\\sum_{h=1}^{H}\\sum_{w=1}^{W} G_{k,h,w}\n",
    "$\n",
    "где \\(k\\in\\{1,\\dots,C\\}\\).\n",
    "\n",
    "2) Строим карту:\n",
    "$\n",
    "\\mathrm{CAM}_{h,w} = \\mathrm{ReLU}\\Big(\\sum_{k=1}^{C} w_k \\, A_{k,h,w}\\Big)\n",
    "$\n",
    "\n",
    "3) Нормируем в \\([0,1]\\) для визуализации.\n",
    "\n",
    "### Интуиция Grad-CAM\n",
    "- Градиент говорит, **какие каналы** важны для увеличения целевой функции \\(y\\) (через \\(w_k\\)).\n",
    "- Активации \\(A_{k,h,w}\\) говорят, **где** эти каналы “светятся”.\n",
    "- Итоговая карта: “где в пространстве находятся признаки, важные для \\(y\\)”.\n",
    "\n",
    "Ключевое ограничение: вся пространственная структура градиента внутри канала **сжимается в одно число** \\(w_k\\).  \n",
    "То есть Grad-CAM очень хорошо отвечает на “какие каналы важны”, но хуже — на “в каких точках карта действительно чувствительна”.\n",
    "\n",
    "---\n",
    "\n",
    "## SSGrad-CAM (как в нашем коде)\n",
    "SSGrad добавляет **пространственный гейт** на основе модуля градиента.\n",
    "\n",
    "1) Те же веса \\(w_k\\) (как в Grad-CAM):\n",
    "$\n",
    "w_k = \\mathrm{GAP}(G_k)\n",
    "$\n",
    "\n",
    "2) Строим **spatial scaling** (нормированный модуль градиента по каждому каналу):\n",
    "$\n",
    "S_{k,h,w} = \\frac{|G_{k,h,w}|}{\\max_{h,w}|G_{k,h,w}| + \\varepsilon}\n",
    "$\n",
    "Здесь \\(S_{k,h,w}\\in[0,1]\\), и он “внутри канала” подсвечивает места, где градиент большой.\n",
    "\n",
    "3) Карта SSGrad:\n",
    "$\n",
    "\\mathrm{SSCAM}_{h,w} = \\mathrm{ReLU}\\Big(\\sum_{k=1}^{C} \\big(w_k A_{k,h,w}\\big)\\cdot S_{k,h,w}\\Big)\n",
    "$\n",
    "\n",
    "4) Нормируем в \\([0,1]\\).\n",
    "\n",
    "### Интуиция SSGrad\n",
    "- \\(w_k\\) отвечает за “важность канала” (как в Grad-CAM),\n",
    "- \\(S_{k,h,w}\\) отвечает за “где внутри канала модель действительно **чувствительна** к \\(y\\)”,\n",
    "- поэтому SSGrad — это Grad-CAM, **дополнительно подавленный там, где градиенты малы**.\n",
    "\n",
    "Практический эффект:\n",
    "- карты обычно становятся **более локализованными** и менее “размазанными”;\n",
    "- SSGrad лучше отражает “что надо пошевелить, чтобы поменять \\(y\\)”, а не просто “что активно”.\n",
    "\n",
    "---\n",
    "\n",
    "## Чем это отличается от |grad * act|\n",
    "В нашем коде есть ещё карта:\n",
    "$\n",
    "M_{h,w} = \\sum_{k=1}^{C} |G_{k,h,w}\\cdot A_{k,h,w}|\n",
    "$\n",
    "Это чистая “энергия чувствительности”: одновременно учитывает и силу активаций, и силу градиентов, без каналных весов и без ReLU по сумме.\n",
    "\n",
    "Интуитивно:\n",
    "- **|grad*act|** — “где одновременно много активации и большой градиент” (часто очень контрастно).\n",
    "- **Grad-CAM** — “где активны важные каналы” (более гладко).\n",
    "- **SSGrad-CAM** — “где активны важные каналы И где градиент внутри канала реально большой” (обычно более точечно).\n",
    "\n",
    "---\n",
    "\n",
    "## Важный нюанс: что именно мы “объясняем”\n",
    "Поскольку \\(y\\) у нас = top-K ROI logits класса `person`, обе карты (Grad-CAM/SSGrad) объясняют **не весь детектор**, а именно:\n",
    "- “какие области входа влияют на логиты человека **в ROI** по выбранной схеме агрегации”.\n",
    "\n",
    "Поэтому эти карты корректно сравнивать с метриками типа “Δ в ROI / вне ROI” и “совпадение Δ с важностью”, но не стоит ожидать, что они всегда совпадут с NMS/финальным bbox после инференса."
   ],
   "id": "79a513247a13456a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "\n",
    "def compute_importance_tensors_for_all(\n",
    "    run_data,\n",
    "    model_torch,\n",
    "    target_layer: str,\n",
    "    target_class_id: int,\n",
    "    imgsz: int,\n",
    "    topk_roi: int = 3,\n",
    "    force_recompute: bool = False,\n",
    "):\n",
    "    \"\"\"\n",
    "    Для каждого примера (clean) считаем и сохраняем:\n",
    "      - imp_ssgrad_hw : (H,W) float32  [0..1]\n",
    "      - imp_gxa_hw    : (H,W) float32  [0..1]  (channel-summed |grad*act|)\n",
    "      - imp_gxa_chw   : (C,H,W) float32 >=0    (per-channel |grad*act|)\n",
    "      - imp_y_clean   : float (твоя ROI-целевая функция)\n",
    "    \"\"\"\n",
    "    for d in tqdm(run_data, desc=\"importance\", total=len(run_data)):\n",
    "        if (not force_recompute) and (\"imp_gxa_chw\" in d) and (\"imp_ssgrad_hw\" in d):\n",
    "            continue\n",
    "\n",
    "        gcinfo = d.get(\"gradcam_info\", {})\n",
    "        bbox = gcinfo.get(\"picked_bbox\", None) if isinstance(gcinfo, dict) else None\n",
    "        if bbox is None:\n",
    "            d[\"imp_ssgrad_hw\"] = None\n",
    "            d[\"imp_gxa_hw\"] = None\n",
    "            d[\"imp_gxa_chw\"] = None\n",
    "            d[\"imp_y_clean\"] = float(\"nan\")\n",
    "            continue\n",
    "\n",
    "        x_clean = torch_preprocess_letterboxed(d[\"clean_lb\"], device=CFG.device, dtype=_MODEL_DTYPE)\n",
    "\n",
    "        def _y_fn(model, x):\n",
    "            return target_topk_roi_logits_scalar(\n",
    "                model, x,\n",
    "                target_class_id=int(target_class_id),\n",
    "                imgsz=int(imgsz),\n",
    "                bbox_xyxy=tuple(float(v) for v in bbox),\n",
    "                topk=int(topk_roi),\n",
    "            )\n",
    "\n",
    "        A, G, y = layer_act_and_grad_for_y(model_torch, x_clean, target_layer, _y_fn)  # (1,C,H,W)\n",
    "\n",
    "        # SSGrad: (1,1,H,W) in [0,1]\n",
    "        ssg_11hw = ssgradcam_raw(A, G)\n",
    "        # grad*act HxW: (1,1,H,W) in [0,1]\n",
    "        gxa_11hw = gradxact_raw(A, G)\n",
    "\n",
    "        # grad*act full: (C,H,W) >= 0\n",
    "        gxa_chw = (G[0] * A[0]).abs().to(torch.float32)\n",
    "\n",
    "        d[\"imp_ssgrad_hw\"] = ssg_11hw[0, 0].numpy().astype(np.float32)\n",
    "        d[\"imp_gxa_hw\"] = gxa_11hw[0, 0].numpy().astype(np.float32)\n",
    "        d[\"imp_gxa_chw\"] = gxa_chw.numpy().astype(np.float32)\n",
    "        d[\"imp_y_clean\"] = float(y)\n",
    "\n",
    "# запуск\n",
    "compute_importance_tensors_for_all(\n",
    "    run_data=run_data,\n",
    "    model_torch=model_torch,\n",
    "    target_layer=\"model.22\",\n",
    "    target_class_id=int(target_class_id),\n",
    "    imgsz=int(CFG.imgsz),\n",
    "    topk_roi=3,\n",
    "    force_recompute=False,\n",
    ")"
   ],
   "id": "7a0e62443bf35dc4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "def _safe_l2(a: np.ndarray, b: np.ndarray, eps: float = 1e-12) -> float:\n",
    "    \"\"\"Euclidean (L2) distance between flattened arrays, ignoring non-finite entries.\"\"\"\n",
    "    a = np.asarray(a, dtype=np.float64).reshape(-1)\n",
    "    b = np.asarray(b, dtype=np.float64).reshape(-1)\n",
    "    m = np.isfinite(a) & np.isfinite(b)\n",
    "    a = a[m]; b = b[m]\n",
    "    if a.size == 0:\n",
    "        return float(\"nan\")\n",
    "    return float(np.linalg.norm(a - b))\n",
    "\n",
    "\n",
    "def _safe_l2_rel(a: np.ndarray, b: np.ndarray, eps: float = 1e-12) -> float:\n",
    "    \"\"\"Globally-normalized L2: ||a-b|| / (||a|| + ||b||).\"\"\"\n",
    "    a = np.asarray(a, dtype=np.float64).reshape(-1)\n",
    "    b = np.asarray(b, dtype=np.float64).reshape(-1)\n",
    "    m = np.isfinite(a) & np.isfinite(b)\n",
    "    a = a[m]; b = b[m]\n",
    "    if a.size == 0:\n",
    "        return float(\"nan\")\n",
    "    na = float(np.linalg.norm(a))\n",
    "    nb = float(np.linalg.norm(b))\n",
    "    den = max(na + nb, eps)\n",
    "    return float(np.linalg.norm(a - b) / den)\n",
    "\n",
    "def _safe_cosine(a: np.ndarray, b: np.ndarray, eps: float = 1e-12) -> float:\n",
    "    a = np.asarray(a, dtype=np.float64).reshape(-1)\n",
    "    b = np.asarray(b, dtype=np.float64).reshape(-1)\n",
    "    m = np.isfinite(a) & np.isfinite(b)\n",
    "    a = a[m]; b = b[m]\n",
    "    if a.size == 0:\n",
    "        return float(\"nan\")\n",
    "    na = float(np.linalg.norm(a))\n",
    "    nb = float(np.linalg.norm(b))\n",
    "    if na <= eps or nb <= eps:\n",
    "        return float(\"nan\")\n",
    "    return float(np.dot(a, b) / (na * nb))\n",
    "\n",
    "def _topq_energy_frac(delta_hw: np.ndarray, imp_hw: np.ndarray, q: float = 10.0, eps: float = 1e-12) -> float:\n",
    "    \"\"\"Доля энергии |Δ| в top-q% наиболее важных ячейках.\"\"\"\n",
    "    d = np.abs(np.asarray(delta_hw, dtype=np.float64))\n",
    "    w = np.clip(np.asarray(imp_hw, dtype=np.float64), 0.0, None)\n",
    "    if d.shape != w.shape:\n",
    "        raise ValueError(f\"shape mismatch: delta {d.shape} vs imp {w.shape}\")\n",
    "    flat_w = w.reshape(-1)\n",
    "    if flat_w.size == 0:\n",
    "        return float(\"nan\")\n",
    "    thr = np.percentile(flat_w, 100.0 - float(q))\n",
    "    mask = w >= thr\n",
    "    num = float(d[mask].sum())\n",
    "    den = float(d.sum())\n",
    "    return float(num / den) if den > eps else 0.0\n",
    "\n",
    "def _jaccard_topk(a: np.ndarray, b: np.ndarray, k: int = 32) -> float:\n",
    "    a = np.asarray(a, dtype=np.float64).reshape(-1)\n",
    "    b = np.asarray(b, dtype=np.float64).reshape(-1)\n",
    "    if a.size == 0 or b.size == 0:\n",
    "        return float(\"nan\")\n",
    "    k = int(min(max(k, 1), a.size, b.size))\n",
    "    ia = set(np.argpartition(a, -k)[-k:].tolist())\n",
    "    ib = set(np.argpartition(b, -k)[-k:].tolist())\n",
    "    inter = len(ia & ib)\n",
    "    union = len(ia | ib)\n",
    "    return float(inter / union) if union else float(\"nan\")\n",
    "\n",
    "def compute_delta_importance_metrics(\n",
    "    delta_bchw: torch.Tensor,\n",
    "    imp_ssgrad_hw,\n",
    "    imp_gxa_hw,\n",
    "    imp_gxa_chw,\n",
    "    reduce_mode_hw: str = \"l2\",\n",
    "    topk: int = 32,\n",
    "    topq: float = 10.0,\n",
    ") -> dict:\n",
    "    if delta_bchw is None:\n",
    "        return {}\n",
    "\n",
    "    d_chw = delta_bchw[0].float()  # (C,H,W)\n",
    "    C, H, W = d_chw.shape\n",
    "\n",
    "    # |Δ| full\n",
    "    delta_abs_chw = d_chw.abs().detach().cpu().numpy().astype(np.float32)\n",
    "\n",
    "    # |Δ|_hw (мagnitude карта для сопоставления с HxW importance)\n",
    "    delta_hw = _reduce_channels(d_chw, mode=reduce_mode_hw, topk=topk).detach().cpu().numpy().astype(np.float32)\n",
    "    delta_hw_abs = delta_hw if reduce_mode_hw in {\"l2\", \"abs_mean\"} else np.abs(delta_hw)\n",
    "\n",
    "    out = {}\n",
    "\n",
    "    # --- HxW: SSGrad ---\n",
    "    if imp_ssgrad_hw is not None:\n",
    "        out[\"cos_hw_ssgrad\"] = _safe_cosine(delta_hw_abs, imp_ssgrad_hw)\n",
    "        out[\"topq_energy_frac_ssgrad\"] = _topq_energy_frac(delta_hw_abs, imp_ssgrad_hw, q=topq)\n",
    "        out[\"l2_hw_ssgrad\"] = _safe_l2(delta_hw_abs, imp_ssgrad_hw)\n",
    "        out[\"l2rel_hw_ssgrad\"] = _safe_l2_rel(delta_hw_abs, imp_ssgrad_hw)\n",
    "    else:\n",
    "        out[\"cos_hw_ssgrad\"] = float(\"nan\")\n",
    "        out[\"topq_energy_frac_ssgrad\"] = float(\"nan\")\n",
    "        out[\"l2_hw_ssgrad\"] = float(\"nan\")\n",
    "        out[\"l2rel_hw_ssgrad\"] = float(\"nan\")\n",
    "\n",
    "    # --- HxW: grad*act (collapsed) ---\n",
    "    if imp_gxa_hw is not None:\n",
    "        out[\"cos_hw_gxa\"] = _safe_cosine(delta_hw_abs, imp_gxa_hw)\n",
    "        out[\"topq_energy_frac_gxa\"] = _topq_energy_frac(delta_hw_abs, imp_gxa_hw, q=topq)\n",
    "        out[\"l2_hw_gxa\"] = _safe_l2(delta_hw_abs, imp_gxa_hw)\n",
    "        out[\"l2rel_hw_gxa\"] = _safe_l2_rel(delta_hw_abs, imp_gxa_hw)\n",
    "    else:\n",
    "        out[\"cos_hw_gxa\"] = float(\"nan\")\n",
    "        out[\"topq_energy_frac_gxa\"] = float(\"nan\")\n",
    "        out[\"l2_hw_gxa\"] = float(\"nan\")\n",
    "        out[\"l2rel_hw_gxa\"] = float(\"nan\")\n",
    "\n",
    "    # --- CxHxW: grad*act (full) ---\n",
    "    if imp_gxa_chw is not None:\n",
    "        gxa = np.asarray(imp_gxa_chw, dtype=np.float32)\n",
    "        if gxa.shape != delta_abs_chw.shape:\n",
    "            raise ValueError(f\"gxa_chw shape {gxa.shape} != delta_chw shape {delta_abs_chw.shape}\")\n",
    "\n",
    "        out[\"cos_chw_gxa\"] = _safe_cosine(delta_abs_chw, gxa)\n",
    "        out[\"l2_chw_gxa\"] = _safe_l2(delta_abs_chw, gxa)\n",
    "        out[\"l2rel_chw_gxa\"] = _safe_l2_rel(delta_abs_chw, gxa)\n",
    "\n",
    "        E_delta = delta_abs_chw.reshape(C, -1).mean(axis=1)\n",
    "        E_gxa = gxa.reshape(C, -1).mean(axis=1)\n",
    "\n",
    "        rho = spearmanr(E_delta, E_gxa).correlation\n",
    "        out[\"spearman_chan_energy_gxa\"] = float(rho) if rho is not None else float(\"nan\")\n",
    "        out[\"jaccard_topk_chan_gxa\"] = _jaccard_topk(E_delta, E_gxa, k=topk)\n",
    "    else:\n",
    "        out[\"cos_chw_gxa\"] = float(\"nan\")\n",
    "        out[\"spearman_chan_energy_gxa\"] = float(\"nan\")\n",
    "        out[\"jaccard_topk_chan_gxa\"] = float(\"nan\")\n",
    "        out[\"l2_chw_gxa\"] = float(\"nan\")\n",
    "        out[\"l2rel_chw_gxa\"] = float(\"nan\")\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "# Добавляем новые колонки в df\n",
    "LAYER = \"model.22\"\n",
    "new_rows = []\n",
    "for d in run_data:\n",
    "    nm = compute_delta_importance_metrics(\n",
    "        delta_bchw=d.get(\"deltas\", {}).get(LAYER, None),\n",
    "        imp_ssgrad_hw=d.get(\"imp_ssgrad_hw\", None),\n",
    "        imp_gxa_hw=d.get(\"imp_gxa_hw\", None),\n",
    "        imp_gxa_chw=d.get(\"imp_gxa_chw\", None),\n",
    "        reduce_mode_hw=\"l2\",\n",
    "        topk=int(CFG.topk_channels),\n",
    "        topq=10.0,\n",
    "    )\n",
    "    new_rows.append(nm)\n",
    "\n",
    "new_df = pd.DataFrame(new_rows)\n",
    "for c in new_df.columns:\n",
    "    df[c] = new_df[c]\n",
    "\n",
    "print(\"Added:\", list(new_df.columns))\n",
    "df[[\"success\", \"drop\"] + list(new_df.columns)].head(10)"
   ],
   "id": "ae834347d261f43",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import roc_auc_score, balanced_accuracy_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def roc_auc_for_metric(df: pd.DataFrame, metric: str, label_col: str = \"success\") -> tuple[float, int]:\n",
    "    \"\"\"\n",
    "    Return (AUC>=0.5, direction).\n",
    "    direction = +1: larger metric -> more likely SUCCESS\n",
    "    direction = -1: smaller metric -> more likely SUCCESS\n",
    "    \"\"\"\n",
    "    y = df[label_col].astype(int).to_numpy()\n",
    "    x = df[metric].to_numpy().astype(float)\n",
    "\n",
    "    m = np.isfinite(x) & np.isfinite(y)\n",
    "    x = x[m]; y = y[m]\n",
    "    if np.unique(y).size < 2:\n",
    "        return float(\"nan\"), 0\n",
    "\n",
    "    auc_raw = float(roc_auc_score(y, x))\n",
    "    direction = +1\n",
    "    auc = auc_raw\n",
    "    if auc_raw < 0.5:\n",
    "        auc = 1.0 - auc_raw\n",
    "        direction = -1\n",
    "    return float(auc), int(direction)\n",
    "\n",
    "def best_balanced_accuracy_for_metric(\n",
    "    df: pd.DataFrame,\n",
    "    metric: str,\n",
    "    label_col: str = \"success\",\n",
    "    *,\n",
    "    direction: int | None = None,\n",
    ") -> tuple[float, float, int]:\n",
    "    \"\"\"Best balanced accuracy achievable by thresholding a single scalar metric.\n",
    "\n",
    "    Returns:\n",
    "      (best_bal_acc, best_threshold, used_direction)\n",
    "\n",
    "    used_direction:\n",
    "      +1 => predict SUCCESS when x >= thr\n",
    "      -1 => predict SUCCESS when x <= thr\n",
    "    \"\"\"\n",
    "    y = df[label_col].astype(int).to_numpy()\n",
    "    x = df[metric].to_numpy().astype(float)\n",
    "\n",
    "    m = np.isfinite(x) & np.isfinite(y)\n",
    "    x = x[m]\n",
    "    y = y[m]\n",
    "\n",
    "    if x.size == 0 or np.unique(y).size < 2:\n",
    "        return float(\"nan\"), float(\"nan\"), 0\n",
    "\n",
    "    if direction is None:\n",
    "        _auc, direction = roc_auc_for_metric(df.loc[m], metric, label_col=label_col)\n",
    "\n",
    "    direction = +1 if int(direction) >= 0 else -1\n",
    "\n",
    "    xs = np.unique(x)\n",
    "    if xs.size == 1:\n",
    "        thr = float(xs[0])\n",
    "        yhat = (x >= thr) if direction == +1 else (x <= thr)\n",
    "        ba = float(balanced_accuracy_score(y, yhat.astype(int)))\n",
    "        return ba, thr, int(direction)\n",
    "\n",
    "    mids = (xs[:-1] + xs[1:]) * 0.5\n",
    "    thr_candidates = np.concatenate(([xs[0] - 1e-12], mids, [xs[-1] + 1e-12]))\n",
    "\n",
    "    best_ba = -1.0\n",
    "    best_thr = float(\"nan\")\n",
    "\n",
    "    for thr in thr_candidates:\n",
    "        yhat = (x >= thr) if direction == +1 else (x <= thr)\n",
    "        ba = float(balanced_accuracy_score(y, yhat.astype(int)))\n",
    "        if ba > best_ba:\n",
    "            best_ba = ba\n",
    "            best_thr = float(thr)\n",
    "\n",
    "    return float(best_ba), float(best_thr), int(direction)\n",
    "\n",
    "# --- ONLY NEW: Δ vs importance (SSGrad / grad*act) ---\n",
    "metric_cols = [\n",
    "    # SSGrad (HxW)\n",
    "    \"cos_hw_ssgrad\",\n",
    "    \"topq_energy_frac_ssgrad\",\n",
    "    \"l2_hw_ssgrad\",\n",
    "    \"l2rel_hw_ssgrad\",\n",
    "\n",
    "    # grad*act (HxW)\n",
    "    \"cos_hw_gxa\",\n",
    "    \"topq_energy_frac_gxa\",\n",
    "    \"l2_hw_gxa\",\n",
    "    \"l2rel_hw_gxa\",\n",
    "\n",
    "    # grad*act (CxHxW)\n",
    "    \"cos_chw_gxa\",\n",
    "    \"l2_chw_gxa\",\n",
    "    \"l2rel_chw_gxa\",\n",
    "    \"spearman_chan_energy_gxa\",\n",
    "    \"jaccard_topk_chan_gxa\",\n",
    "]\n",
    "\n",
    "succ = df[df.success == True]\n",
    "fail = df[df.success == False]\n",
    "\n",
    "summary = []\n",
    "for c in metric_cols:\n",
    "    if c not in df.columns:\n",
    "        continue\n",
    "    xs = succ[c].to_numpy()\n",
    "    xf = fail[c].to_numpy()\n",
    "    auc, direction = roc_auc_for_metric(df, c, label_col=\"success\")\n",
    "    bacc, bthr, _ = best_balanced_accuracy_for_metric(df, c, label_col=\"success\", direction=direction)\n",
    "\n",
    "    summary.append({\n",
    "        \"metric\": c,\n",
    "        \"mean_s\": float(np.nanmean(xs)),\n",
    "        \"mean_f\": float(np.nanmean(xf)),\n",
    "        \"std_s\": float(np.nanstd(xs)),\n",
    "        \"std_f\": float(np.nanstd(xf)),\n",
    "        \"best_bal_acc\": bacc,\n",
    "        \"best_bal_thr\": bthr,\n",
    "        \"roc_auc\": auc,\n",
    "        \"auc_direction\": direction,\n",
    "    })\n",
    "\n",
    "summary_df = pd.DataFrame(summary).sort_values(\"roc_auc\", ascending=False)\n",
    "summary_df"
   ],
   "id": "5168846abb89967d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def _metric_family(m: str) -> str:\n",
    "    if m.endswith(\"_ssgrad\"):\n",
    "        return \"SSGrad (HxW)\"\n",
    "    if m.endswith(\"_gxa\") and m.startswith(\"cos_hw\"):\n",
    "        return \"grad*act (HxW)\"\n",
    "    if m.endswith(\"_gxa\") and (m.startswith(\"cos_chw\") or m.startswith(\"spearman\") or m.startswith(\"jaccard\")):\n",
    "        return \"grad*act (CxHxW)\"\n",
    "    return \"Δ vs importance\"\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def _violin_metric(ax, data_s, data_f, title: str):\n",
    "    \"\"\"Robust distribution viz for FAIL vs SUCCESS.\n",
    "\n",
    "    Uses violin + median lines + jittered scatter.\n",
    "    Works well when std is tiny (boxplots collapse to a line) or values are discretized.\n",
    "    \"\"\"\n",
    "    data_s = np.asarray(data_s, dtype=float)\n",
    "    data_f = np.asarray(data_f, dtype=float)\n",
    "\n",
    "    data_s = data_s[np.isfinite(data_s)]\n",
    "    data_f = data_f[np.isfinite(data_f)]\n",
    "\n",
    "    if (data_s.size == 0) and (data_f.size == 0):\n",
    "        ax.text(0.5, 0.5, \"no finite data\", ha=\"center\", va=\"center\")\n",
    "        ax.set_axis_off()\n",
    "        return\n",
    "\n",
    "    series = []\n",
    "    labels = []\n",
    "    positions = []\n",
    "\n",
    "    if data_f.size:\n",
    "        series.append(data_f)\n",
    "        labels.append(f\"FAIL (n={data_f.size})\")\n",
    "        positions.append(1)\n",
    "\n",
    "    if data_s.size:\n",
    "        series.append(data_s)\n",
    "        labels.append(f\"SUCCESS (n={data_s.size})\")\n",
    "        positions.append(2 if data_f.size else 1)\n",
    "\n",
    "    # violin\n",
    "    vp = ax.violinplot(\n",
    "        series,\n",
    "        positions=positions,\n",
    "        widths=0.8,\n",
    "        showmeans=False,\n",
    "        showmedians=True,\n",
    "        showextrema=False,\n",
    "    )\n",
    "\n",
    "    # jittered scatter to show discretization / collapsed distributions\n",
    "    rng = np.random.default_rng(0)\n",
    "    if data_f.size:\n",
    "        jf = (rng.random(data_f.size) - 0.5) * 0.16\n",
    "        ax.scatter(np.full(data_f.size, 1.0) + jf, data_f, s=10, alpha=0.35)\n",
    "        ax.hlines(np.median(data_f), 0.78, 1.22, linewidth=3)\n",
    "\n",
    "    if data_s.size:\n",
    "        xs = 2.0 if data_f.size else 1.0\n",
    "        js = (rng.random(data_s.size) - 0.5) * 0.16\n",
    "        ax.scatter(np.full(data_s.size, xs) + js, data_s, s=10, alpha=0.35)\n",
    "        ax.hlines(np.median(data_s), xs - 0.22, xs + 0.22, linewidth=3)\n",
    "\n",
    "    ax.set_xticks(positions)\n",
    "    ax.set_xticklabels(labels)\n",
    "    ax.set_title(title)\n",
    "    ax.grid(True, alpha=0.25)\n",
    "\n",
    "topM = 12\n",
    "\n",
    "# Plot only the new metrics (same order as metric_cols; fall back to summary_df ordering)\n",
    "if \"metric_cols\" in globals():\n",
    "    allowed = set(metric_cols)\n",
    "    order_df = summary_df[summary_df[\"metric\"].isin(allowed)].sort_values(\"best_bal_acc\", ascending=False)\n",
    "    best = order_df.head(topM)[\"metric\"].tolist()\n",
    "else:\n",
    "    best = summary_df.sort_values(\"best_bal_acc\", ascending=False).head(topM)[\"metric\"].tolist()\n",
    "\n",
    "succ = df[df.success == True]\n",
    "fail = df[df.success == False]\n",
    "\n",
    "fig = plt.figure(figsize=(14, 3.2 * ((len(best) + 1) // 2)))\n",
    "for i, m in enumerate(best, 1):\n",
    "    ax = plt.subplot((len(best) + 1) // 2, 2, i)\n",
    "    fam = _metric_family(m)\n",
    "    _violin_metric(\n",
    "        ax,\n",
    "        succ[m].to_numpy(),\n",
    "        fail[m].to_numpy(),\n",
    "        f\"{m} | AUC={summary_df.set_index('metric').loc[m, 'roc_auc']:.3g} | bAcc={summary_df.set_index('metric').loc[m, 'best_bal_acc']:.3g}\",\n",
    "    )\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure(figsize=(9.5, 0.42 * len(summary_df) + 1.5))\n",
    "order = summary_df.sort_values(\"best_bal_acc\", ascending=True)\n",
    "plt.barh(order[\"metric\"], order[\"best_bal_acc\"])\n",
    "plt.xlabel(\"best_bal_acc (>=0.5; higher is better)\")\n",
    "plt.title(\"best_bal_acc for Δ vs importance metrics\")\n",
    "plt.grid(True, axis=\"x\", alpha=0.25)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "5aa14f594910fdc3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# -------------------------\n",
    "# Helpers: top-K energy stats\n",
    "# -------------------------\n",
    "\n",
    "def _topk_indices(x_flat: np.ndarray, k: int):\n",
    "    x = np.asarray(x_flat, dtype=np.float64).reshape(-1)\n",
    "    n = x.size\n",
    "    if n == 0:\n",
    "        return np.array([], dtype=np.int64)\n",
    "    k = int(min(max(int(k), 1), n))\n",
    "    return np.argpartition(x, -k)[-k:]\n",
    "\n",
    "def _energy_frac_in_topk(delta_abs_flat: np.ndarray, imp_flat: np.ndarray, k: int, eps: float = 1e-12):\n",
    "    \"\"\"\n",
    "    frac   = sum(|Δ| over topK(imp)) / sum(|Δ|)\n",
    "    enrich = frac / (K/N)\n",
    "    \"\"\"\n",
    "    d = np.asarray(delta_abs_flat, dtype=np.float64).reshape(-1)\n",
    "    w = np.asarray(imp_flat, dtype=np.float64).reshape(-1)\n",
    "    m = np.isfinite(d) & np.isfinite(w)\n",
    "    d = d[m]; w = w[m]\n",
    "    n = d.size\n",
    "    if n == 0:\n",
    "        return float(\"nan\"), float(\"nan\")\n",
    "\n",
    "    den = float(d.sum())\n",
    "    if den <= eps:\n",
    "        return 0.0, 0.0\n",
    "\n",
    "    idx = _topk_indices(w, k)\n",
    "    num = float(d[idx].sum())\n",
    "    frac = float(num / den)\n",
    "\n",
    "    k_eff = int(min(max(int(k), 1), n))\n",
    "    base = float(k_eff / n)\n",
    "    enrich = float(frac / max(base, eps))\n",
    "    return frac, enrich\n",
    "\n",
    "def _jaccard_topk_sets(a_flat: np.ndarray, b_flat: np.ndarray, k: int):\n",
    "    a = np.asarray(a_flat, dtype=np.float64).reshape(-1)\n",
    "    b = np.asarray(b_flat, dtype=np.float64).reshape(-1)\n",
    "    m = np.isfinite(a) & np.isfinite(b)\n",
    "    a = a[m]; b = b[m]\n",
    "    if a.size == 0:\n",
    "        return float(\"nan\")\n",
    "    k = int(min(max(int(k), 1), a.size))\n",
    "    ia = set(_topk_indices(a, k).tolist())\n",
    "    ib = set(_topk_indices(b, k).tolist())\n",
    "    inter = len(ia & ib)\n",
    "    union = len(ia | ib)\n",
    "    return float(inter / union) if union else float(\"nan\")\n",
    "\n",
    "# -------------------------\n",
    "# Compute per-image metrics for multiple K\n",
    "# -------------------------\n",
    "assert \"run_data\" in globals() and \"df\" in globals(), \"Need run_data and df.\"\n",
    "\n",
    "LAYER = \"model.22\"\n",
    "\n",
    "# Для CHW: всего 512*20*20 ~ 204_800 элементов → K можно брать больше\n",
    "K_LIST_CHW = [200, 500, 1000, 2000, 5000]\n",
    "\n",
    "# Для HW: всего 20*20 = 400 элементов → K поменьше\n",
    "K_LIST_HW  = [10, 25, 50, 100, 200]\n",
    "\n",
    "rows = []\n",
    "for d in run_data:\n",
    "    delta = d.get(\"deltas\", {}).get(LAYER, None)\n",
    "    if delta is None:\n",
    "        rows.append({})\n",
    "        continue\n",
    "\n",
    "    d_chw = delta[0].float()  # (C,H,W)\n",
    "    C, H, W = d_chw.shape\n",
    "    delta_abs_chw = d_chw.abs().detach().cpu().numpy().astype(np.float32)\n",
    "    delta_abs_flat = delta_abs_chw.reshape(-1)\n",
    "\n",
    "    # Importance tensors (already computed earlier)\n",
    "    imp_chw     = d.get(\"imp_gxa_chw\", None)     # (C,H,W) >=0\n",
    "    imp_gxa_hw  = d.get(\"imp_gxa_hw\", None)      # (H,W)   in [0,1]\n",
    "    imp_ss_hw   = d.get(\"imp_ssgrad_hw\", None)   # (H,W)   in [0,1]\n",
    "\n",
    "    out = {}\n",
    "\n",
    "    # ---- grad*act full (CxHxW): energy in top-K important features ----\n",
    "    if imp_chw is not None:\n",
    "        imp_flat = np.asarray(imp_chw, dtype=np.float32).reshape(-1)\n",
    "        for k in K_LIST_CHW:\n",
    "            frac, enrich = _energy_frac_in_topk(delta_abs_flat, imp_flat, k=k)\n",
    "            out[f\"focus_frac__gxa_chw_k{k}\"] = frac\n",
    "            out[f\"enrichE_impTopK_gxa_chw_k{k}\"] = enrich\n",
    "            out[f\"overlap_jacc__gxa_chw_k{k}\"] = _jaccard_topk_sets(delta_abs_flat, imp_flat, k=k)\n",
    "    else:\n",
    "        for k in K_LIST_CHW:\n",
    "            out[f\"focus_frac__gxa_chw_k{k}\"] = float(\"nan\")\n",
    "            out[f\"enrichE_impTopK_gxa_chw_k{k}\"] = float(\"nan\")\n",
    "            out[f\"overlap_jacc__gxa_chw_k{k}\"] = float(\"nan\")\n",
    "\n",
    "    # ---- collapsed HxW: compare |Δ|_hw to HxW importance ----\n",
    "    # magnitude map for Δ on HxW grid (same reducer as elsewhere)\n",
    "    delta_hw = _reduce_channels(d_chw, mode=\"l2\", topk=int(CFG.topk_channels)).detach().cpu().numpy().astype(np.float32)\n",
    "    delta_hw_flat = delta_hw.reshape(-1)  # non-negative\n",
    "\n",
    "    if imp_gxa_hw is not None:\n",
    "        imp_flat = np.asarray(imp_gxa_hw, dtype=np.float32).reshape(-1)\n",
    "        for k in K_LIST_HW:\n",
    "            frac, enrich = _energy_frac_in_topk(delta_hw_flat, imp_flat, k=k)\n",
    "            out[f\"focus_frac__gxa_hw_k{k}\"] = frac\n",
    "            out[f\"enrichE_impTopK_gxa_hw_k{k}\"] = enrich\n",
    "    else:\n",
    "        for k in K_LIST_HW:\n",
    "            out[f\"focus_frac__gxa_hw_k{k}\"] = float(\"nan\")\n",
    "            out[f\"enrichE_impTopK_gxa_hw_k{k}\"] = float(\"nan\")\n",
    "\n",
    "    if imp_ss_hw is not None:\n",
    "        imp_flat = np.asarray(imp_ss_hw, dtype=np.float32).reshape(-1)\n",
    "        for k in K_LIST_HW:\n",
    "            frac, enrich = _energy_frac_in_topk(delta_hw_flat, imp_flat, k=k)\n",
    "            out[f\"focus_frac__ssgrad_hw_k{k}\"] = frac\n",
    "            out[f\"enrichE_impTopK_ssgrad_hw_k{k}\"] = enrich\n",
    "    else:\n",
    "        for k in K_LIST_HW:\n",
    "            out[f\"focus_frac__ssgrad_hw_k{k}\"] = float(\"nan\")\n",
    "            out[f\"enrichE_impTopK_ssgrad_hw_k{k}\"] = float(\"nan\")\n",
    "\n",
    "    rows.append(out)\n",
    "\n",
    "new_topk_df = pd.DataFrame(rows)\n",
    "for c in new_topk_df.columns:\n",
    "    df[c] = new_topk_df[c]\n",
    "\n",
    "print(\"Added TOP-K energy columns:\")\n",
    "print(list(new_topk_df.columns))\n",
    "\n",
    "# -------------------------\n",
    "# Quick visualization: frac/enrich vs success for a few K\n",
    "# -------------------------\n",
    "def _plot_scatter(df, xcol, ycol, title):\n",
    "    s = df[df.success == True]\n",
    "    f = df[df.success == False]\n",
    "    plt.figure(figsize=(6.2, 4.6))\n",
    "    plt.scatter(f[xcol], f[ycol], s=18, alpha=0.55, label=\"FAIL\")\n",
    "    plt.scatter(s[xcol], s[ycol], s=18, alpha=0.55, label=\"SUCCESS\")\n",
    "    plt.xlabel(xcol)\n",
    "    plt.ylabel(ycol)\n",
    "    plt.title(title)\n",
    "    plt.grid(True, alpha=0.25)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# total delta energy for CHW (L1)\n",
    "if \"delta_energy_l1\" not in df.columns:\n",
    "    energies = []\n",
    "    for d in run_data:\n",
    "        delta = d.get(\"deltas\", {}).get(LAYER, None)\n",
    "        if delta is None:\n",
    "            energies.append(float(\"nan\"))\n",
    "        else:\n",
    "            dd = delta[0].float().abs().detach().cpu().numpy()\n",
    "            energies.append(float(dd.sum()))\n",
    "    df[\"delta_energy_l1\"] = energies\n",
    "\n",
    "for k in [500, 2000, 5000]:\n",
    "    colf = f\"focus_frac__gxa_chw_k{k}\"\n",
    "    cole = f\"enrichE_impTopK_gxa_chw_k{k}\"\n",
    "    if colf in df.columns:\n",
    "        _plot_scatter(df, \"delta_energy_l1\", colf, f\"grad*act CHW: frac energy in top-{k} important features\")\n",
    "    if cole in df.columns:\n",
    "        _plot_scatter(df, \"delta_energy_l1\", cole, f\"grad*act CHW: enrichment (top-{k})\")"
   ],
   "id": "3590a5f3e847f15",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# --- RAW L2 energy inside top-K important features (NO normalization) + ROC-AUC for all K=2000 metrics ---\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score, balanced_accuracy_score\n",
    "\n",
    "K = 2000\n",
    "LAYER = \"model.22\"\n",
    "\n",
    "# ---------------------------\n",
    "# Compute raw L2 inside/outside top-K important (CHW)\n",
    "# ---------------------------\n",
    "l2_in_list = []\n",
    "l2_out_list = []\n",
    "\n",
    "for d in run_data:\n",
    "    delta = d.get(\"deltas\", {}).get(LAYER, None)\n",
    "    imp_chw = d.get(\"imp_gxa_chw\", None)\n",
    "\n",
    "    if (delta is None) or (imp_chw is None):\n",
    "        l2_in_list.append(float(\"nan\"))\n",
    "        l2_out_list.append(float(\"nan\"))\n",
    "        continue\n",
    "\n",
    "    d_chw = delta[0].float()\n",
    "    delta_abs_flat = d_chw.abs().detach().cpu().numpy().astype(np.float32).reshape(-1)\n",
    "    imp_flat = np.asarray(imp_chw, dtype=np.float32).reshape(-1)\n",
    "\n",
    "    m = np.isfinite(delta_abs_flat) & np.isfinite(imp_flat)\n",
    "    dflat = delta_abs_flat[m]\n",
    "    wflat = imp_flat[m]\n",
    "    n = dflat.size\n",
    "    if n == 0:\n",
    "        l2_in_list.append(float(\"nan\"))\n",
    "        l2_out_list.append(float(\"nan\"))\n",
    "        continue\n",
    "\n",
    "    k_eff = int(min(max(int(K), 1), n))\n",
    "    idx = _topk_idx(wflat, k_eff)  # top-K by importance\n",
    "\n",
    "    mask = np.zeros(n, dtype=bool)\n",
    "    mask[idx] = True\n",
    "\n",
    "    din = dflat[mask]\n",
    "    dout = dflat[~mask]\n",
    "\n",
    "    l2_in_list.append(float(np.linalg.norm(din)) if din.size else float(\"nan\"))\n",
    "    l2_out_list.append(float(np.linalg.norm(dout)) if dout.size else float(\"nan\"))\n",
    "\n",
    "col_l2_in  = f\"l2_in_topk__gxa_chw_k{K}\"\n",
    "col_l2_out = f\"l2_out_topk__gxa_chw_k{K}\"\n",
    "df[col_l2_in] = l2_in_list\n",
    "df[col_l2_out] = l2_out_list\n",
    "\n",
    "# IMPORTANT: create ratio BEFORE succ/fail slicing (fixes your KeyError)\n",
    "col_l2_ratio = f\"l2_ratio_in_out__gxa_chw_k{K}\"\n",
    "with np.errstate(divide=\"ignore\", invalid=\"ignore\"):\n",
    "    df[col_l2_ratio] = df[col_l2_in] / df[col_l2_out]\n",
    "\n",
    "print(\"Added:\", col_l2_in, col_l2_out, col_l2_ratio)\n",
    "print(df[[\"success\", \"drop\", col_l2_in, col_l2_out, col_l2_ratio]].head(12))\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# Violin plots (3 side-by-side)\n",
    "# ---------------------------\n",
    "succ = df[df.success == True]\n",
    "fail = df[df.success == False]\n",
    "\n",
    "y_bin = df[\"success\"].astype(int).to_numpy()\n",
    "\n",
    "# --- best balanced accuracy for a single metric (try both directions) ---\n",
    "def _best_bacc_any_direction(y, x):\n",
    "    y = np.asarray(y, dtype=int)\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    m = np.isfinite(x) & np.isfinite(y)\n",
    "    if m.sum() < 5 or np.unique(y[m]).size < 2:\n",
    "        return float(\"nan\"), 0\n",
    "\n",
    "    yy = y[m]\n",
    "    xx = x[m]\n",
    "    xs = np.unique(xx)\n",
    "\n",
    "    # candidate thresholds\n",
    "    if xs.size == 1:\n",
    "        thr_candidates = np.array([xs[0]], dtype=float)\n",
    "    else:\n",
    "        mids = (xs[:-1] + xs[1:]) * 0.5\n",
    "        thr_candidates = np.concatenate(([xs[0] - 1e-12], mids, [xs[-1] + 1e-12]))\n",
    "\n",
    "    def _best_for_dir(dir_sign: int):\n",
    "        best = -1.0\n",
    "        for thr in thr_candidates:\n",
    "            yhat = (xx >= thr) if dir_sign >= 0 else (xx <= thr)\n",
    "            ba = float(balanced_accuracy_score(yy, yhat.astype(int)))\n",
    "            if ba > best:\n",
    "                best = ba\n",
    "        return best\n",
    "\n",
    "    bpos = _best_for_dir(+1)\n",
    "    bneg = _best_for_dir(-1)\n",
    "    if bpos >= bneg:\n",
    "        return float(bpos), +1\n",
    "    return float(bneg), -1\n",
    "\n",
    "\n",
    "def _bacc_str(colname: str) -> str:\n",
    "    if colname not in df.columns:\n",
    "        return \"\"\n",
    "    bacc, _dir = _best_bacc_any_direction(y_bin, df[colname].to_numpy(dtype=float))\n",
    "    return f\" | bAcc={bacc:.3g}\" if np.isfinite(bacc) else \"\"\n",
    "\n",
    "\n",
    "def _violin_fail_succ(ax, values_s, values_f, title, ylabel=\"\"):\n",
    "    vs = np.asarray(values_s, float)\n",
    "    vf = np.asarray(values_f, float)\n",
    "    vs = vs[np.isfinite(vs)]\n",
    "    vf = vf[np.isfinite(vf)]\n",
    "\n",
    "    series, pos, labels = [], [], []\n",
    "    if vf.size:\n",
    "        series.append(vf); pos.append(1); labels.append(f\"FAIL (n={vf.size})\")\n",
    "    if vs.size:\n",
    "        series.append(vs); pos.append(2 if vf.size else 1); labels.append(f\"SUCCESS (n={vs.size})\")\n",
    "\n",
    "    if not series:\n",
    "        ax.text(0.5, 0.5, \"no finite data\", ha=\"center\", va=\"center\")\n",
    "        ax.set_axis_off()\n",
    "        return\n",
    "\n",
    "    ax.violinplot(series, positions=pos, widths=0.8, showmeans=False, showmedians=True, showextrema=False)\n",
    "\n",
    "    rng = np.random.default_rng(0)\n",
    "    if vf.size:\n",
    "        jf = (rng.random(vf.size) - 0.5) * 0.16\n",
    "        ax.scatter(np.full(vf.size, 1.0) + jf, vf, s=10, alpha=0.35)\n",
    "        ax.hlines(np.median(vf), 0.78, 1.22, linewidth=3)\n",
    "    if vs.size:\n",
    "        xs = 2.0 if vf.size else 1.0\n",
    "        js = (rng.random(vs.size) - 0.5) * 0.16\n",
    "        ax.scatter(np.full(vs.size, xs) + js, vs, s=10, alpha=0.35)\n",
    "        ax.hlines(np.median(vs), xs - 0.22, xs + 0.22, linewidth=3)\n",
    "\n",
    "    ax.set_xticks(pos)\n",
    "    ax.set_xticklabels(labels)\n",
    "    ax.set_title(title)\n",
    "    if ylabel:\n",
    "        ax.set_ylabel(ylabel)\n",
    "    ax.grid(True, alpha=0.25)\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(19.5, 4.8), constrained_layout=True)\n",
    "\n",
    "_violin_fail_succ(\n",
    "    axs[0],\n",
    "    succ[col_l2_in].to_numpy(),\n",
    "    fail[col_l2_in].to_numpy(),\n",
    "    f\"RAW L2 inside top-K important (K={K})\" + _bacc_str(col_l2_in),\n",
    "    col_l2_in,\n",
    ")\n",
    "_violin_fail_succ(\n",
    "    axs[1],\n",
    "    succ[col_l2_out].to_numpy(),\n",
    "    fail[col_l2_out].to_numpy(),\n",
    "    f\"RAW L2 outside top-K important (K={K})\" + _bacc_str(col_l2_out),\n",
    "    col_l2_out,\n",
    ")\n",
    "_violin_fail_succ(\n",
    "    axs[2],\n",
    "    succ[col_l2_ratio].to_numpy(),\n",
    "    fail[col_l2_ratio].to_numpy(),\n",
    "    f\"L2_in / L2_out (K={K})\" + _bacc_str(col_l2_ratio),\n",
    "    col_l2_ratio,\n",
    ")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# ROC-AUC for ALL metrics at K=2000\n",
    "# ---------------------------\n",
    "def _roc_auc_dir(y, x):\n",
    "    m = np.isfinite(x) & np.isfinite(y)\n",
    "    if m.sum() < 5 or np.unique(y[m]).size < 2:\n",
    "        return float(\"nan\"), 0\n",
    "    auc_raw = float(roc_auc_score(y[m], x[m]))\n",
    "    if auc_raw >= 0.5:\n",
    "        return auc_raw, +1\n",
    "    return 1.0 - auc_raw, -1\n",
    "\n",
    "\n",
    "# --- Helper: best balanced accuracy by thresholding ---\n",
    "def _best_bacc_dir(y, x, direction: int):\n",
    "    y = np.asarray(y, dtype=int)\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    m = np.isfinite(x) & np.isfinite(y)\n",
    "    if m.sum() < 5 or np.unique(y[m]).size < 2:\n",
    "        return float(\"nan\"), float(\"nan\")\n",
    "\n",
    "    yy = y[m]\n",
    "    xx = x[m]\n",
    "\n",
    "    xs = np.unique(xx)\n",
    "    if xs.size == 1:\n",
    "        thr = float(xs[0])\n",
    "        yhat = (xx >= thr) if int(direction) >= 0 else (xx <= thr)\n",
    "        return float(balanced_accuracy_score(yy, yhat.astype(int))), thr\n",
    "\n",
    "    mids = (xs[:-1] + xs[1:]) * 0.5\n",
    "    thr_candidates = np.concatenate(([xs[0] - 1e-12], mids, [xs[-1] + 1e-12]))\n",
    "\n",
    "    best_ba = -1.0\n",
    "    best_thr = float(\"nan\")\n",
    "    for thr in thr_candidates:\n",
    "        yhat = (xx >= thr) if int(direction) >= 0 else (xx <= thr)\n",
    "        ba = float(balanced_accuracy_score(yy, yhat.astype(int)))\n",
    "        if ba > best_ba:\n",
    "            best_ba = ba\n",
    "            best_thr = float(thr)\n",
    "\n",
    "    return float(best_ba), float(best_thr)\n",
    "\n",
    "\n",
    "k = K\n",
    "metrics_k2000 = [\n",
    "    f\"focus_frac__gxa_chw_k{k}\",\n",
    "    f\"enrichE_impTopK_gxa_chw_k{k}\",\n",
    "    f\"overlap_jacc__gxa_chw_k{k}\",\n",
    "    f\"focus_ratio_mean__gxa_chw_k{k}\",\n",
    "    f\"focus_diff_mean__gxa_chw_k{k}\",\n",
    "    f\"l2_in_topk__gxa_chw_k{k}\",\n",
    "    f\"l2_out_topk__gxa_chw_k{k}\",\n",
    "    f\"l2_ratio_in_out__gxa_chw_k{k}\",\n",
    "]\n",
    "\n",
    "y = df[\"success\"].astype(int).to_numpy()\n",
    "\n",
    "rows = []\n",
    "for mname in metrics_k2000:\n",
    "    if mname not in df.columns:\n",
    "        continue\n",
    "    x = df[mname].to_numpy(dtype=float)\n",
    "    auc, direction = _roc_auc_dir(y, x)\n",
    "    bacc, bthr = _best_bacc_dir(y, x, direction)\n",
    "\n",
    "    xs = succ[mname].to_numpy(dtype=float) if mname in succ.columns else np.array([])\n",
    "    xf = fail[mname].to_numpy(dtype=float) if mname in fail.columns else np.array([])\n",
    "    xs = xs[np.isfinite(xs)]\n",
    "    xf = xf[np.isfinite(xf)]\n",
    "\n",
    "    rows.append({\n",
    "        \"metric\": mname,\n",
    "        \"roc_auc\": float(auc),\n",
    "        \"auc_direction\": int(direction),\n",
    "        \"best_bal_acc\": float(bacc),\n",
    "        \"best_bal_thr\": float(bthr),\n",
    "        \"mean_s\": float(np.nanmean(xs)) if xs.size else float(\"nan\"),\n",
    "        \"mean_f\": float(np.nanmean(xf)) if xf.size else float(\"nan\"),\n",
    "        \"std_s\": float(np.nanstd(xs)) if xs.size else float(\"nan\"),\n",
    "        \"std_f\": float(np.nanstd(xf)) if xf.size else float(\"nan\"),\n",
    "        \"n_s\": int(xs.size),\n",
    "        \"n_f\": int(xf.size),\n",
    "    })\n",
    "\n",
    "auc_df_k2000 = pd.DataFrame(rows).sort_values(\"roc_auc\", ascending=False)\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# Side-by-side: ROC-AUC barh and best balanced accuracy barh\n",
    "# ---------------------------\n",
    "_v = auc_df_k2000.copy()\n",
    "_v = _v[np.isfinite(_v[\"roc_auc\"].to_numpy(dtype=float))]\n",
    "_v = _v.sort_values(\"roc_auc\", ascending=True)\n",
    "\n",
    "_vb = auc_df_k2000.copy()\n",
    "_vb = _vb[np.isfinite(_vb[\"best_bal_acc\"].to_numpy(dtype=float))]\n",
    "_vb = _vb.sort_values(\"best_bal_acc\", ascending=True)\n",
    "\n",
    "h = 0.45 * max(len(_v), len(_vb), 1) + 1.8\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(21.0, h), constrained_layout=True)\n",
    "\n",
    "# ROC-AUC (left)\n",
    "ax1.barh(_v[\"metric\"], _v[\"roc_auc\"])\n",
    "ax1.set_xlabel(\"ROC-AUC (>=0.5; higher is better)\")\n",
    "ax1.set_title(\"ROC-AUC for K=2000 metrics\")\n",
    "ax1.grid(True, axis=\"x\", alpha=0.25)\n",
    "for i, (auc, direc) in enumerate(zip(_v[\"roc_auc\"], _v[\"auc_direction\"])):\n",
    "    arrow = \"↑\" if int(direc) >= 0 else \"↓\"\n",
    "    ax1.text(float(auc) + 0.003, i, f\"{auc:.3f} {arrow}\", va=\"center\", fontsize=10)\n",
    "xmax1 = float(np.nanmax(_v[\"roc_auc\"].to_numpy(dtype=float))) if len(_v) else 1.0\n",
    "ax1.set_xlim(0.45, min(1.0, xmax1 + 0.06))\n",
    "\n",
    "# best bAcc (right)\n",
    "ax2.barh(_vb[\"metric\"], _vb[\"best_bal_acc\"])\n",
    "ax2.set_xlabel(\"best_bal_acc (>=0.5; higher is better)\")\n",
    "ax2.set_title(\"Best balanced accuracy for K=2000 metrics\")\n",
    "ax2.grid(True, axis=\"x\", alpha=0.25)\n",
    "for i, (ba, thr, direc) in enumerate(zip(_vb[\"best_bal_acc\"], _vb[\"best_bal_thr\"], _vb[\"auc_direction\"])):\n",
    "    rule = \">=\" if int(direc) >= 0 else \"<=\"\n",
    "    ax2.text(float(ba) + 0.003, i, f\"{ba:.3f} | thr {rule} {thr:.3g}\", va=\"center\", fontsize=10)\n",
    "xmax2 = float(np.nanmax(_vb[\"best_bal_acc\"].to_numpy(dtype=float))) if len(_vb) else 1.0\n",
    "ax2.set_xlim(0.45, min(1.0, xmax2 + 0.10))\n",
    "\n",
    "plt.show()"
   ],
   "id": "e6084643a8d2f3b3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Метрики для анализа Δ-фич и (не)успешности атаки\n",
    "\n",
    "Ниже собраны все метрики, которые мы считаем в ноутбуке, с кратким описанием **как именно они вычисляются** и **что должны отражать**.\n",
    "Обозначения:\n",
    "\n",
    "- Есть чистое изображение `x` и изображение с патчем `x̃`.\n",
    "- На фиксированном слое детектора получаем фичи `F(x)` и `F(x̃)`.\n",
    "- **Δ-фичи**: `Δ = F(x̃) - F(x)`, тензор размера `(C,H,W)` (в нашем случае обычно `C=512`, `H=W≈20`).\n",
    "- `|Δ|` — поэлементный модуль.\n",
    "- `success ∈ {0,1}` — успешность атаки (по выбранному критерию).\n",
    "- `importance` — карта “важности фич” для детекции объекта (считали двумя методами):\n",
    "  - `SSGrad`: **только H×W** (каналы неизбежно схлопнуты).\n",
    "  - `GradAct` (grad*act): доступна и **H×W**, и **полная C×H×W**.\n",
    "\n",
    "---\n",
    "\n",
    "## 1) Базовые метрики только по Δ (без importance)\n",
    "\n",
    "### `mean_signed`\n",
    "**Как считаем:** среднее значение Δ по всем элементам:\n",
    "\n",
    "$[\n",
    "\\text{mean\\_signed} = \\mathrm{mean}(\\Delta)\n",
    "]$\n",
    "\n",
    "**Что показывает:** общий “сдвиг знака” (например, систематическое уменьшение/увеличение активаций).\n",
    "Часто малоинформативно, потому что положительные и отрицательные изменения могут взаимно компенсироваться.\n",
    "\n",
    "### `l2_rms`\n",
    "**Как считаем:** RMS по всем элементам Δ:\n",
    "$\n",
    "\\text{l2\\_rms} = \\sqrt{\\mathrm{mean}(\\Delta^2)}\n",
    "$\n",
    "**Что показывает:** общую мощность изменения фич (масштаб атаки в фич-пространстве).\n",
    "\n",
    "### `abs_mean`, `abs_max`\n",
    "**Как считаем:**\n",
    "$\n",
    "\\text{abs\\_mean} = \\mathrm{mean}(|\\Delta|), \\quad\n",
    "\\text{abs\\_max} = \\max(|\\Delta|)\n",
    "$\n",
    "**Что показывает:** среднюю и пиковую величину изменения.\n",
    "\n",
    "### Канальные метрики (по каналам C)\n",
    "Пусть:\n",
    "$\n",
    "E_c = \\mathrm{mean}_{h,w}(|\\Delta_{c,h,w}|)\n",
    "$\n",
    "это энергия изменения в канале `c`.\n",
    "\n",
    "- `chan_energy_topk_mean` — среднее по top-k каналов по `E_c`.\n",
    "- `chan_energy_gini` — **Gini** по вектору `E` (неотрицательный).\n",
    "\n",
    "**Gini (для неотрицательных):** мера неравномерности распределения энергии по каналам.\n",
    "**Интерпретация:** высокий Gini → атака “концентрирует” изменение в небольшом числе каналов; низкий → изменения размазаны равномернее.\n",
    "\n",
    "### Метрики на H×W-карте Δ\n",
    "Мы строим “magnitude карту” на сетке H×W, схлопывая каналы, напр. через `reduce_mode=\"l2\"`:\n",
    "$\n",
    "\\Delta_{hw} = \\mathrm{reduce}_C(\\Delta) \\in \\mathbb{R}^{H\\times W},\\ \\Delta_{hw}\\ge 0\n",
    "$\n",
    "Далее считаем:\n",
    "- `hw_abs_mean`, `hw_abs_max`\n",
    "- `hw_gini` — Gini по `Δ_hw`\n",
    "- `hw_sparsity_p90` — доля ячеек, попавших в верхние 10% по `Δ_hw`\n",
    "\n",
    "### ROI-метрики (по bbox из clean-предсказания)\n",
    "bbox человека (из clean) переводим в ROI на сетке H×W. Затем:\n",
    "- `roi_abs_mean` — среднее `Δ_hw` внутри ROI\n",
    "- `roi_abs_ratio` — отношение среднего внутри ROI к среднему вне ROI\n",
    "\n",
    "**Смысл:** если успех атаки связан с попаданием изменений в область объекта, то `roi_abs_ratio`/`roi_abs_mean` могут расти для успешных атак.\n",
    "\n",
    "---\n",
    "\n",
    "## 2) Метрики Δ vs importance (сопоставление с “важными фичами”)\n",
    "\n",
    "Мы сравниваем `|Δ|` с `importance` в двух представлениях:\n",
    "\n",
    "### H×W (SSGrad и GradAct collapsed)\n",
    "Есть:\n",
    "- `Δ_hw` (например reduce=`l2`)\n",
    "- `imp_hw` (важность на H×W)\n",
    "\n",
    "Метрики:\n",
    "\n",
    "#### `cos_hw_ssgrad`, `cos_hw_gxa`\n",
    "**Как считаем:** cosine similarity между `Δ_hw` и `imp_hw`:\n",
    "$\n",
    "\\cos = \\frac{\\langle \\Delta_{hw},\\ imp_{hw}\\rangle}{\\|\\Delta_{hw}\\|\\cdot\\|imp_{hw}\\|}\n",
    "$\n",
    "**Что показывает:** насколько форма карты Δ похожа на карту важности.\n",
    "\n",
    "#### `l2_hw_*`, `l2rel_hw_*`\n",
    "**Как считаем:**\n",
    "- `l2`: \\(\\|\\Delta_{hw} - imp_{hw}\\|_2\\)\n",
    "- `l2rel`: \\(\\frac{\\|\\Delta_{hw}-imp_{hw}\\|_2}{\\|\\Delta_{hw}\\|_2 + \\|imp_{hw}\\|_2}\\)\n",
    "\n",
    "**Что показывает:** “расхождение” Δ и importance.\n",
    "\n",
    "#### `topq_energy_frac_*` (обычно q=10%)\n",
    "**Как считаем:** доля энергии `|Δ_hw|` в верхних q% наиболее важных ячеек:\n",
    "$\n",
    "\\text{topq\\_energy\\_frac} = \\frac{\\sum_{(h,w)\\in \\text{top-q%}(imp)} |\\Delta_{hw}|}{\\sum_{h,w} |\\Delta_{hw}|}\n",
    "$\n",
    "**Что показывает:** концентрирует ли атака энергию именно в наиболее важных местах.\n",
    "\n",
    "### C×H×W (GradAct full)\n",
    "Есть полный тензор важности `imp_chw ≥ 0` и `|Δ|_chw`.\n",
    "\n",
    "#### `cos_chw_gxa`\n",
    "Cosine similarity на векторизации всех элементов:\n",
    "$\n",
    "\\cos = \\frac{\\langle |\\Delta|,\\ imp\\rangle}{\\||\\Delta|\\|\\cdot\\|imp\\|}\n",
    "$\n",
    "\n",
    "#### `l2_chw_gxa`, `l2rel_chw_gxa`\n",
    "L2 и относительная L2 (как выше, но по CHW).\n",
    "\n",
    "#### `spearman_chan_energy_gxa`\n",
    "Берём вектор энергий по каналам:\n",
    "$\n",
    "E^\\Delta_c = \\mathrm{mean}_{h,w}(|\\Delta_{c,h,w}|), \\quad\n",
    "E^{imp}_c = \\mathrm{mean}_{h,w}(imp_{c,h,w})\n",
    "$\n",
    "Считаем Spearman(ранговую корреляцию) между двумя векторами.\n",
    "\n",
    "**Смысл:** совпадает ли ранжирование “важных каналов” и “каналов, по которым бьёт патч”.\n",
    "\n",
    "#### `jaccard_topk_chan_gxa`\n",
    "Берём top-k каналов по `E^\\Delta` и по `E^{imp}` и считаем Jaccard:\n",
    "$\n",
    "J = \\frac{|TopK(E^\\Delta)\\cap TopK(E^{imp})|}{|TopK(E^\\Delta)\\cup TopK(E^{imp})|}\n",
    "$\n",
    "**Смысл:** доля совпадения самых “энергичных” и самых “важных” каналов.\n",
    "\n",
    "---\n",
    "\n",
    "## 3) Top-K фокус на важных фичах (feature-focus experiments)\n",
    "\n",
    "Здесь мы выбираем **top-K элементов importance** и смотрим, сколько энергии Δ попало именно туда.\n",
    "Работает на:\n",
    "- CHW: (очень много элементов, K может быть 2000+)\n",
    "- HW: (всего 400 элементов, K меньше)\n",
    "\n",
    "### Ключевая идея\n",
    "Пусть `S = TopK(imp)` — множество индексов K самых важных элементов.\n",
    "\n",
    "Тогда:\n",
    "\n",
    "### `focus_frac__*__*__kK`\n",
    "**Как считаем:**\n",
    "$\n",
    "\\text{focus\\_frac} = \\frac{\\sum_{i \\in S} |\\Delta_i|}{\\sum_i |\\Delta_i|}\n",
    "$\n",
    "**Что показывает:** какая доля энергии атаки попала в важные фичи (масштаб-независимо).\n",
    "\n",
    "### `focus_enrich__*__*__kK`\n",
    "**Как считаем:** нормируем на “ожидаемую долю при равномерном попадании” `K/N`:\n",
    "$\n",
    "\\text{focus\\_enrich} = \\frac{\\text{focus\\_frac}}{K/N}\n",
    "$\n",
    "**Интерпретация:**\n",
    "- ~1 → попадание как случайное\n",
    "- >1 → атака концентрируется в важных\n",
    "- <1 → атакует “неважные”\n",
    "\n",
    "### `overlap_jacc__delta_vs_imp__...__kK` (CHW GradAct)\n",
    "Берём `TopK(|Δ|)` и `TopK(imp)` и считаем Jaccard:\n",
    "$\n",
    "J = \\frac{|TopK(|\\Delta|)\\cap TopK(imp)|}{|TopK(|\\Delta|)\\cup TopK(imp)|}\n",
    "$\n",
    "**Смысл:** совпадают ли “самые изменённые” элементы с “самыми важными”.\n",
    "\n",
    "---\n",
    "\n",
    "## 4) “Только важные фичи” без общей энергии: внутри vs снаружи (mean-contrast)\n",
    "\n",
    "Мы сравниваем **средний уровень |Δ|** внутри top-K(imp) и снаружи.\n",
    "\n",
    "Пусть `S = TopK(imp)`, тогда:\n",
    "$\n",
    "\\mu_{in}=\\mathrm{mean}_{i\\in S}(|\\Delta_i|), \\quad \\mu_{out}=\\mathrm{mean}_{i\\notin S}(|\\Delta_i|)\n",
    "$\n",
    "\n",
    "### `focus_ratio_mean__...__kK`\n",
    "$\n",
    "\\text{ratio} = \\frac{\\mu_{in}}{\\mu_{out}}\n",
    "$\n",
    "**Смысл:** насколько сильнее “дрожат” важные фичи относительно неважных.\n",
    "\n",
    "### `focus_diff_mean__...__kK`\n",
    "$\n",
    "\\text{diff} = \\mu_{in}-\\mu_{out}\n",
    "$\n",
    "**Смысл:** абсолютная разница уровня изменения.\n",
    "\n",
    "---\n",
    "\n",
    "## 5) RAW L2 энергия Δ в важных фичах (без нормировок)\n",
    "\n",
    "Это именно “энергия атаки в выбранных важных координатах”, а не сравнение Δ и importance.\n",
    "\n",
    "Пусть `S = TopK(imp)`:\n",
    "\n",
    "### `l2_in_topk__...__kK`\n",
    "$\n",
    "\\text{L2\\_in} = \\|\\ |\\Delta|_{S}\\ \\|_2\n",
    "$\n",
    "\n",
    "### `l2_out_topk__...__kK`\n",
    "$\n",
    "\\text{L2\\_out} = \\|\\ |\\Delta|_{\\neg S}\\ \\|_2\n",
    "$\n",
    "\n",
    "### `l2_ratio_in_out__...__kK`\n",
    "$\n",
    "\\text{L2\\_ratio} = \\frac{\\text{L2\\_in}}{\\text{L2\\_out}}\n",
    "$\n",
    "\n",
    "**Смысл:** сколько “квадратичной энергии” Δ оказалось в важной области относительно неважной.\n",
    "\n",
    "---\n",
    "\n",
    "## 6) ROC-AUC и направление (auc_direction)\n",
    "\n",
    "Для каждой метрики `m` мы считаем ROC-AUC по бинарной метке `success`.\n",
    "Так как нам важно сравнивать “качество разделения”, мы всегда приводим AUC к ≥ 0.5:\n",
    "\n",
    "- `auc_direction = +1`: **большие значения метрики → более вероятный SUCCESS**\n",
    "- `auc_direction = -1`: метрика работает “в обратную сторону” (SUCCESS при меньших значениях), поэтому мы выводим `1 - AUC_raw`\n",
    "\n",
    "Это удобно для сортировки метрик по “разделяющей способности”, но важно помнить направление при интерпретации.\n",
    "\n",
    "---\n",
    "\n",
    "## 7) Как читать метрики в контексте гипотезы\n",
    "\n",
    "Гипотеза: *успешная атака отличается тем, что энергия Δ лучше “попадает” в важные фичи (или ROI) для детекции.*\n",
    "\n",
    "Ожидаемые паттерны при подтверждении гипотезы:\n",
    "- выше `focus_frac`, `focus_enrich`\n",
    "- выше `focus_ratio_mean` / `focus_diff_mean`\n",
    "- выше `l2_in_topk` и/или выше `l2_ratio_in_out`\n",
    "- выше `topq_energy_frac_*`\n",
    "- выше `overlap_jacc_*` и/или `jaccard_topk_chan_gxa`\n",
    "- выше `roi_abs_ratio`\n",
    "\n",
    "Если “всё плохо” и AUC близко к 0.5, это означает, что:\n",
    "- либо патч меняет фичи схожим образом и в success и в fail,\n",
    "- либо текущая importance-карта не соответствует реальным причинным “важным” фичам (ошибка выбора target/ROI/критерия),\n",
    "- либо успех определяется не попаданием в важные фичи на данном слое, а динамикой на других слоях/в голове/в NMS/в bbox selection."
   ],
   "id": "9207477ad666dbfc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Взвешенные дельты\n",
    "\n",
    "В дальнейших расчетах будут участвовать тензоры дельт от наложения патча, умноженные на тензоры важностей соответствующих фич (поэлементно)"
   ],
   "id": "7a506dec967fd95d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# --- Δ overlays + grad*act + weighted(Δ⊙imp) with 5 columns ---\n",
    "# Cols:\n",
    "# 1) patched\n",
    "# 2) patched + signed Δ (seismic, symmetric)\n",
    "# 3) patched + signed grad*act (seismic, symmetric around 0)\n",
    "# 4) patched + signed (Δ ⊙ importance) with alpha=0.0 (i.e., hidden overlay) + bbox\n",
    "# 5) patched + signed (Δ ⊙ importance) with custom alpha ONLY for this column + bbox\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, List\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def _robust_norm_signed(x: np.ndarray, q: float = 99.0, eps: float = 1e-12):\n",
    "    \"\"\"Normalize to [-1,1] using symmetric robust scale based on q-th percentile of |x|.\"\"\"\n",
    "    x = np.asarray(x, dtype=np.float32)\n",
    "    s = float(np.percentile(np.abs(x[np.isfinite(x)]), q)) if np.isfinite(x).any() else 1.0\n",
    "    s = max(s, eps)\n",
    "    return np.clip(x / s, -1.0, 1.0), s\n",
    "\n",
    "\n",
    "def _reduce_channels(t_chw: torch.Tensor, mode: str = \"topk_mean\", topk: int = 32) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Reduce (C,H,W) -> (H,W).\n",
    "    Expected to exist in your notebook already; kept here for safety.\n",
    "    Modes used in this cell:\n",
    "      - \"l2\": sqrt(mean_c x^2)\n",
    "      - \"abs_mean\": mean_c |x|\n",
    "      - \"topk_mean\": mean of top-k |x| across channels (signed by mean sign per pixel)\n",
    "      - \"topk_sum\": sum of top-k |x| across channels (signed by mean sign per pixel)\n",
    "    \"\"\"\n",
    "    if t_chw.ndim != 3:\n",
    "        raise ValueError(f\"_reduce_channels expects (C,H,W), got {tuple(t_chw.shape)}\")\n",
    "\n",
    "    C, H, W = t_chw.shape\n",
    "    if mode == \"l2\":\n",
    "        return torch.sqrt(torch.mean(t_chw * t_chw, dim=0).clamp(min=0))\n",
    "    if mode == \"abs_mean\":\n",
    "        return torch.mean(t_chw.abs(), dim=0)\n",
    "\n",
    "    # topk by magnitude across channels, but keep sign:\n",
    "    # sign per (h,w) from mean over channels (robust enough for visualization)\n",
    "    k = int(min(max(int(topk), 1), C))\n",
    "    mag = t_chw.abs()  # (C,H,W)\n",
    "    topv, _ = torch.topk(mag, k=k, dim=0, largest=True, sorted=False)  # (k,H,W)\n",
    "    base = topv.mean(dim=0) if mode == \"topk_mean\" else topv.sum(dim=0)\n",
    "    sgn = torch.sign(t_chw.mean(dim=0))  # (H,W)\n",
    "    return base * sgn\n",
    "\n",
    "\n",
    "def _draw_clean_bbox(ax, bbox_xyxy, success: bool):\n",
    "    \"\"\"Draw bbox (x1,y1,x2,y2) on axis; assumes image is 640x640.\"\"\"\n",
    "    if bbox_xyxy is None:\n",
    "        return\n",
    "    x1, y1, x2, y2 = [float(v) for v in bbox_xyxy]\n",
    "    w = max(0.0, x2 - x1)\n",
    "    h = max(0.0, y2 - y1)\n",
    "    import matplotlib.patches as patches\n",
    "    rect = patches.Rectangle(\n",
    "        (x1, y1), w, h,\n",
    "        linewidth=2.0,\n",
    "        edgecolor=(\"lime\" if success else \"red\"),\n",
    "        facecolor=\"none\",\n",
    "    )\n",
    "    ax.add_patch(rect)\n",
    "\n",
    "\n",
    "def visualize_delta_maps_5cols(\n",
    "    run_data: List[Dict[str, Any]],\n",
    "    layer: str = \"model.22\",\n",
    "    reduce_mode: str = \"topk_mean\",\n",
    "    topk: int = 32,\n",
    "    max_rows: int | None = None,\n",
    "    alpha: float = 0.45,\n",
    "    alpha_weighted: float = 0.25,   # ONLY for col 5\n",
    "    save_dir: str | Path | None = None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Per-row layout (5 columns):\n",
    "      1) patched\n",
    "      2) patched + signed Δ\n",
    "      3) patched + signed grad*act (imp_gxa_hw, sign restored)\n",
    "      4) patched + signed (Δ ⊙ importance), BUT alpha=0.0 (hidden)  [still draws bbox]\n",
    "      5) patched + signed (Δ ⊙ importance) with alpha=alpha_weighted\n",
    "\n",
    "    Requirements for `run_data` entries:\n",
    "      - d[\"patch_lb\"] or d[\"patched_lb\"] or equivalent PIL image (letterboxed)\n",
    "      - d[\"gradcam_info\"][\"picked_bbox\"] for bbox overlay (optional)\n",
    "      - d[\"success\"], d[\"conf_clean\"], d[\"conf_patch\"], d[\"drop\"]\n",
    "      - d[\"deltas\"][layer] as torch.Tensor (1,C,H,W) OR (C,H,W) (we handle both)\n",
    "      - d[\"imp_gxa_hw\"] as (H,W) float array in [0,1] (used for col 3, sign restored)\n",
    "      - d[\"imp_gxa_chw\"] as (C,H,W) float array >=0 (used for weighted product)\n",
    "    \"\"\"\n",
    "\n",
    "    # choose subset\n",
    "    rows = run_data if (max_rows is None) else run_data[: int(max_rows)]\n",
    "    n = len(rows)\n",
    "    if n == 0:\n",
    "        print(\"[warn] No rows to visualize.\")\n",
    "        return\n",
    "\n",
    "    fig, axes = plt.subplots(nrows=n, ncols=5, figsize=(25, 4.6 * n))\n",
    "    if n == 1:\n",
    "        axes = np.expand_dims(axes, axis=0)\n",
    "\n",
    "    if save_dir is not None:\n",
    "        save_dir = Path(save_dir)\n",
    "        save_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    for i, d in enumerate(rows):\n",
    "        # ---- basic fields ----\n",
    "        p = d.get(\"path\", f\"row{i}\")\n",
    "        success = bool(d.get(\"success\", False))\n",
    "        status = \"SUCCESS\" if success else \"FAIL\"\n",
    "        conf_c = float(d.get(\"conf_clean\", float(\"nan\")))\n",
    "        conf_p = float(d.get(\"conf_patch\", float(\"nan\")))\n",
    "        drop = float(d.get(\"drop\", float(\"nan\")))\n",
    "\n",
    "        gcinfo = d.get(\"gradcam_info\", {}) if isinstance(d.get(\"gradcam_info\", {}), dict) else {}\n",
    "        bbox_xyxy = gcinfo.get(\"picked_bbox\", None)\n",
    "\n",
    "        # patched image (try a few common keys)\n",
    "        patched_img = d.get(\"patch_lb\", None)\n",
    "        if patched_img is None:\n",
    "            patched_img = d.get(\"patched_lb\", None)\n",
    "        if patched_img is None:\n",
    "            patched_img = d.get(\"clean_lb\", None)\n",
    "\n",
    "        if patched_img is None:\n",
    "            # nothing to draw\n",
    "            for j in range(5):\n",
    "                axes[i, j].set_axis_off()\n",
    "                axes[i, j].set_title(\"missing image\")\n",
    "            continue\n",
    "\n",
    "        img_np = np.asarray(patched_img.convert(\"RGB\"))\n",
    "        tgt_h, tgt_w = img_np.shape[0], img_np.shape[1]\n",
    "\n",
    "        # delta (prefer stored torch tensor)\n",
    "        delta = d.get(\"deltas\", {}).get(layer, None)\n",
    "        if delta is None:\n",
    "            # still show image-only\n",
    "            for j, title in enumerate(\n",
    "                [\"patched\", \"patched + signed Δ\", \"patched + signed grad*act\", \"patched + signed (Δ⊙imp) alpha=0\", \"patched + signed (Δ⊙imp)\"]\n",
    "            ):\n",
    "                axes[i, j].imshow(img_np)\n",
    "                _draw_clean_bbox(axes[i, j], bbox_xyxy, success)\n",
    "                axes[i, j].set_title(title + \" (missing Δ)\")\n",
    "                axes[i, j].axis(\"off\")\n",
    "            continue\n",
    "\n",
    "        # normalize delta shape to (C,H,W) torch\n",
    "        if isinstance(delta, torch.Tensor):\n",
    "            if delta.ndim == 4:\n",
    "                delta_chw = delta[0].detach().cpu()\n",
    "            elif delta.ndim == 3:\n",
    "                delta_chw = delta.detach().cpu()\n",
    "            else:\n",
    "                raise ValueError(f\"Unexpected delta tensor shape: {tuple(delta.shape)}\")\n",
    "        else:\n",
    "            # allow numpy\n",
    "            delta_arr = np.asarray(delta)\n",
    "            if delta_arr.ndim == 4:\n",
    "                delta_arr = delta_arr[0]\n",
    "            if delta_arr.ndim != 3:\n",
    "                raise ValueError(f\"Unexpected delta array shape: {tuple(delta_arr.shape)}\")\n",
    "            delta_chw = torch.as_tensor(delta_arr, dtype=torch.float32)\n",
    "\n",
    "        C, H, W = tuple(delta_chw.shape)\n",
    "\n",
    "        # --- signed Δ map (H,W) then upsample ---\n",
    "        signed_hw_t = _reduce_channels(delta_chw.float(), mode=reduce_mode, topk=topk)  # (H,W) signed\n",
    "        if tuple(signed_hw_t.shape) != (tgt_h, tgt_w):\n",
    "            signed_hw_t = F.interpolate(signed_hw_t[None, None, ...], size=(tgt_h, tgt_w), mode=\"nearest\")[0, 0]\n",
    "        signed_hw = signed_hw_t.numpy()\n",
    "        signed_n, _ = _robust_norm_signed(signed_hw, q=99.0)\n",
    "\n",
    "        # --- signed grad*act map from imp_gxa_hw (H,W in [0,1]) ---\n",
    "        gxa_hw = d.get(\"imp_gxa_hw\", None)\n",
    "        if gxa_hw is not None:\n",
    "            gxa_hw_t = torch.as_tensor(np.asarray(gxa_hw), dtype=torch.float32)\n",
    "            # restore sign from Δ map (same grid) BEFORE upsampling\n",
    "            sign_hw_small = torch.sign(_reduce_channels(delta_chw.float(), mode=reduce_mode, topk=topk))\n",
    "            # align shapes (should already be H,W)\n",
    "            if tuple(gxa_hw_t.shape) != tuple(sign_hw_small.shape):\n",
    "                raise ValueError(f\"imp_gxa_hw shape {tuple(gxa_hw_t.shape)} != sign_hw shape {tuple(sign_hw_small.shape)}\")\n",
    "            gxa_signed_small = gxa_hw_t * sign_hw_small  # signed grad*act proxy\n",
    "            if tuple(gxa_signed_small.shape) != (tgt_h, tgt_w):\n",
    "                gxa_signed_up = F.interpolate(gxa_signed_small[None, None, ...], size=(tgt_h, tgt_w), mode=\"nearest\")[0, 0]\n",
    "            else:\n",
    "                gxa_signed_up = gxa_signed_small\n",
    "            gxa_signed = gxa_signed_up.numpy()\n",
    "            gxa_n, _ = _robust_norm_signed(gxa_signed, q=99.0)\n",
    "        else:\n",
    "            gxa_n = None\n",
    "\n",
    "        # --- signed (Δ ⊙ importance) computed on full (C,H,W) ---\n",
    "        imp_chw = d.get(\"imp_gxa_chw\", None)\n",
    "        if imp_chw is not None:\n",
    "            imp_chw_t = torch.as_tensor(np.asarray(imp_chw), dtype=torch.float32)\n",
    "            if tuple(imp_chw_t.shape) != tuple(delta_chw.shape):\n",
    "                raise ValueError(f\"imp_gxa_chw shape {tuple(imp_chw_t.shape)} != delta_chw shape {tuple(delta_chw.shape)}\")\n",
    "\n",
    "            weighted_chw = delta_chw.float() * imp_chw_t  # KEEP SIGN ✅\n",
    "            weighted_hw_t = _reduce_channels(weighted_chw, mode=reduce_mode, topk=topk).detach().cpu()  # signed (H,W)\n",
    "\n",
    "            if tuple(weighted_hw_t.shape) != (tgt_h, tgt_w):\n",
    "                weighted_hw_t = F.interpolate(weighted_hw_t[None, None, ...], size=(tgt_h, tgt_w), mode=\"nearest\")[0, 0]\n",
    "            weighted_hw = weighted_hw_t.numpy()\n",
    "            weighted_n, _ = _robust_norm_signed(weighted_hw, q=99.0)\n",
    "        else:\n",
    "            weighted_n = None\n",
    "\n",
    "        # -------------------------\n",
    "        # Plot: 5 columns\n",
    "        # -------------------------\n",
    "        # Col 1: patched\n",
    "        axes[i, 0].imshow(img_np)\n",
    "        _draw_clean_bbox(axes[i, 0], bbox_xyxy, success)\n",
    "        axes[i, 0].set_title(f\"patched | {status}\\nclean={conf_c:.3f} → patched={conf_p:.3f} (drop={drop:.3f})\")\n",
    "        axes[i, 0].axis(\"off\")\n",
    "\n",
    "        # Col 2: signed Δ\n",
    "        axes[i, 1].imshow(img_np)\n",
    "        _draw_clean_bbox(axes[i, 1], bbox_xyxy, success)\n",
    "        im2 = axes[i, 1].imshow(signed_n, vmin=-1, vmax=1, cmap=\"seismic\", alpha=alpha)\n",
    "        axes[i, 1].set_title(f\"patched + signed Δ | {reduce_mode}\\n{status}\")\n",
    "        axes[i, 1].axis(\"off\")\n",
    "        plt.colorbar(im2, ax=axes[i, 1], fraction=0.046, pad=0.04)\n",
    "\n",
    "        # Col 3: signed grad*act\n",
    "        axes[i, 2].imshow(img_np)\n",
    "        _draw_clean_bbox(axes[i, 2], bbox_xyxy, success)\n",
    "        if gxa_n is None:\n",
    "            axes[i, 2].set_title(\"patched + signed grad*act (missing)\")\n",
    "        else:\n",
    "            im3 = axes[i, 2].imshow(gxa_n, vmin=-1, vmax=1, cmap=\"seismic\", alpha=alpha)\n",
    "            axes[i, 2].set_title(f\"patched + signed grad*act\\n{status}\")\n",
    "            plt.colorbar(im3, ax=axes[i, 2], fraction=0.046, pad=0.04)\n",
    "        axes[i, 2].axis(\"off\")\n",
    "\n",
    "        # Col 4: signed (Δ⊙imp) alpha=0.0\n",
    "        axes[i, 3].imshow(img_np)\n",
    "        _draw_clean_bbox(axes[i, 3], bbox_xyxy, success)\n",
    "        if weighted_n is None:\n",
    "            axes[i, 3].set_title(\"patched + signed (Δ⊙imp) (missing) | alpha=0\")\n",
    "        else:\n",
    "            axes[i, 3].imshow(weighted_n, vmin=-1, vmax=1, cmap=\"seismic\", alpha=1.0)  # alpha=0 ✅\n",
    "            axes[i, 3].set_title(f\"patched + signed (Δ⊙imp) | alpha=0\\n{status}\")\n",
    "        axes[i, 3].axis(\"off\")\n",
    "\n",
    "        # Col 5: signed (Δ⊙imp) custom alpha\n",
    "        axes[i, 4].imshow(img_np)\n",
    "        _draw_clean_bbox(axes[i, 4], bbox_xyxy, success)\n",
    "        if weighted_n is None:\n",
    "            axes[i, 4].set_title(\"patched + signed (Δ⊙imp) (missing)\")\n",
    "        else:\n",
    "            im5 = axes[i, 4].imshow(weighted_n, vmin=-1, vmax=1, cmap=\"seismic\", alpha=float(alpha_weighted))\n",
    "            axes[i, 4].set_title(f\"patched + signed (Δ⊙imp) | alpha={alpha_weighted:g}\\n{status}\")\n",
    "            plt.colorbar(im5, ax=axes[i, 4], fraction=0.046, pad=0.04)\n",
    "        axes[i, 4].axis(\"off\")\n",
    "\n",
    "        # Row label\n",
    "        axes[i, 0].set_ylabel(\n",
    "            f\"{Path(str(p)).name}\\n{status} | clean={conf_c:.3f} patched={conf_p:.3f} drop={drop:.3f}\",\n",
    "            rotation=0,\n",
    "            labelpad=70,\n",
    "            va=\"center\",\n",
    "        )\n",
    "\n",
    "        # Optional save: save composite RGBs for cols 2/3/5 (col 4 is intentionally alpha=0)\n",
    "        if save_dir is not None:\n",
    "            stem = Path(str(p)).stem\n",
    "            base = img_np.astype(np.float32) / 255.0\n",
    "\n",
    "            def _save_signed_overlay(arr_n, out_path: Path, a: float):\n",
    "                cmap = plt.get_cmap(\"seismic\")\n",
    "                rgba = cmap((arr_n + 1.0) * 0.5)\n",
    "                comp = (1 - a) * base + a * rgba[..., :3]\n",
    "                comp = np.clip(comp, 0.0, 1.0)\n",
    "                plt.imsave(out_path, comp)\n",
    "\n",
    "            out2 = save_dir / f\"{stem}__overlay_signedDelta_{reduce_mode}.png\"\n",
    "            _save_signed_overlay(signed_n, out2, float(alpha))\n",
    "\n",
    "            if gxa_n is not None:\n",
    "                out3 = save_dir / f\"{stem}__overlay_signedGradAct.png\"\n",
    "                _save_signed_overlay(gxa_n, out3, float(alpha))\n",
    "\n",
    "            if weighted_n is not None:\n",
    "                out5 = save_dir / f\"{stem}__overlay_signedWeighted_{reduce_mode}_a{alpha_weighted:g}.png\"\n",
    "                _save_signed_overlay(weighted_n, out5, float(alpha_weighted))\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Example call:\n",
    "visualize_delta_maps_5cols(\n",
    "     run_data=examples,          # or run_data\n",
    "     layer=\"model.22\",\n",
    "     reduce_mode=\"topk_mean\",\n",
    "     topk=32,\n",
    "     max_rows=10,\n",
    "     alpha=1,\n",
    "     alpha_weighted=0.22,\n",
    "     save_dir=None,\n",
    " )"
   ],
   "id": "462b3b0728cfedc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "3f805f432a0b0839",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
